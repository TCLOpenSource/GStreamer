From d789693bb929e846b9b46a6fc25ebb5325b80b3f Mon Sep 17 00:00:00 2001
From: TCLCode <opensource@tcl.com>
Date: Thu, 6 Mar 2025 11:24:05 +0800
Subject: [PATCH] TCL modifications for gst-plugins-bad

---
 .../gst-plugins-bad/ext/aes/meson.build       |    7 +-
 .../ext/closedcaption/gstcea708decoder.c      |   10 +-
 .../gst-plugins-bad/ext/dtls/meson.build      |    7 +-
 .../ext/fluidsynth/gstfluiddec.c              |   95 +
 .../gst-plugins-bad/ext/hls/gsthlsplugin.c    |    3 +-
 .../gst-plugins-bad/ext/hls/meson.build       |    7 +-
 subprojects/gst-plugins-bad/ext/meson.build   |    1 +
 .../ext/videorender/gstnativewindowsink.c     | 1140 ++++++
 .../ext/videorender/gstnativewindowsink.h     |  140 +
 .../ext/videorender/gstnativewindowwrap.c     | 1270 ++++++
 .../ext/videorender/gstnativewindowwrap.h     |  177 +
 .../ext/videorender/meson.build               |   16 +
 .../gst-libs/gst/codecparsers/gsth264parser.c |    4 +
 .../gst-libs/gst/codecparsers/gsth265parser.c |    9 +
 .../gst-libs/gst/mpegts/gstmpegtssection.c    |   21 +-
 .../gst-libs/gst/mpegts/gstmpegtssection.h    |    6 +-
 subprojects/gst-plugins-bad/gst/aiff/aiff.c   |    2 +
 .../gst-plugins-bad/gst/id3tag/gstid3mux.c    |    4 +
 .../gst/mpegdemux/gstmpegdemux.c              |  203 +-
 .../gst/mpegdemux/gstmpegdemux.h              |   25 +-
 .../gst/mpegdemux/gstpesfilter.c              |   41 +
 .../gst/mpegdemux/gstpesfilter.h              |   15 +-
 .../gst/mpegtsdemux/gstavprotocol.c           |  371 ++
 .../gst/mpegtsdemux/gstavprotocol.h           |   79 +
 .../gst/mpegtsdemux/gstmpegdesc.h             |    5 +-
 .../gst/mpegtsdemux/meson.build               |   13 +-
 .../gst/mpegtsdemux/mpegtsbase.c              |  262 +-
 .../gst/mpegtsdemux/mpegtsbase.h              |   27 +-
 .../gst/mpegtsdemux/mpegtspacketizer.c        |  426 +-
 .../gst/mpegtsdemux/mpegtspacketizer.h        |   57 +-
 .../gst/mpegtsdemux/pesparse.c                |   25 +
 .../gst-plugins-bad/gst/mpegtsdemux/tsdemux.c | 2325 ++++++++++-
 .../gst-plugins-bad/gst/mpegtsdemux/tsdemux.h |  138 +
 .../gst-plugins-bad/gst/rawparse/plugin.c     |    5 +
 .../gst/videofilters/gstvideofiltersbad.c     |    5 +-
 .../gst/videoparsers/gstav1parse.c            |   11 +-
 .../gst/videoparsers/gsth264parse.c           |   64 +
 .../gst/videoparsers/gsth265parse.c           |   55 +-
 .../gst/videoparsers/gsth265parse2.c          | 3433 +++++++++++++++++
 .../gst/videoparsers/gsth265parse2.h          |  141 +
 .../gst/videoparsers/gstmpeg4videoparse.c     |   23 +
 .../gst/videoparsers/gstmpegvideoparse.c      |   29 +
 .../gst/videoparsers/gstpngparse.c            |   81 +-
 .../gst/videoparsers/gstpngparse.h            |    4 +-
 .../videoparsers/gstvideoparserselements.h    |    3 +
 .../gst/videoparsers/meson.build              |    1 +
 .../gst-plugins-bad/gst/videoparsers/plugin.c |    3 +
 subprojects/gst-plugins-bad/meson.build       |   12 +-
 subprojects/gst-plugins-bad/meson_options.txt |    1 +
 .../dshowsrcwrapper/dshowdeviceprovider.cpp   |    2 +-
 .../gst-plugins-bad/sys/tinyalsa/tinyalsa.c   |    4 +
 .../sys/tinyalsa/tinyalsasink.c               | 1005 +++++
 .../sys/tinyalsa/tinyalsasink.h               |    8 +
 .../sys/winks/ksdeviceprovider.c              |    2 +-
 54 files changed, 11725 insertions(+), 98 deletions(-)
 create mode 100644 subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.c
 create mode 100644 subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.h
 create mode 100644 subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.c
 create mode 100644 subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.h
 create mode 100644 subprojects/gst-plugins-bad/ext/videorender/meson.build
 create mode 100644 subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.c
 create mode 100644 subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.h
 create mode 100644 subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.c
 create mode 100644 subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.h

diff --git a/subprojects/gst-plugins-bad/ext/aes/meson.build b/subprojects/gst-plugins-bad/ext/aes/meson.build
index 20b8a2cabd..454f72d858 100644
--- a/subprojects/gst-plugins-bad/ext/aes/meson.build
+++ b/subprojects/gst-plugins-bad/ext/aes/meson.build
@@ -4,11 +4,12 @@ aes_sources = [
   'gstaesenc.c',
   'gstaesdec.c',
 ]
-
 aes_cargs = []
-aes_dep = dependency('openssl', version : '>= 1.1.0', required : get_option('aes'))
+openssl_link_args = []
+aes_dep = dependency('openssl', version : '>= 1.1.0', required : get_option('aes'), static :true)
 if aes_dep.found()
   aes_cargs += ['-DHAVE_OPENSSL']
+  openssl_link_args += ['-Wl,--exclude-libs,libssl.a -Wl,--exclude-libs,libcrypto.a']
 else
   subdir_done()
 endif
@@ -16,7 +17,7 @@ endif
 gstaes = library('gstaes',
   aes_sources,
   c_args : gst_plugins_bad_args + aes_cargs,
-  link_args : noseh_link_args,
+  link_args : noseh_link_args + openssl_link_args,
   include_directories : [configinc],
   dependencies : [gstpbutils_dep, gstvideo_dep,
                   aes_dep, gio_dep, libm],
diff --git a/subprojects/gst-plugins-bad/ext/closedcaption/gstcea708decoder.c b/subprojects/gst-plugins-bad/ext/closedcaption/gstcea708decoder.c
index b2e9f98b6f..af6a1796e3 100644
--- a/subprojects/gst-plugins-bad/ext/closedcaption/gstcea708decoder.c
+++ b/subprojects/gst-plugins-bad/ext/closedcaption/gstcea708decoder.c
@@ -983,13 +983,13 @@ static void
 gst_cea708dec_show_pango_window (Cea708Dec * decoder, guint window_id)
 {
   cea708Window *window = decoder->cc_windows[window_id];
-  guint16 row, col;
+  gint16 row, col;
   gboolean display = FALSE;     /* = TRUE when text lines should be written */
   gchar line_buffer[LINEBUFFER_SIZE];
   gchar outchar_utf8[CC_UTF8_MAX_LENGTH + 1] = { 0 };
   guint8 utf8_char_length;
-  guint16 i, j;
-  guint16 right_index;          /* within a single line of window text, the
+  gint16 i, j;
+  gint16 right_index;           /* within a single line of window text, the
                                  * index of the rightmost non-blank character */
   guint16 index;
   guint len = 0;
@@ -1653,8 +1653,8 @@ static void
 gst_cea708dec_window_add_char (Cea708Dec * decoder, gunichar c)
 {
   cea708Window *window = decoder->cc_windows[decoder->current_window];
-  guint16 pen_row;
-  guint16 pen_col;
+  gint16 pen_row;
+  gint16 pen_col;
 
   /* Add one character to the current window, using current pen location.
    * Wrap pen location if necessary */
diff --git a/subprojects/gst-plugins-bad/ext/dtls/meson.build b/subprojects/gst-plugins-bad/ext/dtls/meson.build
index 99c2ffe133..25b88b1788 100644
--- a/subprojects/gst-plugins-bad/ext/dtls/meson.build
+++ b/subprojects/gst-plugins-bad/ext/dtls/meson.build
@@ -11,16 +11,17 @@ dtls_sources = [
   'plugin.c',
   'gstdtlselement.c',
 ]
-
-openssl_dep = dependency('openssl', version : '>= 1.0.1', required : get_option('dtls'))
-libcrypto_dep = dependency('libcrypto', required : get_option('dtls'))
+openssl_dep = dependency('openssl', version : '>= 1.0.1', required : get_option('dtls'), static: true)
+libcrypto_dep = dependency('libcrypto', required : get_option('dtls'), static: true)
 
 if openssl_dep.found() and libcrypto_dep.found()
+  openssl_link_args = ['-Wl,--exclude-libs,libssl.a -Wl,--exclude-libs,libcrypto.a']
   gstdtls = library('gstdtls',
     dtls_sources,
     c_args : gst_plugins_bad_args,
     include_directories : [configinc],
     dependencies : [gst_dep, libcrypto_dep, openssl_dep] + winsock2,
+    link_args: openssl_link_args,
     install : true,
     install_dir : plugins_install_dir,
   )
diff --git a/subprojects/gst-plugins-bad/ext/fluidsynth/gstfluiddec.c b/subprojects/gst-plugins-bad/ext/fluidsynth/gstfluiddec.c
index c53325526a..d9471809cc 100644
--- a/subprojects/gst-plugins-bad/ext/fluidsynth/gstfluiddec.c
+++ b/subprojects/gst-plugins-bad/ext/fluidsynth/gstfluiddec.c
@@ -472,6 +472,100 @@ gst_fluid_dec_chain (GstPad * sinkpad, GstObject * parent, GstBuffer * buffer)
   return res;
 }
 
+#ifdef TCL_PATCH
+static gboolean
+gst_fluid_dec_open (GstFluidDec * fluiddec)
+{
+  char* midi_enable = getenv("MIDI_ENABLE");
+  GDir *dir;
+  GError *error = NULL;
+
+  if(NULL == midi_enable || strcmp(midi_enable,"1") != 0){
+    return FALSE;
+  }
+  if (fluiddec->sf != -1)
+    return TRUE;
+
+  if (fluiddec->soundfont) {
+    GST_DEBUG_OBJECT (fluiddec, "loading soundfont file %s",
+        fluiddec->soundfont);
+
+    fluiddec->sf = fluid_synth_sfload (fluiddec->synth, fluiddec->soundfont, 1);
+    if (fluiddec->sf == -1)
+      goto load_failed;
+
+    GST_DEBUG_OBJECT (fluiddec, "loaded soundfont file %s",
+        fluiddec->soundfont);
+  } else {
+    char* root_diretory = getenv("MIDI_SOUNDFONT_ROOT_DIRECTORY");
+    char* sub_diretory  = getenv("MIDI_SOUNDFONT_SUBDIRECTORY");
+    gchar *soundfont_path = NULL;
+    if(NULL == root_diretory || NULL == sub_diretory){
+        return FALSE;
+    }
+    soundfont_path = g_build_path ("/", root_diretory, sub_diretory, NULL);;
+    GST_DEBUG_OBJECT (fluiddec, "Trying to list contents of a %s directory", soundfont_path);
+    error = NULL;
+    dir = g_dir_open (soundfont_path, 0, &error);
+    if (dir == NULL) {
+      GST_DEBUG_OBJECT (fluiddec,
+          "Can't open a potential soundfont directory %s: %s",
+          soundfont_path, error->message);
+      g_free (soundfont_path);
+      g_error_free (error);
+    }
+
+    while (TRUE) {
+      const gchar *name;
+      gchar *filename;
+
+      if ((name = g_dir_read_name (dir)) == NULL)
+        break;
+
+      filename = g_build_filename (soundfont_path, name, NULL);
+
+      GST_DEBUG_OBJECT (fluiddec, "loading soundfont file %s", filename);
+      fluiddec->sf = fluid_synth_sfload (fluiddec->synth, filename, 1);
+      if (fluiddec->sf != -1) {
+        GST_DEBUG_OBJECT (fluiddec, "loaded soundfont file %s", filename);
+        g_free (filename);
+        g_dir_close (dir);
+        g_free (soundfont_path);
+        goto done;
+      }
+      GST_DEBUG_OBJECT (fluiddec, "could not load soundfont file %s",
+          filename);
+      g_free (filename);
+    }
+    g_dir_close (dir);
+    g_free (soundfont_path);
+
+    if (fluiddec->sf == -1) {
+      goto no_soundfont;
+    }
+    root_diretory = NULL;
+    sub_diretory  = NULL;
+  }
+done:
+  return TRUE;
+
+  /* ERRORS */
+load_failed:
+  {
+    GST_ELEMENT_ERROR (fluiddec, RESOURCE, OPEN_READ,
+        ("Can't open soundfont %s", fluiddec->soundfont),
+        ("failed to open soundfont file %s for reading", fluiddec->soundfont));
+    return FALSE;
+  }
+no_soundfont:
+  {
+    GST_ELEMENT_ERROR (fluiddec, RESOURCE, OPEN_READ,
+        ("Can't find a soundfont file in subdirectories of XDG_DATA_DIRS paths"),
+        ("no usable soundfont files found in subdirectories of XDG_DATA_DIRS"));
+    return FALSE;
+  }
+}
+#else
 static gboolean
 gst_fluid_dec_open (GstFluidDec * fluiddec)
 {
@@ -566,6 +660,7 @@ no_soundfont:
     return FALSE;
   }
 }
+#endif
 
 static gboolean
 gst_fluid_dec_close (GstFluidDec * fluiddec)
diff --git a/subprojects/gst-plugins-bad/ext/hls/gsthlsplugin.c b/subprojects/gst-plugins-bad/ext/hls/gsthlsplugin.c
index cad1b55830..a4737befbe 100644
--- a/subprojects/gst-plugins-bad/ext/hls/gsthlsplugin.c
+++ b/subprojects/gst-plugins-bad/ext/hls/gsthlsplugin.c
@@ -10,8 +10,9 @@ static gboolean
 plugin_init (GstPlugin * plugin)
 {
   gboolean ret = FALSE;
-
+#ifndef TCL_PATCH
   ret |= GST_ELEMENT_REGISTER (hlsdemux, plugin);
+#endif
   ret |= GST_ELEMENT_REGISTER (hlssink, plugin);
   ret |= GST_ELEMENT_REGISTER (hlssink2, plugin);
   return ret;
diff --git a/subprojects/gst-plugins-bad/ext/hls/meson.build b/subprojects/gst-plugins-bad/ext/hls/meson.build
index 3444d37e79..92c11ee7cc 100644
--- a/subprojects/gst-plugins-bad/ext/hls/meson.build
+++ b/subprojects/gst-plugins-bad/ext/hls/meson.build
@@ -34,11 +34,12 @@ if not hls_crypto_dep.found() and ['auto', 'libgcrypt'].contains(hls_crypto)
     hls_cargs += ['-DHAVE_LIBGCRYPT']
   endif
 endif
-
+openssl_link_args = []
 if not hls_crypto_dep.found() and ['auto', 'openssl'].contains(hls_crypto)
-  hls_crypto_dep = dependency('openssl', required : false)
+  hls_crypto_dep = dependency('openssl', required : false, static: true)
   if hls_crypto_dep.found()
     hls_cargs += ['-DHAVE_OPENSSL']
+    openssl_link_args += ['-Wl,--exclude-libs,libssl.a -Wl,--exclude-libs,libcrypto.a']
   endif
 endif
 
@@ -55,7 +56,7 @@ endif
 gsthls = library('gsthls',
   hls_sources,
   c_args : gst_plugins_bad_args + hls_cargs,
-  link_args : noseh_link_args,
+  link_args : noseh_link_args + openssl_link_args,
   include_directories : [configinc],
   dependencies : [gstpbutils_dep, gsttag_dep, gstvideo_dep,
                   gstadaptivedemux_dep, gsturidownloader_dep,
diff --git a/subprojects/gst-plugins-bad/ext/meson.build b/subprojects/gst-plugins-bad/ext/meson.build
index 1e40ace7f3..2dc0c3213b 100644
--- a/subprojects/gst-plugins-bad/ext/meson.build
+++ b/subprojects/gst-plugins-bad/ext/meson.build
@@ -72,3 +72,4 @@ subdir('wpe')
 subdir('x265')
 subdir('zxing')
 subdir('zbar')
+subdir('videorender')
\ No newline at end of file
diff --git a/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.c b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.c
new file mode 100644
index 0000000000..e76510a82e
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.c
@@ -0,0 +1,1140 @@
+/*
+ * GStreamer
+ * Copyright (C) 2005 Thomas Vander Stichele <thomas@apestaart.org>
+ * Copyright (C) 2005 Ronald S. Bultje <rbultje@ronald.bitfreak.net>
+ * Copyright (C) 2023 root <<user@hostname.org>>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Alternatively, the contents of this file may be used under the
+ * GNU Lesser General Public License Version 2.1 (the "LGPL"), in
+ * which case the following provisions apply instead of the ones
+ * mentioned above:
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+/**
+ * SECTION:element-nativewindowsink
+ *
+ * FIXME:Describe nativewindowsink here.
+ *
+ * <refsect2>
+ * <title>Example launch line</title>
+ * |[
+ * gst-launch -v -m fakesrc ! nativewindowsink ! fakesink silent=TRUE
+ * ]|
+ * </refsect2>
+ */
+
+#ifdef HAVE_CONFIG_H
+#  include <config.h>
+#endif
+
+#include "gstnativewindowsink.h"
+#include <gst/video/video-frame.h>
+#include <gst/video/videodirection.h>
+#include <gst/gstsample.h>
+GST_DEBUG_CATEGORY_STATIC (gst_nativewindow_sink_debug);
+#define GST_CAT_DEFAULT gst_nativewindow_sink_debug
+
+enum
+{
+  PROP_0,
+  PROP_SILENT,
+  PROP_WINDOW_ID,
+  PROP_RENDER_OSD,
+  PROP_VIDEO_DIRECTION,
+  PROP_FIT,
+  PROP_CUM_EFFECT_MODE,
+  PROP_ORI_EFFECT,
+  PROP_CAPS,
+  PROP_FORCE_ASPECT_RATIO,
+  PROP_PIXEL_ASPECT_RATIO,
+  PROP_POS_X,
+  PROP_POS_Y,
+  PROP_POS_W,
+  PROP_POS_H,
+  PROP_SCALE_SX,
+  PROP_SCALE_SY,
+  PROP_MOVE_DX,
+  PROP_MOVE_DY,
+  PROP_ROTATION_DEGREE,
+  PROP_RENDER_DELAY,
+};
+
+/* wsink signals and args */
+enum
+{
+  SIGNAL_UNKNOWN_TYPE,
+  SIGNAL_BUFFER_READY,
+  LAST_SIGNAL
+};
+
+static guint gst_nativewindowsink_signals[LAST_SIGNAL] = { 0 };
+
+
+/* the capabilities of the inputs and outputs.
+ *
+ * describe the real formats here.
+ */
+#define GST_NATIVEWINDOW_SINK_CAPS \
+    "video/x-raw, "              \
+    "format = (string) RGBA, "                                          \
+    "width = " GST_VIDEO_SIZE_RANGE ", "                                \
+    "height = " GST_VIDEO_SIZE_RANGE ", "                               \
+    "framerate = " GST_VIDEO_FPS_RANGE ", "                             \
+    "interlace_mode = (string) progressive, "
+
+static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS (GST_NATIVEWINDOW_SINK_CAPS)
+    );
+
+static GstStaticPadTemplate src_factory = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("ANY")
+    );
+
+static void gst_nativewindow_sink_direction_init (GstVideoDirectionInterface * iface);
+static void gst_nativewindow_sink_video_overlay_init (GstVideoOverlayInterface * iface);
+static void gst_nativewindow_sink_navigation_interface_init (GstNavigationInterface * iface);
+static void gst_nativewindow_sink_reset (GstNativewindowSink * wsink);
+static void gst_nativewindow_sink_pos_reset (GstNativewindowSink * wsink); //坐标
+static void gst_nativewindow_sink_effect_reset (GstNativewindowSink * wsink); //效果
+static void gst_nativewindow_sink_release (GstNativewindowSink * wsink);
+static void gst_nativewindow_sink_set_window_info (GstNativewindowSink * wsink);
+static void _do_init_type (GType type)
+{
+  static const GInterfaceInfo ov_info = {
+    gst_nativewindow_sink_video_overlay_init,
+    NULL, NULL
+  };
+  static const GInterfaceInfo nav_info = {
+    gst_nativewindow_sink_navigation_interface_init,
+    NULL, NULL
+  };
+  static const GInterfaceInfo direction_info = {
+    gst_nativewindow_sink_direction_init,
+    NULL, NULL
+  };
+
+  g_type_add_interface_static (type, GST_TYPE_VIDEO_OVERLAY, &ov_info);
+  g_type_add_interface_static (type, GST_TYPE_NAVIGATION, &nav_info);
+  g_type_add_interface_static (type, GST_TYPE_VIDEO_DIRECTION, &direction_info);
+}
+
+#define gst_nativewindow_sink_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstNativewindowSink, gst_nativewindow_sink, GST_TYPE_VIDEO_SINK,
+    _do_init_type (g_define_type_id));
+#define _do_init \
+    GST_DEBUG_CATEGORY_INIT (gst_nativewindow_sink_debug, "nativewindowsink", 0, "video render");
+
+#define NATIVEWINDOW_SINK_RANK (GST_RANK_SECONDARY + 100)
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (nativewindowsink, "nativewindowsink", NATIVEWINDOW_SINK_RANK,
+    GST_TYPE_NATIVEWINDOW_SINK, _do_init);
+
+#define GST_NATIVEWINDOW_SINK_GET_LOCK(wsink) \
+  (GST_NATIVEWINDOW_SINK(wsink)->drawing_lock)
+#define GST_NATIVEWINDOW_SINK_LOCK(wsink) \
+  (g_mutex_lock(&GST_NATIVEWINDOW_SINK_GET_LOCK (wsink)))
+#define GST_NATIVEWINDOW_SINK_UNLOCK(wsink) \
+  (g_mutex_unlock(&GST_NATIVEWINDOW_SINK_GET_LOCK (wsink)))
+
+//static GstFlowReturn gst_nativewindow_sink_chain (GstPad * pad, GstObject * parent, GstBuffer * buf);
+static GstFlowReturn gst_nativewindow_sink_render(GstVideoSink * vsink, GstBuffer * buffer);
+static GstFlowReturn gst_nativewindow_sink_prepare(GstBaseSink * vsink, GstBuffer * buffer);
+static gboolean gst_nativewindow_sink_start(GstBaseSink * bsink);
+static gboolean gst_nativewindow_sink_stop(GstBaseSink * bsink);
+static gboolean gst_nativewindow_sink_event(GstBaseSink * bsink, GstEvent  * event);
+static gboolean gst_nativewindow_sink_set_caps (GstBaseSink * bsink, GstCaps * caps);
+static gboolean gst_nativewindow_sink_sink_event (GstPad * pad, GstObject * parent, GstEvent * event);
+static gboolean gst_nativewindow_sink_query (GstBaseSink * bsink, GstQuery * query);
+static gboolean ensure_nativewindow_setup (GstNativewindowSink * wsink);
+static void gst_nativewindow_sink_dispose(GObject * obj);
+static void gst_nativewindow_sink_finalize (GObject * object);
+static void gst_nativewindow_sink_on_close (GstNativewindowSink * wsink);
+static void gst_nativewindow_sink_expose (GstVideoOverlay * overlay);
+static void gst_nativewindow_sink_handle_events (GstVideoOverlay * overlay, gboolean handle_events);
+static void gst_nativewindow_sink_set_render_rectangle (GstVideoOverlay * overlay, gint x, gint y, gint width, gint height);
+static void gst_nativewindow_sink_set_window_handle (GstVideoOverlay * overlay, guintptr id);
+static void gst_nativewindow_sink_set_property (GObject * object, guint prop_id, const GValue * value, GParamSpec * pspec);
+static void gst_nativewindow_sink_get_property (GObject * object, guint prop_id, GValue * value, GParamSpec * pspec);
+static void gst_nativewindow_sink_get_times (GstBaseSink * bsink, GstBuffer * buf, GstClockTime * start, GstClockTime * end);
+static void gst_nativewindow_sink_navigation_send_event (GstNavigation * navigation, GstStructure * structure);
+static void gst_nativewindow_sink_set_orientation (GstNativewindowSink * wsink, GstVideoOrientationMethod method);
+static GstCaps * gst_nativewindow_sink_get_caps (GstBaseSink * bsink, GstCaps * filter);
+static GstStateChangeReturn gst_nativewindow_sink_change_state (GstElement * element, GstStateChange transition);
+static void gst_nativewindow_sink_get_nativewindow_obj (GstNativewindowSink * wsink);
+static gint32 gst_nativewindow_sink_conv_orientation (GstNativewindowSink * wsink, GstVideoOrientationMethod method);
+#define DEFAULT_ROTATE_METHOD GST_VIDEO_ORIENTATION_IDENTITY
+#define GST_TYPE_NATIVEWINDOW_ROTATE_METHOD (gst_nativewindow_rotate_method_get_type())
+
+static const GEnumValue rotate_methods[] = {
+  {GST_VIDEO_ORIENTATION_IDENTITY, "Identity (no rotation)", "none"},
+  {GST_VIDEO_ORIENTATION_90R, "Rotate clockwise 90 degrees", "clockwise"},
+  {GST_VIDEO_ORIENTATION_180, "Rotate 180 degrees", "rotate-180"},
+  {GST_VIDEO_ORIENTATION_90L, "Rotate counter-clockwise 90 degrees",
+      "counterclockwise"},
+  {GST_VIDEO_ORIENTATION_HORIZ, "Flip horizontally", "horizontal-flip"},
+  {GST_VIDEO_ORIENTATION_VERT, "Flip vertically", "vertical-flip"},
+  {GST_VIDEO_ORIENTATION_UL_LR,
+      "Flip across upper left/lower right diagonal", "upper-left-diagonal"},
+  {GST_VIDEO_ORIENTATION_UR_LL,
+      "Flip across upper right/lower left diagonal", "upper-right-diagonal"},
+  {GST_VIDEO_ORIENTATION_AUTO,
+      "Select rotate method based on image-orientation tag", "automatic"},
+  {0, NULL, NULL},
+};
+
+static GType
+gst_nativewindow_rotate_method_get_type (void)
+{
+  static GType rotate_method_type = 0;
+
+  if (!rotate_method_type) {
+    rotate_method_type = g_enum_register_static ("GstNativewindowRotateMethod",
+        rotate_methods);
+  }
+  return rotate_method_type;
+}
+
+/* initialize the nativewindowsink's class */
+static void
+gst_nativewindow_sink_class_init (GstNativewindowSinkClass * klass)
+{
+  GObjectClass * gobject_class;
+  GstElementClass * gstelement_class;
+  GstBaseSinkClass * gstbase_sink_class;
+  GstVideoSinkClass * gstvideo_sink_class;
+
+  gobject_class = (GObjectClass *) klass;
+  gstelement_class = (GstElementClass *) klass;
+  gstbase_sink_class = (GstBaseSinkClass *) klass;
+  gstvideo_sink_class = (GstVideoSinkClass *) klass;
+
+  gobject_class->set_property = gst_nativewindow_sink_set_property;
+  gobject_class->get_property = gst_nativewindow_sink_get_property;
+  gobject_class->finalize = gst_nativewindow_sink_finalize;
+  gstelement_class->query = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_query);
+  gstelement_class->change_state = gst_nativewindow_sink_change_state;
+
+
+  gst_nativewindowsink_signals[SIGNAL_BUFFER_READY] =
+      g_signal_new ("buffer-ready", G_TYPE_FROM_CLASS (klass),
+      G_SIGNAL_RUN_LAST, 0, NULL, NULL, NULL, G_TYPE_NONE, 0, G_TYPE_NONE);
+
+  g_object_class_install_property (gobject_class, PROP_RENDER_OSD,
+      g_param_spec_boolean ("render-osd", "RENDER OSD", "Render image to OSD layer",
+          FALSE, G_PARAM_READWRITE));
+
+  g_object_class_install_property (gobject_class, PROP_SILENT,
+      g_param_spec_boolean ("silent", "Silent", "Produce verbose output ?",
+          FALSE, G_PARAM_READWRITE));
+
+  g_object_class_install_property (gobject_class, PROP_CAPS,
+      g_param_spec_boxed ("caps", "Caps",
+          "The caps on which to stop decoding. (NULL = default)",
+          GST_TYPE_CAPS, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+#if 0
+  g_object_class_install_property (gobject_class, PROP_FORCE_ASPECT_RATIO,
+      g_param_spec_boolean ("force-aspect-ratio", "Force aspect ratio",
+          "When enabled, reverse caps negotiation (scaling) will respect "
+          "original aspect ratio", TRUE,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+#endif
+
+  g_object_class_install_property (gobject_class, PROP_CUM_EFFECT_MODE,
+      g_param_spec_boolean ("cum-effect-mode", "cum efecct mode", "rotate/scale/translate based on the previous frame effect",
+          TRUE, G_PARAM_READWRITE));
+
+  g_object_class_install_property (gobject_class, PROP_ORI_EFFECT,
+      g_param_spec_boolean ("ori-effect", "reset origin effect", "reset origin rotate/scale/translate effect",
+          FALSE, G_PARAM_READWRITE));
+
+  g_object_class_install_property (gobject_class, PROP_RENDER_DELAY,
+      g_param_spec_boolean ("render-delay", "delay render", "not to render until expose api",
+          FALSE, G_PARAM_READWRITE));
+
+  g_object_class_install_property (gobject_class, PROP_PIXEL_ASPECT_RATIO,
+      g_param_spec_string ("pixel-aspect-ratio", "Pixel Aspect Ratio",
+          "The pixel aspect ratio of the device", "1/1",
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_FIT,
+      g_param_spec_int ("fit", "Fit", "Set display scale fit mode",
+          0, 6, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_POS_X,
+      g_param_spec_int ("x", "X", "Set screen display pos to x",
+          -1, 3840, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_POS_Y,
+      g_param_spec_int ("y", "Y", "Set screen display pos to y",
+          -1, 2160, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_POS_W,
+      g_param_spec_int ("w", "Width", "Set screen display pos to w",
+          -1, 3840, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_POS_H,
+      g_param_spec_int ("h", "Height", "Set screen display pos to h",
+          -1, 2160, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_SCALE_SX,
+      g_param_spec_float ("sx", "scale x", "Scale screen display by sx",
+          0, 2.0, 1.0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_SCALE_SY,
+      g_param_spec_float ("sy", "scale y", "Scale screen display by sy",
+          0, 2.0, 1.0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_ROTATION_DEGREE,
+      g_param_spec_int ("rotation-degree", "rotate degree", "Rotate screen display by degrees",
+          0, 360, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_MOVE_DX,
+      g_param_spec_float ("dx", "dx offset", "Translate screen display by dx-offset",
+          -3840, 3840, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  g_object_class_install_property (G_OBJECT_CLASS (klass), PROP_MOVE_DY,
+      g_param_spec_float ("dy", "dy offset", "Translate screen display by dy-offset",
+          -2160, 2160, 0,
+          (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+  gst_element_class_set_metadata (gstelement_class, "VideoRender sink",
+      "Sink/Video", "A videosink based on ANativeWindow for Android",
+      "tcl");
+
+  gst_element_class_add_pad_template (gstelement_class,
+      gst_static_pad_template_get (&src_factory));
+  gst_element_class_add_pad_template (gstelement_class,
+      gst_static_pad_template_get (&sink_factory));
+
+  g_object_class_override_property (gobject_class, PROP_VIDEO_DIRECTION,
+      "video-direction");
+  gstbase_sink_class->event       = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_event);
+  gstvideo_sink_class->show_frame = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_render);
+  gstbase_sink_class->start       = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_start);
+  gstbase_sink_class->stop        = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_stop);
+  gstbase_sink_class->prepare     = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_prepare);
+  gstbase_sink_class->set_caps    = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_set_caps);
+  gstbase_sink_class->get_caps    = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_get_caps);
+  //gstbase_sink_class->get_times = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_get_times);
+  gstbase_sink_class->query = GST_DEBUG_FUNCPTR (gst_nativewindow_sink_query);
+}
+
+/* initialize the new element
+ * instantiate pads and add them to element
+ * set pad callback functions
+ * initialize instance structure
+ */
+static void
+gst_nativewindow_sink_init (GstNativewindowSink * wsink)
+{
+  GST_DEBUG ("gst_nativewindow_sink_init.\n");
+  wsink->sinkpad = gst_pad_new_from_static_template (&sink_factory, "sink");
+  gst_pad_set_event_function (wsink->sinkpad,
+      GST_DEBUG_FUNCPTR (gst_nativewindow_sink_sink_event));
+ // gst_pad_set_chain_function (wsink->sinkpad,\
+      GST_DEBUG_FUNCPTR (gst_nativewindow_sink_chain));
+  GST_PAD_SET_PROXY_CAPS (wsink->sinkpad);
+  gst_element_add_pad (GST_ELEMENT (wsink), wsink->sinkpad);
+
+  wsink->srcpad = gst_pad_new_from_static_template (&src_factory, "src");
+  GST_PAD_SET_PROXY_CAPS (wsink->srcpad);
+  gst_element_add_pad (GST_ELEMENT (wsink), wsink->srcpad);
+
+  g_mutex_init (&wsink->drawing_lock);
+
+  gst_nativewindow_sink_reset (wsink);
+  gst_nativewindow_sink_get_nativewindow_obj (wsink);
+}
+
+#if 0
+typedef enum {
+  GST_VIDEO_ORIENTATION_IDENTITY,
+  GST_VIDEO_ORIENTATION_90R,
+  GST_VIDEO_ORIENTATION_180,
+  GST_VIDEO_ORIENTATION_90L,
+  GST_VIDEO_ORIENTATION_HORIZ,
+  GST_VIDEO_ORIENTATION_VERT,
+  GST_VIDEO_ORIENTATION_UL_LR,
+  GST_VIDEO_ORIENTATION_UR_LL,
+  GST_VIDEO_ORIENTATION_AUTO,
+  GST_VIDEO_ORIENTATION_CUSTOM,
+} GstVideoOrientationMethod;
+#endif
+
+static gint32
+gst_nativewindow_sink_conv_orientation (GstNativewindowSink * wsink, GstVideoOrientationMethod method) {
+  gint32 rotate = 0;
+  switch (method) {
+    case GST_VIDEO_ORIENTATION_90R:
+      rotate = 90;
+      break;
+    case GST_VIDEO_ORIENTATION_180:
+      rotate = 180;
+      break;
+    case GST_VIDEO_ORIENTATION_90L:
+      rotate = 270;
+      break;
+  }
+
+  return rotate;
+}
+
+static gboolean
+gst_nativewindow_sink_event (GstBaseSink * sink, GstEvent * event)
+{
+  GstNativewindowSink *wsink = GST_NATIVEWINDOW_SINK (sink);
+  GstTagList *taglist = NULL;
+  GstVideoOrientationMethod method = GST_VIDEO_ORIENTATION_IDENTITY;
+  gboolean ret = FALSE;
+  gchar *r_flip = NULL;
+
+  GST_DEBUG_OBJECT (wsink, "handling %s event", GST_EVENT_TYPE_NAME (event));
+
+  switch (GST_EVENT_TYPE (event)) {
+    case GST_EVENT_TAG:
+      gst_event_parse_tag (event, &taglist);
+
+      if (gst_video_orientation_from_tag (taglist, &method)){
+        wsink->parse_rotation_degree = gst_nativewindow_sink_conv_orientation(wsink, method);
+      }
+      if (gst_tag_list_get_string (taglist, GST_TAG_IMAGE_ORIENTATION_FLIP, &r_flip) && r_flip && !g_strcmp0 ("rotate-180-horiz", r_flip)){
+        wsink->parse_rotation_degree = 180;
+        wsink->rotate_method = GST_VIDEO_ORIENTATION_HORIZ;
+        wsink->parse_rotation_method = GST_VIDEO_ORIENTATION_HORIZ;
+      }
+      if(r_flip){
+        g_free(r_flip);
+      }
+
+      break;
+    default:
+      break;
+  }
+  ret = GST_BASE_SINK_CLASS (parent_class)->event (sink, event);
+
+  return ret;
+}
+
+static void
+gst_nativewindow_sink_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstNativewindowSink *wsink = GST_NATIVEWINDOW_SINK (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+
+  switch (prop_id) {
+    case PROP_SILENT:
+      wsink->silent = g_value_get_boolean (value);
+      break;
+    case PROP_RENDER_OSD:
+      wsink->render_osd = g_value_get_boolean (value);
+      break;
+    case PROP_RENDER_DELAY:
+      wsink->render_delay = g_value_get_boolean (value);
+      break;
+    case PROP_CUM_EFFECT_MODE:
+      wsink->cum_effect_mode = g_value_get_boolean (value);
+      break;
+    case PROP_ORI_EFFECT:
+      wsink->ori_effect = g_value_get_boolean (value);
+      break;
+    case PROP_VIDEO_DIRECTION:
+      wsink->rotate_method = g_value_get_enum (value);
+      break;
+    case PROP_PIXEL_ASPECT_RATIO:
+    {
+      wsink->par_n = gst_value_get_fraction_numerator (value);
+      wsink->par_d = gst_value_get_fraction_denominator (value);
+      break;
+    }
+    case PROP_CAPS:
+      break;
+    case PROP_POS_X:
+    {
+      wsink->x = g_value_get_int (value);
+      break;
+    }
+    case PROP_POS_Y:
+    {
+      wsink->y = g_value_get_int (value);
+      break;
+    }
+    case PROP_POS_W:
+    {
+      wsink->w = g_value_get_int (value);
+      break;
+    }
+    case PROP_POS_H:
+    {
+      wsink->h = g_value_get_int (value);
+      break;
+    }
+    case PROP_SCALE_SX:
+    {
+      wsink->sx = g_value_get_float (value);
+      break;
+    }
+    case PROP_SCALE_SY:
+    {
+      wsink->sy = g_value_get_float (value);
+      break;
+    }
+    case PROP_MOVE_DX:
+    {
+      wsink->dx = g_value_get_float (value);
+      break;
+    }
+    case PROP_MOVE_DY:
+    {
+      wsink->dy = g_value_get_float (value);
+      break;
+    }
+    case PROP_ROTATION_DEGREE:
+    {
+      wsink->rotation_degree = g_value_get_int (value);
+      break;
+    }
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_nativewindow_sink_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+
+  switch (prop_id) {
+    case PROP_SILENT:
+      g_value_set_boolean (value, wsink->silent);
+      break;
+    case PROP_RENDER_OSD:
+      g_value_set_boolean (value, wsink->render_osd);
+      break;
+    case PROP_VIDEO_DIRECTION:
+      g_value_set_enum (value, wsink->rotate_method);
+      break;
+    case PROP_CAPS:
+      g_value_set_boxed (value, wsink->nativewindow_wrap->cur_caps);
+      break;
+    case PROP_FIT:
+      g_value_set_int (value, wsink->fit_mode);
+      break;
+    case PROP_PIXEL_ASPECT_RATIO:
+      gst_value_set_fraction (value, wsink->par_n, wsink->par_d);
+      break;
+    case PROP_POS_X:
+    {
+      g_value_set_int (value, wsink->x);
+      break;
+    }
+    case PROP_POS_Y:
+    {
+      g_value_set_int (value, wsink->y);
+      break;
+    }
+    case PROP_POS_W:
+    {
+      g_value_set_int (value, wsink->w);
+      break;
+    }
+    case PROP_POS_H:
+    {
+      g_value_set_int (value, wsink->h);
+      break;
+    }
+    case PROP_SCALE_SX:
+    {
+      g_value_set_float (value, wsink->sx);
+      break;
+    }
+    case PROP_SCALE_SY:
+    {
+      g_value_set_float (value, wsink->sy);
+      break;
+    }
+    case PROP_MOVE_DX:
+    {
+      g_value_set_float (value, wsink->dx);
+      break;
+    }
+    case PROP_MOVE_DY:
+    {
+      g_value_set_float (value, wsink->dy);
+      break;
+    }
+    case PROP_ROTATION_DEGREE:
+    {
+      g_value_set_float (value, wsink->rotation_degree);
+      break;
+    }
+    case PROP_RENDER_DELAY:
+    {
+      break;
+    }
+    case PROP_CUM_EFFECT_MODE:
+    {
+      break;
+    }
+    case PROP_ORI_EFFECT:
+    {
+      break;
+    }
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+/* this function handles sink events */
+static gboolean
+gst_nativewindow_sink_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
+{
+  GstNativewindowSink *wsink;
+  gboolean ret;
+
+  wsink = GST_NATIVEWINDOW_SINK (parent);
+
+  GST_LOG_OBJECT (wsink, "Received %s event: %" GST_PTR_FORMAT,
+      GST_EVENT_TYPE_NAME (event), event);
+
+  switch (GST_EVENT_TYPE (event)) {
+    case GST_EVENT_CAPS:
+    {
+      GstCaps *caps;
+      gst_event_parse_caps (event, &caps);
+      /* do something with the caps */
+
+      /* and forward */
+      ret = gst_pad_event_default (pad, parent, event);
+      break;
+    }
+    default:
+      ret = gst_pad_event_default (pad, parent, event);
+      break;
+  }
+  return ret;
+}
+
+static void
+gst_nativewindow_sink_video_overlay_init (GstVideoOverlayInterface * iface)
+{
+  iface->set_window_handle = gst_nativewindow_sink_set_window_handle;
+  iface->set_render_rectangle = gst_nativewindow_sink_set_render_rectangle;
+  iface->handle_events = gst_nativewindow_sink_handle_events;
+  iface->expose = gst_nativewindow_sink_expose;
+}
+
+static void
+gst_nativewindow_sink_navigation_interface_init (GstNavigationInterface * iface)
+{
+  iface->send_event = gst_nativewindow_sink_navigation_send_event;
+}
+
+static void
+gst_nativewindow_sink_navigation_send_event (GstNavigation * navigation, GstStructure
+    * structure)
+{
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (navigation);
+}
+
+static void
+gst_nativewindow_sink_set_window_handle (GstVideoOverlay * overlay, guintptr id)
+{
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+
+  GST_DEBUG ("set_window_id %" G_GUINT64_FORMAT, (guint64) id);
+  wsink->new_window_id = id;
+}
+
+static void //redraw
+gst_nativewindow_sink_expose (GstVideoOverlay * overlay)
+{
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink) && wsink->nativewindow_wrap);
+
+  g_mutex_lock(&wsink->drawing_lock);
+
+  gst_nativewindow_sink_set_window_info (wsink);
+  gst_nativewindow_wrap_setOriEffect(wsink->nativewindow_wrap, wsink->ori_effect);
+
+  if (wsink->buffer_ready) {
+      gst_video_overlay_expose (GST_VIDEO_OVERLAY (wsink->nativewindow_wrap));
+    } else {
+      wsink->render_delay = FALSE;
+  }
+
+  g_mutex_unlock(&wsink->drawing_lock);
+}
+
+static void
+gst_nativewindow_sink_set_render_rectangle (GstVideoOverlay * overlay,
+    gint x, gint y, gint width, gint height)
+{
+   GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (overlay);
+   g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+
+   wsink->surface_width = width;
+   wsink->surface_height = height;
+}
+
+static void
+gst_nativewindow_sink_handle_events (GstVideoOverlay * overlay, gboolean handle_events)
+{
+  GstNativewindowSink *wsink = GST_NATIVEWINDOW_SINK (overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  wsink->handle_events = handle_events;
+}
+
+static void
+gst_nativewindow_sink_get_nativewindow_obj (GstNativewindowSink * wsink)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  if (wsink->nativewindow_wrap == NULL) {
+      wsink->nativewindow_wrap = g_object_new (GST_TYPE_NATIVEWINDOW_WRAP, NULL);
+  }
+}
+
+static void
+gst_nativewindow_sink_set_window_info (GstNativewindowSink * wsink)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink) && wsink->nativewindow_wrap);
+
+  if (wsink->rotation_degree != 0) {
+    wsink->sx = 0;
+    wsink->sy = 0;
+  }
+  //gst_nativewindow_wrap_setDisplayPos (wsink->nativewindow_wrap, wsink->x, wsink->y, wsink->w, wsink->h);
+  gst_nativewindow_wrap_setTranslateOffset (wsink->nativewindow_wrap, wsink->dx, wsink->dy);
+  gst_nativewindow_wrap_setScaleFactor (wsink->nativewindow_wrap, wsink->sx, wsink->sy);
+  gst_nativewindow_wrap_setRotateDegree (wsink->nativewindow_wrap, wsink->rotation_degree);
+  gst_nativewindow_wrap_setRotateMethod (wsink->nativewindow_wrap, wsink->rotate_method);
+  gst_nativewindow_wrap_set_osd_render (wsink->nativewindow_wrap, wsink->render_osd);
+
+  gst_nativewindow_sink_effect_reset (wsink);
+}
+
+static gboolean
+ensure_nativewindow_setup (GstNativewindowSink * wsink)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink), FALSE);
+
+  if (!wsink->window_id && !wsink->new_window_id) {
+    gst_video_overlay_prepare_window_handle (GST_VIDEO_OVERLAY (wsink));
+    GST_DEBUG_OBJECT(wsink, "window_id not found error");
+    return FALSE;
+  }
+
+  GST_DEBUG_OBJECT (wsink, "window_id : %" G_GUINTPTR_FORMAT " , new_window_id : %"
+      G_GUINTPTR_FORMAT, wsink->window_id, wsink->new_window_id);
+
+  gst_nativewindow_sink_get_nativewindow_obj (wsink);
+
+  if (wsink->window_id != wsink->new_window_id && wsink->nativewindow_wrap) {
+      wsink->window_id = wsink->new_window_id;
+     // GST_DEBUG_OBJECT (wsink, "Setting window id %" G_GUINTPTR_FORMAT, wsink->window_id);
+      gst_video_overlay_set_window_handle(GST_VIDEO_OVERLAY(wsink->nativewindow_wrap), wsink->window_id);
+  }
+
+  GST_DEBUG_OBJECT (wsink, "setup nativewindow sucessfully");
+
+  return TRUE;
+}
+
+static gboolean
+gst_nativewindow_sink_start(GstBaseSink * bsink)
+{
+    GST_DEBUG ("gst_nativewindow_sink_start.\n");
+    return TRUE;
+}
+
+static gboolean
+gst_nativewindow_sink_stop(GstBaseSink * bsink)
+{
+    GST_DEBUG ("gst_nativewindow_sink_stop.\n");
+    return TRUE;
+}
+
+static GstStateChangeReturn
+gst_nativewindow_sink_change_state (GstElement * element, GstStateChange transition)
+{
+  GstNativewindowSink *wsink;
+  GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS;
+
+  GST_DEBUG ("changing state: %s => %s",
+      gst_element_state_get_name (GST_STATE_TRANSITION_CURRENT (transition)),
+      gst_element_state_get_name (GST_STATE_TRANSITION_NEXT (transition)));
+
+  wsink = GST_NATIVEWINDOW_SINK (element);
+
+  switch (transition) {
+    case GST_STATE_CHANGE_NULL_TO_READY:
+      break;
+    case GST_STATE_CHANGE_READY_TO_PAUSED:
+      if (!ensure_nativewindow_setup(wsink)){
+        return GST_STATE_CHANGE_FAILURE;
+      }
+      break;
+    case GST_STATE_CHANGE_PAUSED_TO_PLAYING:
+      break;
+    default:
+      break;
+  }
+
+  ret = GST_ELEMENT_CLASS (parent_class)->change_state (element, transition);
+  if (ret == GST_STATE_CHANGE_FAILURE)
+    return ret;
+
+  switch (transition) {
+    case GST_STATE_CHANGE_PLAYING_TO_PAUSED:
+      break;
+    case GST_STATE_CHANGE_PAUSED_TO_READY:
+    {
+      gst_nativewindow_sink_reset(wsink);
+      break;
+    }
+    case GST_STATE_CHANGE_READY_TO_NULL:
+      break;
+    default:
+      break;
+  }
+
+  return ret;
+}
+
+static GstFlowReturn
+gst_nativewindow_sink_prepare (GstBaseSink * bsink, GstBuffer * buf)
+{
+   /*chain func */
+  GST_DEBUG ("gst_nativewindow_sink_prepare buf!");
+  GstNativewindowSink *wsink = GST_NATIVEWINDOW_SINK(bsink);
+
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK(wsink), GST_FLOW_ERROR);
+  if(wsink->buffer_ready){
+    GST_WARNING("buffer is ready!");
+    return GST_FLOW_OK;
+  }
+  if (!ensure_nativewindow_setup(wsink)) {
+    GST_ERROR ("window handle has not been set yet！");
+    return GST_FLOW_ERROR;
+   }
+  g_mutex_lock(&wsink->drawing_lock);
+
+  //gst_nativewindow_wrap_setDisplayPos (wsink->nativewindow_wrap, wsink->x, wsink->y, wsink->w, wsink->h);
+  gst_nativewindow_wrap_setDisplaySurface(wsink->nativewindow_wrap, wsink->surface_width, wsink->surface_height);
+  gst_nativewindow_wrap_set_osd_render (wsink->nativewindow_wrap, wsink->render_osd);
+  //gst_nativewindow_sink_set_window_info (wsink);
+  gst_nativewindow_wrap_set_cum_effect_mode(wsink->nativewindow_wrap, wsink->cum_effect_mode);
+  gst_nativewindow_wrap_set_fit_mode(wsink->nativewindow_wrap, wsink->fit_mode);
+  gst_nativewindow_wrap_setParseRotateDegree(wsink->nativewindow_wrap, wsink->parse_rotation_degree);
+  gst_nativewindow_wrap_setParseRotateMethod(wsink->nativewindow_wrap, wsink->parse_rotation_method);
+
+  gst_nativewindow_wrap_prepare (wsink->nativewindow_wrap, wsink->in_caps, buf);
+
+  wsink->buffer_ready = TRUE;
+
+  g_signal_emit (wsink, gst_nativewindowsink_signals[SIGNAL_BUFFER_READY], 0, NULL);
+
+  g_mutex_unlock(&wsink->drawing_lock);
+
+  return GST_FLOW_OK;
+}
+
+static gboolean
+gst_nativewindow_sink_query (GstBaseSink * bsink, GstQuery * query)
+{
+  GstNativewindowSink *wsink = GST_NATIVEWINDOW_SINK (bsink);
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink), FALSE);
+  gboolean res = FALSE;
+
+  switch (GST_QUERY_TYPE (query)) {
+    default:
+      res = GST_BASE_SINK_CLASS (parent_class)->query (bsink, query);
+      break;
+  }
+
+  return res;
+}
+
+static GstFlowReturn
+gst_nativewindow_sink_render (GstVideoSink * vsink, GstBuffer * buffer)
+{
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (vsink);
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink), GST_FLOW_ERROR);
+
+  g_mutex_lock(&wsink->drawing_lock);
+
+  if (wsink->render_delay) {
+    g_mutex_unlock (&wsink->drawing_lock);
+    GST_DEBUG_OBJECT (wsink, "render_delay = %d", wsink->render_delay);
+    return GST_FLOW_OK;
+  }
+  gst_nativewindow_wrap_render_process(wsink->nativewindow_wrap, buffer, TRUE);
+
+  g_mutex_unlock(&wsink->drawing_lock);
+
+  return GST_FLOW_OK;
+}
+
+/* Finalize is called only once, dispose can be called multiple times.
+ * We use mutexes and don't reset stuff to NULL here so let's register
+ * as a finalize. */
+static void
+gst_nativewindow_sink_finalize (GObject * object)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (object));
+
+  GstNativewindowSink * wsink = GST_NATIVEWINDOW_SINK (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  gst_nativewindow_sink_release(wsink);
+
+  g_mutex_clear (&wsink->drawing_lock);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static gboolean
+gst_nativewindow_sink_set_caps (GstBaseSink * bsink, GstCaps * caps)
+{
+  GstNativewindowSink *wsink;
+  gboolean ret;
+  GstVideoInfo video_info;
+
+  GST_DEBUG_OBJECT (bsink, "set caps with %" GST_PTR_FORMAT, caps);
+
+  wsink = GST_NATIVEWINDOW_SINK (bsink);
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink), FALSE);
+
+  ret = gst_video_info_from_caps (&video_info, caps);
+
+  if (!ret)
+    return FALSE;
+  //GST_NATIVEWINDOW_SINK_LOCK(wsink);
+  wsink->in_caps = gst_caps_ref (caps);
+  wsink->video_info = video_info;
+
+  if (wsink->nativewindow_wrap) {
+    gst_nativewindow_wrap_set_caps (wsink->nativewindow_wrap, wsink->in_caps);
+  }
+  GST_VIDEO_SINK_WIDTH (wsink) = video_info.width;
+  GST_VIDEO_SINK_HEIGHT (wsink) = video_info.height;
+  //GST_NATIVEWINDOW_SINK_UNLOCK(wsink);
+
+  return ret;
+}
+
+static GstCaps *
+gst_nativewindow_sink_get_caps (GstBaseSink * bsink, GstCaps * filter)
+{
+  GstNativewindowSink * wsink;
+  GstCaps * caps;
+
+  wsink = GST_NATIVEWINDOW_SINK (bsink);
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink), NULL);
+
+  caps = gst_pad_get_pad_template_caps (GST_VIDEO_SINK_PAD (wsink));
+  if (filter) {
+    GstCaps *intersection;
+    intersection = gst_caps_intersect_full (filter, caps, GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (caps);
+    caps = intersection;
+  }
+
+  return caps;
+}
+
+#if 0
+static void
+gst_nativewindow_sink_get_times (GstBaseSink * bsink, GstBuffer * buf, GstClockTime * start, GstClockTime * end)
+{
+  GstNativewindowSink * wsink;
+  wsink = GST_NATIVEWINDOW_SINK (wsink);
+
+  if (GST_BUFFER_TIMESTAMP_IS_VALID (buf)) {
+    *start = GST_BUFFER_TIMESTAMP (buf);
+    if (GST_BUFFER_DURATION_IS_VALID (buf))
+      *end = *start + GST_BUFFER_DURATION (buf);
+    else {
+      if (GST_VIDEO_INFO_FPS_N (&wsink->video_info) > 0) {
+        *end = *start +
+            gst_util_uint64_scale_int (GST_SECOND,
+            GST_VIDEO_INFO_FPS_D (&wsink->video_info),
+            GST_VIDEO_INFO_FPS_N (&wsink->video_info));
+      }
+    }
+  }
+}
+#endif
+
+#if 0
+enum ScaleToFit {
+   Keep_FrmSize_ScaleToFit,
+  Fill_FrmDAR_ScaleToFit,
+  Fill_Full_ScaleToFit,
+  No_ScaleToFit
+};
+#endif
+
+static void
+gst_nativewindow_sink_reset (GstNativewindowSink * wsink)
+{
+  GST_DEBUG ("gst_nativewindow_sink_reset");
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK(wsink));
+  g_mutex_lock(&wsink->drawing_lock);
+  wsink->window_id = 0;
+  wsink->x = -1;
+  wsink->y = -1;
+  wsink->w = -1;
+  wsink->h = -1;
+  wsink->sx = 0;
+  wsink->sy = 0;
+  wsink->dx = 0;
+  wsink->dy = 0;
+  wsink->fit_mode = 0;
+  wsink->rotation_degree = 0;
+  wsink->parse_rotation_degree = 0;
+  wsink->rotate_method = GST_VIDEO_ORIENTATION_IDENTITY;
+  wsink->parse_rotation_method = GST_VIDEO_ORIENTATION_IDENTITY;
+  wsink->render_osd = FALSE;
+  wsink->render_delay = FALSE;
+  wsink->silent = FALSE;
+  wsink->cum_effect_mode = TRUE;
+  wsink->ori_effect = FALSE;
+  wsink->buffer_ready = FALSE;
+
+  /* Clear cached caps */
+  if (wsink->in_caps) {
+      gst_caps_unref (wsink->in_caps);
+      wsink->in_caps = NULL;
+  }
+
+  g_mutex_unlock(&wsink->drawing_lock);
+}
+
+static void
+gst_nativewindow_sink_pos_reset (GstNativewindowSink * wsink)
+{
+  GST_DEBUG ("gst_nativewindow_sink_pos_reset");
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  wsink->x = -1;
+  wsink->y = -1;
+  wsink->w = -1;
+  wsink->h = -1;
+}
+
+static void
+gst_nativewindow_sink_effect_reset (GstNativewindowSink * wsink)
+{
+  GST_DEBUG ("gst_nativewindow_sink_effect_reset");
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  wsink->sx = 0;
+  wsink->sy = 0;
+  wsink->dx = 0;
+  wsink->dy = 0;
+  wsink->rotation_degree = 0;
+  wsink->rotate_method = GST_VIDEO_ORIENTATION_IDENTITY;
+}
+
+static void
+gst_nativewindow_sink_release (GstNativewindowSink * wsink)
+{
+  GST_DEBUG ("gst_nativewindow_sink_reset");
+  g_return_if_fail (GST_IS_NATIVEWINDOW_SINK (wsink));
+  wsink->new_window_id = 0;
+  if (wsink->nativewindow_wrap) {
+    g_object_unref (wsink->nativewindow_wrap);
+    wsink->nativewindow_wrap = NULL;
+  }
+  gst_nativewindow_sink_reset (wsink);
+}
+
+static void
+gst_nativewindow_sink_direction_init (GstVideoDirectionInterface * iface)
+{
+  /* We implement the video-direction property */
+}
+
+/* entry point to initialize the plug-in
+ * initialize the plug-in itself
+ * register the element factories and other features
+ */
+static gboolean
+plugin_init (GstPlugin * plugin)
+{
+  /* debug category for filtering log messages
+   *
+   * exchange the string 'Template nativewindowsink' with your description
+   */
+  GST_DEBUG_CATEGORY_INIT (gst_nativewindow_sink_debug, "nativewindowsink",
+      0, "Template nativewindowsink");
+
+  return GST_ELEMENT_REGISTER (nativewindowsink, plugin);
+}
+/* PACKAGE: this is usually set by meson depending on some _INIT macro
+ * in meson.build and then written into and defined in config.h, but we can
+ * just set it ourselves here in case someone doesn't use meson to
+ * compile this code. GST_PLUGIN_DEFINE needs PACKAGE to be defined.
+ */
+#ifndef PACKAGE
+#define PACKAGE "nativewindowsink"
+#endif
+
+/* gstreamer looks for this structure to register nativewindowsinks
+ *
+ * exchange the string 'Template nativewindowsink' with your nativewindowsink description
+ */
+GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
+    GST_VERSION_MINOR,
+    nativewindowsink,
+    "nativewindow_sink",
+    plugin_init,
+    PACKAGE_VERSION, GST_LICENSE, GST_PACKAGE_NAME, GST_PACKAGE_ORIGIN)
diff --git a/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.h b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.h
new file mode 100644
index 0000000000..c19a93b119
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowsink.h
@@ -0,0 +1,140 @@
+/*
+ * GStreamer
+ * Copyright (C) 2005 Thomas Vander Stichele <thomas@apestaart.org>
+ * Copyright (C) 2005 Ronald S. Bultje <rbultje@ronald.bitfreak.net>
+ * Copyright (C) 2020 Niels De Graef <niels.degraef@gmail.com>
+ * Copyright (C) 2023 root <<user@hostname.org>>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Alternatively, the contents of this file may be used under the
+ * GNU Lesser General Public License Version 2.1 (the "LGPL"), in
+ * which case the following provisions apply instead of the ones
+ * mentioned above:
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+#ifndef __GST_NATIVEWINDOWSINK_H__
+#define __GST_NATIVEWINDOWSINK_H__
+
+#include <gst/gst.h>
+#include <gst/base/gstbasesink.h>
+#include <stdio.h>
+#include <errno.h>
+#include <string.h>
+#include <gst/video/videooverlay.h>
+#include <gst/video/gstvideosink.h>
+#include <gst/video/video.h>
+#include <gst/video/video-format.h>
+#include "gstnativewindowwrap.h"
+#include <gst/video/videoorientation.h>
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_NATIVEWINDOW_SINK (gst_nativewindow_sink_get_type())
+
+#define GST_NATIVEWINDOW_SINK(obj) \
+  (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_NATIVEWINDOW_SINK,GstNativewindowSink))
+#define GST_NATIVEWINDOW_SINK_CLASS(klass) \
+  (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_NATIVEWINDOW_SINK,GstNativewindowSinkClass))
+#define GST_IS_NATIVEWINDOW_SINK(obj) \
+  (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_NATIVEWINDOW_SINK))
+#define GST_IS_NATIVEWINDOW_SINK_CLASS(klass) \
+  (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_NATIVEWINDOW_SINK))
+#define GST_NATIVEWINDOW_SINK_CAST(obj) \
+  ((GstNativewindowSink *)obj)
+
+typedef struct _GstNativewindowSink      GstNativewindowSink;
+typedef struct _GstNativewindowSinkClass GstNativewindowSinkClass;
+
+struct _GstNativewindowSink
+{
+  GstVideoSink video_sink;
+
+  GstPad * sinkpad, * srcpad;
+
+  gboolean silent;
+  guintptr window_id;
+  guintptr new_window_id;
+
+  GstVideoInfo video_info;
+  GstCaps * in_caps;
+
+  FILE * fp;
+  gchar * dump_path;
+  gboolean dump_enable;
+
+  gboolean buffer_ready;
+  gint par_n, par_d;
+  gboolean handle_events;
+  GMutex drawing_lock;
+  gboolean ignore_alpha;
+  gboolean render_delay;
+  gboolean render_osd;
+  gboolean cum_effect_mode;
+  gboolean ori_effect;
+
+  GstNativewindowWrap * nativewindow_wrap;
+
+  GstVideoOrientationMethod rotate_method;
+  gint32 parse_rotation_degree;
+  GstVideoOrientationMethod parse_rotation_method;
+  gint32 fit_mode;
+  gfloat sx; //scale
+  gfloat sy;
+  gfloat dx; //translate
+  gfloat dy;
+  gint32 rotation_degree;
+  gint32 surface_width;
+  gint32 surface_height;
+  gint x; //display pos
+  gint y;
+  gint w;
+  gint h;
+};
+
+struct _GstNativewindowSinkClass
+{
+  GstVideoSinkClass video_sink_class;
+
+  GstPad * sinkpad, * srcpad;
+
+  gboolean silent;
+};
+
+GType gst_nativewindow_sink_get_type (void);
+GST_ELEMENT_REGISTER_DECLARE (nativewindowsink);
+
+G_END_DECLS
+
+#endif /* __GST_NATIVEWINDOWSINK_H__ */
diff --git a/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.c b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.c
new file mode 100644
index 0000000000..aa02dbdd8c
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.c
@@ -0,0 +1,1270 @@
+/*
+ * GStreamer
+ * Copyright (C) 2005 Thomas Vander Stichele <thomas@apestaart.org>
+ * Copyright (C) 2005 Ronald S. Bultje <rbultje@ronald.bitfreak.net>
+ * Copyright (C) 2023 root <<user@hostname.org>>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Alternatively, the contents of this file may be used under the
+ * GNU Lesser General Public License Version 2.1 (the "LGPL"), in
+ * which case the following provisions apply instead of the ones
+ * mentioned above:
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+/**
+ * SECTION:element-GstNativewindowWrap
+ *
+ * FIXME:Describe GstNativewindowWrap here.
+ *
+ * <refsect2>
+ * <title>Example launch line</title>
+ * |[
+ * gst-launch -v -m fakesrc ! GstNativewindowWrap ! fakesink silent=TRUE
+ * ]|
+ * </refsect2>7
+ * ''
+ */
+
+#ifdef HAVE_CONFIG_H
+#  include <config.h>
+#endif
+
+#include "gstnativewindowwrap.h"
+#include <gst/video/video-frame.h>
+#include <gst/video/video.h>
+#include <gst/video/video-format.h>
+//#include "common.h"
+#include <libpng16/png.h>
+#include <gmodule.h>
+#include <sys/system_properties.h>
+
+GST_DEBUG_CATEGORY_STATIC (gst_nativewindow_wrap_debug);
+#define GST_CAT_DEFAULT gst_nativewindow_wrap_debug
+
+static void gst_nativewindow_wrap_video_overlay_init (GstVideoOverlayInterface * iface);
+//static void gst_nativewindow_wrap_direction_init (GstVideoDirectionInterface * iface);
+static void _do_init_type (GType type)
+{
+  static const GInterfaceInfo ov_info = {
+    gst_nativewindow_wrap_video_overlay_init,
+    NULL, NULL
+  };
+  /*static const GInterfaceInfo direction_info = {
+    gst_nativewindow_wrap_direction_init,
+    NULL, NULL
+  };*/
+
+  g_type_add_interface_static (type, GST_TYPE_VIDEO_OVERLAY, &ov_info);
+  //g_type_add_interface_static (type, GST_TYPE_VIDEO_DIRECTION, &direction_info);
+
+  GST_DEBUG_CATEGORY_INIT (GST_CAT_DEFAULT, "nativewindowwrap", 0, "nativewindowwrap");
+}
+
+enum
+{
+  PROP_0,
+  PROP_SILENT,
+  //PROP_VIDEO_DIRECTION,
+  PROP_CAPS,
+};
+
+#define WIDTH_4K (3840)
+#define HEIGHT_4K (2160)
+
+#define gst_nativewindow_wrap_parent_class parent_class
+G_DEFINE_TYPE_WITH_CODE (GstNativewindowWrap, gst_nativewindow_wrap, GST_TYPE_OBJECT, G_ADD_PRIVATE(GstNativewindowWrap) _do_init_type(g_define_type_id));
+
+static gint32 (*render_player_create)(guintptr window, gint32 enable);
+static gint32 (*render_player_setDisplayPos)(guintptr id, gint32 x, gint32 y, gint32 w,gint32 h);
+static gint32 (*render_player_initDisplaySurface)(guintptr id, gint32 w,gint32 h);
+static gint32 (*render_player_setScaleToFit)(guintptr id, gint32 mode);
+static gint32 (*render_player_setData)(guintptr id, gint32 frameWidth, gint32 frameHeight, gint32 format, gsize len, guintptr data);
+static gint32 (*render_player_draw)(guintptr id);
+static gint32 (*render_player_draw_direct)(guintptr id);
+static gint32 (*render_player_reset)(guintptr id);
+static gint32 (*render_player_release)(guintptr id);
+static gint32 (*render_player_getSurfaceWH)(guintptr id, gint32 * w, gint32 * h);
+static gint32 (*render_player_scale)(guintptr id, gfloat sx , gfloat sy, gint32 show);
+static gint32 (*render_player_translate)(guintptr id, gfloat dx , gfloat dy, gint32 show);
+static gint32 (*render_player_flip)(guintptr id, guintptr rotation, gint32 show);
+static gint32 (*render_player_rotate)(guintptr id, gfloat degrees, gint32 show);
+static gint32 (*render_player_isInitDisplaySurface)(guintptr id, gint32 * ok);
+static gint32 (*render_player_create_new)(guintptr window, guintptr *id, gint32 enable);
+static gint32 (*render_player_fill_buffer)(guintptr id);
+static gint32 (*render_player_gen_matrix)(guintptr id);
+
+
+static void gst_nativewindow_wrap_class_init (GstNativewindowWrapClass * klass);
+static void gst_nativewindow_wrap_init (GstNativewindowWrap * filter);
+static void gst_nativewindow_wrap_finalize (GObject * object);
+static gboolean load_library_func (GstNativewindowWrapClass * klass, const gchar * library);
+static void gst_nativewindow_wrap_adjust_display_pos(GstNativewindowWrap * window);
+static void gst_nativewindow_wrap_send_message_async (GstNativewindowWrap * window,
+    GstNativeWindowWrapCB callback, gpointer data, GDestroyNotify destroy);
+static void gst_nativewindow_wrap_send_message_sync (GstNativewindowWrap * window,
+    GstNativeWindowWrapCB callback, gpointer data, GDestroyNotify destroy);
+static void gst_nativewindow_wrap_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec);
+static void gst_nativewindow_wrap_get_property (GObject * object, guint prop_id,
+     GValue * value, GParamSpec * pspec);
+static gboolean gst_nativewindow_wrap_draw (GstNativewindowWrap * window);
+static gpointer gst_nativewindow_wrap_create_thread (GstNativewindowWrap * window);
+static void gst_nativewindow_wrap_stop_thread (GstNativewindowWrap * window);
+static void gst_nativewindow_wrap_start_thread (GstNativewindowWrap * window);
+static void gst_nativewindow_wrap_dispose (GObject * object);
+static void gst_nativewindow_wrap_finalize (GObject * object);
+static void gst_nativewindow_wrap_pos_reset (GstNativewindowWrap * window);
+static void gst_nativewindow_wrap_effect_reset (GstNativewindowWrap * window);
+
+static GModule * module = NULL;
+#if defined(__LP64__)
+static const gchar * lib_nativewindoww_wrap = "/system_ext/lib64/libnativewindowwrap.so";
+#else
+static const gchar * lib_nativewindoww_wrap = "/system_ext/lib/libnativewindowwrap.so";
+#endif
+
+/* initialize the GstNativewindowWrap's class */
+static void
+gst_nativewindow_wrap_class_init (GstNativewindowWrapClass * klass)
+{
+  GObjectClass *gobject_class;
+  gobject_class = (GObjectClass *) klass;
+
+  gobject_class->dispose = GST_DEBUG_FUNCPTR(gst_nativewindow_wrap_dispose);
+  gobject_class->finalize = GST_DEBUG_FUNCPTR(gst_nativewindow_wrap_finalize);
+
+  gobject_class->set_property = gst_nativewindow_wrap_set_property;
+  gobject_class->get_property = gst_nativewindow_wrap_get_property;
+
+ // g_object_class_override_property (gobject_class, PROP_VIDEO_DIRECTION,\
+      "video-direction");
+
+  g_object_class_install_property (gobject_class, PROP_CAPS,
+    g_param_spec_boxed( "caps", "Caps", "The caps of the element",
+    gst_caps_get_type(), G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  load_library_func (klass, lib_nativewindoww_wrap);
+}
+/* initialize the new element
+ * instantiate pads and add them to element
+ * set pad callback functions
+ * initialize instance structure
+ */
+static void
+gst_nativewindow_wrap_init (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  window->priv = gst_nativewindow_wrap_get_instance_private (window);
+  GstNativewindowWrapClass * klass = GST_NATIVEWINDOW_WRAP_GET_CLASS(window);
+
+  g_mutex_init(&window->lock);
+  g_mutex_init(&window->loop_lock);
+  g_mutex_init (&window->priv->sync_message_lock);
+  g_cond_init (&window->priv->sync_message_cond);
+
+  window->priv->loop = NULL;
+  window->priv->main_context = NULL;
+  window->priv->thread = NULL;
+  window->loop_stop = FALSE;
+
+  gst_nativewindow_wrap_start_thread (window);
+  window->draw_cb = gst_nativewindow_wrap_draw;
+  window->priv->renderPlayerID = 0;
+  gst_nativewindow_wrap_reset (window);
+
+  window->dump_path = "/data/tcluniplayer";
+  gchar flg_png[PROPERTY_VALUE_MAX] = {0};
+  gchar flg_raw[PROPERTY_VALUE_MAX] = {0};
+  gchar path[PROPERTY_VALUE_MAX] = {0};
+  __system_property_get("media.uniplayer.dump.png", flg_png);
+  __system_property_get("media.uniplayer.dump.raw", flg_raw);
+  __system_property_get("media.uniplayer.dump.path", path);
+  if (strlen(path) > 0) {
+    window->dump_path = path;
+  }
+  window->dump_raw = (atoi(flg_raw) == 1);
+  window->dump_png = (atoi(flg_png) == 1);
+}
+
+static gboolean
+load_library_func (GstNativewindowWrapClass * klass, const gchar * library)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP_CLASS (klass) && library, FALSE);
+
+  module = g_module_open (library, G_MODULE_BIND_LOCAL);
+
+  if (!module) {
+    GST_ERROR_OBJECT (klass, "load %s failed, %s", library,g_module_error());
+    return FALSE;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_create",
+          (gpointer *) & render_player_create)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_create error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_create_new",
+          (gpointer *) & render_player_create_new)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_create_new error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_setDisplayPos",
+          (gpointer *) & render_player_setDisplayPos)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_setDisplayPos error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_initDisplaySurface",
+          (gpointer *) & render_player_initDisplaySurface)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_initDisplaySurface error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_isInitDisplaySurface",
+          (gpointer *) & render_player_isInitDisplaySurface)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_isInitDisplaySurface error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_setScaleToFit",
+          (gpointer *) & render_player_setScaleToFit)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_setScaleToFitMode error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_setData",
+          (gpointer *) & render_player_setData)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_setData error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_draw",
+          (gpointer *) & render_player_draw)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_draw error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_draw_direct",
+          (gpointer *) & render_player_draw_direct)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_draw_direct error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_reset",
+          (gpointer *) & render_player_reset)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_reset error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_release",
+          (gpointer *) & render_player_release)) {
+    GST_ERROR_OBJECT (klass, "load symbols render_wrap_release error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_getSurfaceWH",
+          (gpointer *) & render_player_getSurfaceWH)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_getHeight error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_scale",
+          (gpointer *) & render_player_scale)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_scale error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_flip",
+          (gpointer *) & render_player_flip)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_flip error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_translate",
+          (gpointer *) & render_player_translate)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_translate error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_rotate",
+          (gpointer *) & render_player_rotate)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_rotate error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_fill_buffer",
+          (gpointer *) & render_player_fill_buffer)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_fill_buffer error");
+    goto symbol_error;
+  }
+
+  if (!g_module_symbol (module, "render_wrap_gen_matrix",
+          (gpointer *) & render_player_gen_matrix)) {
+    GST_ERROR_OBJECT (klass, "load symbols  render_wrap_gen_matrix error");
+    goto symbol_error;
+  }
+
+  GST_DEBUG_OBJECT (klass,"load %s sucessfully", library);
+  return TRUE;
+
+symbol_error:
+  GST_ERROR_OBJECT (klass, "load symbols failed", library);
+  g_module_close (module);
+  module = NULL;
+
+  return FALSE;
+}
+
+static void
+gst_nativewindow_wrap_set_window_info (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  //gst_nativewindow_wrap_adjust_display_pos (window);
+  GST_DEBUG_OBJECT (window, "image effect info rotation = %d, flip = %d, sx = %f, sy = %f, dx = %f, dy = %f",window->priv->cur_image_effector.rotation_degree, window->priv->cur_image_effector.rotation_method, window->priv->cur_image_effector.sx,
+    window->priv->cur_image_effector.sy, window->priv->cur_image_effector.dx, window->priv->cur_image_effector.dy);
+  //render_player_setDisplayPos (window->priv->renderPlayerID, window->priv->cur_image_effector.x, window->priv->cur_image_effector.y, window->priv->cur_image_effector.w, window->priv->cur_image_effector.h);
+  render_player_rotate (window->priv->renderPlayerID, (gfloat)(window->priv->cur_image_effector.rotation_degree + window->parse_rotation_degree), FALSE);
+  render_player_scale (window->priv->renderPlayerID, window->priv->cur_image_effector.sx, window->priv->cur_image_effector.sy, FALSE);
+  render_player_translate (window->priv->renderPlayerID, window->priv->cur_image_effector.dx, window->priv->cur_image_effector.dy, FALSE);
+  render_player_flip (window->priv->renderPlayerID, window->priv->cur_image_effector.rotation_method, FALSE);
+}
+
+#define BYTES_NUM_FOR_COLOR  4
+static void
+dump_write_png_file(GstNativewindowWrap * window, guint8* data, guint width, guint height)
+{
+  gint         i, j;
+  guint        temp;
+  png_structp  png_ptr;
+  png_infop    info_ptr;
+  png_bytep*   row_pointers = NULL;
+
+  if (G_UNLIKELY(NULL == data))
+  {
+    GST_DEBUG("error: pixels_rgba is NULL");
+    return;
+  }
+
+  gchar file[PROPERTY_VALUE_MAX]  = {0};
+  gchar file_name[PROPERTY_VALUE_MAX]  = {0};
+  time_t timer        = time(NULL);
+  strftime (file_name, sizeof(file_name), "dump_%Y%m%d_%H%M%S.png", localtime(&timer));
+  sprintf (file,"%s/%s", window->dump_path, file_name);
+
+  /* create file */
+  FILE* fp = fopen(file, "wb");
+  if (!fp)
+  {
+    GST_DEBUG("[write_png_file] File %s could not be opened for writing", file_name);
+    return;
+  }
+  /* initialize stuff */
+  png_ptr = png_create_write_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);
+  if (!png_ptr)
+  {
+    GST_DEBUG("[write_png_file] png_create_write_struct failed");
+    fclose(fp);
+    return;
+  }
+  info_ptr = png_create_info_struct(png_ptr);
+  if (!info_ptr)
+  {
+    GST_DEBUG("[write_png_file] png_create_info_struct failed");
+    fclose(fp);
+    return;
+  }
+  if (setjmp(png_jmpbuf(png_ptr)))
+  {
+    GST_DEBUG("[write_png_file] Error during init_io");
+    fclose(fp);
+    return;
+  }
+  png_init_io(png_ptr, fp);
+  /* write header */
+  if (setjmp(png_jmpbuf(png_ptr)))
+  {
+    GST_DEBUG("[write_png_file] Error during writing header");
+    fclose(fp);
+    return;
+  }
+  png_set_IHDR(png_ptr, info_ptr, width, height, 8, PNG_COLOR_TYPE_RGB_ALPHA, PNG_INTERLACE_NONE, PNG_COMPRESSION_TYPE_BASE, PNG_FILTER_TYPE_BASE);
+  png_write_info(png_ptr, info_ptr);
+  /* write bytes */
+  if (setjmp(png_jmpbuf(png_ptr)))
+  {
+    GST_DEBUG("[write_png_file] Error during writing bytes");
+    fclose(fp);
+    return;
+  }
+  temp         = (BYTES_NUM_FOR_COLOR * width);
+  row_pointers = (png_bytep*)g_malloc0(height * sizeof(png_bytep));
+  if (!row_pointers)
+  {
+    fclose(fp);
+    return;
+  }
+  memset(row_pointers, 0x0, height * sizeof(png_bytep));
+  for (i = 0; i < height; i++)
+  {
+    row_pointers[i] = (png_bytep)g_malloc0(sizeof(png_byte) * temp);
+    if (row_pointers[i])
+    {
+      memset(row_pointers[i], 0x0, sizeof(png_byte) * temp);
+      guchar* texture_buffer  = data + i * width * BYTES_NUM_FOR_COLOR;
+      for(j = 0; j < temp; j  += BYTES_NUM_FOR_COLOR)
+      {
+        row_pointers[i][j]   = *(texture_buffer);       // red
+        row_pointers[i][j+1] = *(texture_buffer + 1) ;  // green
+        row_pointers[i][j+2] = *(texture_buffer + 2);   // blue
+        row_pointers[i][j+3] = *(texture_buffer + 3);   // alpha
+        texture_buffer      += BYTES_NUM_FOR_COLOR;
+      }
+    } else {
+      goto clean;
+    }
+  }
+  png_write_image(png_ptr, row_pointers);
+  /* end write */
+  if (setjmp(png_jmpbuf(png_ptr))) {
+    GST_DEBUG("[write_png_file] Error during end of write");
+    return;
+  }
+  png_write_end(png_ptr, NULL);
+
+clean:
+  /* cleanup heap allocation */
+  for (j = 0; j < height; j++)
+  {
+    if(row_pointers[j])
+      g_free(row_pointers[j]);
+  }
+  if (row_pointers)
+    g_free(row_pointers);
+  fclose(fp);
+}
+
+static void
+dump_write_raw_file(GstNativewindowWrap * window, guint8* data, gsize size)
+{
+  if (G_UNLIKELY(NULL == data))
+  {
+    GST_DEBUG("error: pixels_rgba is NULL");
+    return;
+  }
+
+  gchar file[PROPERTY_VALUE_MAX]  = {0};
+  gchar file_name[PROPERTY_VALUE_MAX]  = {0};
+  time_t timer        = time(NULL);
+  strftime(file_name, sizeof(file_name), "dump_%Y%m%d_%H%M%S.rbg", localtime(&timer));
+  sprintf(file,"%s/%s", window->dump_path, file_name);
+  /* create file */
+  FILE* fp = fopen(file, "wb");
+  if(!fp)
+  {
+    GST_DEBUG("[write_png_file] File %s could not be opened for writing", file_name);
+    return;
+  }
+
+  size_t bytes_written = fwrite(data, sizeof(guint8), size, fp);
+  if (bytes_written < size) {
+    GST_DEBUG("Failed to write all data to file\n");
+    goto clean;
+  }
+
+clean:
+  /* cleanup heap allocation */
+  if (fp)
+    fclose(fp);
+}
+
+static gboolean
+gst_nativewindow_wrap_sendData (GstNativewindowWrap * window)
+{
+  GstNativewindowWrapClass * klass = GST_NATIVEWINDOW_WRAP_GET_CLASS(window);
+
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP_CLASS(klass),  FALSE);
+  g_return_val_if_fail (window->cur_caps && window->cur_buffer, FALSE);
+
+  GstVideoFrame vframe;
+  GstVideoInfo vinfo;
+
+  gst_video_info_from_caps (&vinfo, window->cur_caps);
+
+  if (!gst_video_frame_map (&vframe, &vinfo, window->cur_buffer, GST_MAP_READ)) {
+    GST_ERROR_OBJECT (window, "could not map image");
+    return FALSE;
+  }
+
+  gint32 frame_width  = GST_VIDEO_INFO_WIDTH (&vinfo);
+  gint32 frame_height = GST_VIDEO_INFO_HEIGHT (&vinfo);
+  gint32 format = GST_VIDEO_INFO_FORMAT (&vinfo);
+  gint32 pixel_components = GST_VIDEO_INFO_N_COMPONENTS(&vinfo);
+
+  GST_DEBUG_OBJECT (window,"frameinfo size:%ld, flags:%d, res:%dx%d, interlace:%d, stride:%d, pixel_components:%d\n",\
+        vinfo.size, vinfo.flags, vinfo.width, vinfo.height, vinfo.interlace_mode, vinfo.stride[0], pixel_components);
+
+  guint8 * framebuf = (guint8 *)vframe.data[0];
+  gint32 stride = GST_VIDEO_INFO_PLANE_STRIDE(&vinfo, 0);
+
+  if (RET_OK != render_player_setData (window->priv->renderPlayerID, frame_width, frame_height, format, stride, framebuf)) {
+    GST_ERROR_OBJECT (window, "render_player_setData failed");
+    gst_video_frame_unmap (&vframe);
+    return FALSE;
+  }
+
+  if (window->dump_png)
+    dump_write_png_file (window, framebuf, frame_width, frame_height);
+  if (window->dump_raw)
+    dump_write_raw_file (window, framebuf, vinfo.size);
+
+  gst_video_frame_unmap (&vframe);
+
+  return TRUE;
+}
+
+static void
+gst_nativewindow_wrap_adjust_display_pos (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  window->priv->next_image_effector.x = (window->priv->next_image_effector.x == -1) ? 0 : window->priv->next_image_effector.x;
+  window->priv->next_image_effector.y = (window->priv->next_image_effector.y == -1) ? 0 : window->priv->next_image_effector.y;
+
+  window->priv->next_image_effector.w = (window->priv->next_image_effector.w == -1) ? window->frame_width : window->priv->next_image_effector.w;
+  window->priv->next_image_effector.h = (window->priv->next_image_effector.h == -1) ? window->frame_height : window->priv->next_image_effector.h;
+}
+
+static void
+gst_nativewindow_wrap_get_frameWH (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+  GstVideoInfo vinfo;
+  gst_video_info_from_caps (&vinfo , window->cur_caps);
+  window->frame_width = GST_VIDEO_INFO_WIDTH (&vinfo);
+  window->frame_height = GST_VIDEO_INFO_HEIGHT (&vinfo);
+  GST_DEBUG_OBJECT (window, "cur frame w*h = %dx%d", window->frame_width, window->frame_height );
+}
+
+gboolean
+gst_nativewindow_wrap_prepare (GstNativewindowWrap * window, GstCaps * caps, GstBuffer * buffer)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  if (!buffer) {
+      GST_ERROR_OBJECT (window,"cur_buffer is invalid");
+      return FALSE;
+  }
+
+  if (window->cur_buffer != buffer) {
+    gst_buffer_unref (window->cur_buffer);
+    window->cur_buffer = gst_buffer_ref(buffer);
+  } else {
+    return TRUE;
+  }
+
+  if (!gst_caps_is_equal (caps, window->cur_caps)) {
+    gst_caps_unref (window->cur_caps );
+    window->cur_caps = gst_caps_ref(caps);
+  }
+
+  if (window->priv->renderPlayerID == 0) {
+    if(RET_OK != render_player_create_new (window->priv->window_id, &window->priv->renderPlayerID,window->priv->render_osd)) {
+      GST_ERROR_OBJECT (window, "create renderplayer failed id = %" G_GUINT64_FORMAT, (guint64)window->priv->renderPlayerID);
+      return FALSE;
+    }
+  }
+
+  GST_DEBUG_OBJECT (window, "renderplayer id = %" G_GUINT64_FORMAT, (guint64)window->priv->renderPlayerID);
+  GST_DEBUG_OBJECT (window, "DisplaySurface wxh = %dx%d", window->priv->surface_width, window->priv->surface_height);
+
+  if (!window->priv->init_surface) {
+    render_player_isInitDisplaySurface (window->priv->renderPlayerID, &window->priv->init_surface);
+    render_player_setDisplayPos (window->priv->renderPlayerID, 0, 0,window->priv->surface_width, window->priv->surface_height);
+    if (!window->priv->init_surface && RET_OK != render_player_initDisplaySurface (window->priv->renderPlayerID, WIDTH_4K, HEIGHT_4K)) {
+      GST_ERROR_OBJECT (window, "render_player_initDisplaySurface failed, renderplayer id = %d", window->priv->renderPlayerID);
+      return FALSE;
+    }
+    render_player_setScaleToFit(window->priv->renderPlayerID, window->priv->fit_mode);
+  }
+
+  GST_DEBUG_OBJECT (window, "render_osd = %d fit_mode = %d", window->priv->render_osd, window->priv->fit_mode);
+
+  gst_nativewindow_wrap_get_frameWH (window);
+
+  if (!gst_nativewindow_wrap_sendData (window)) {
+    return FALSE;
+  }
+
+  render_player_gen_matrix(window->priv->renderPlayerID);
+  render_player_fill_buffer(window->priv->renderPlayerID);
+
+  return TRUE;
+}
+
+static gboolean
+gst_nativewindow_wrap_draw (GstNativewindowWrap * window)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  if (RET_OK != render_player_draw_direct (window->priv->renderPlayerID)) {
+      GST_ERROR_OBJECT (window, "render_player_draw failed");
+      return FALSE;
+  }
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_render_process (GstNativewindowWrap * window, GstBuffer * buffer, gboolean is_sync)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window), FALSE);
+
+  if (is_sync) {
+    gst_nativewindow_wrap_send_message_sync (window, window->draw_cb, window, NULL);
+  } else {
+    gst_nativewindow_wrap_send_message_async (window, window->draw_cb, window, NULL);
+  }
+
+  return GST_FLOW_OK;
+}
+
+typedef struct _GstAsyncMessage
+{
+  GstNativeWindowWrapCB callback;
+  gpointer data;
+  GDestroyNotify destroy;
+} GstAsyncMessage;
+
+static gboolean
+_run_message_async (GstAsyncMessage * message)
+{
+  if (!message)
+    return FALSE;
+
+  if (message->callback)
+    message->callback (message->data);
+
+  g_slice_free (GstAsyncMessage, message);
+
+  return FALSE;
+}
+
+static void
+gst_nativewindow_wrap_send_message_async (GstNativewindowWrap * window,
+    GstNativeWindowWrapCB callback, gpointer data, GDestroyNotify destroy)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+  GstAsyncMessage * message = g_slice_new (GstAsyncMessage);
+
+  message->callback = callback;
+  message->data = data;
+  message->destroy = destroy;
+  GST_DEBUG_OBJECT (window, "gst_nativewindow_wrap_send_message_async");
+  g_main_context_invoke (window->priv->main_context, (GSourceFunc)_run_message_async, message);
+}
+
+typedef struct _GstSyncMessage
+{
+  GstNativewindowWrap * window;
+  GstNativeWindowWrapCB callback;
+  gpointer data;
+  GDestroyNotify destroy;
+  gboolean fired;
+} GstSyncMessage;
+
+static void
+_run_message_sync (GstSyncMessage * message)
+{
+  if (!message)
+    return;
+
+  if (message->callback)
+    message->callback (message->data);
+
+  g_mutex_lock (&message->window->priv->sync_message_lock);
+  message->fired = TRUE;
+  g_cond_broadcast (&message->window->priv->sync_message_cond);
+  g_mutex_unlock (&message->window->priv->sync_message_lock);
+
+  g_slice_free (GstAsyncMessage, message);
+}
+
+static void
+gst_nativewindow_wrap_send_message_sync (GstNativewindowWrap * window,
+    GstNativeWindowWrapCB callback, gpointer data, GDestroyNotify destroy)
+{
+  GstSyncMessage message;
+
+  message.window = window;
+  message.callback = callback;
+  message.data = data;
+  message.fired = FALSE;
+
+  gst_nativewindow_wrap_send_message_async (window, (GstNativeWindowWrapCB) _run_message_sync,
+      &message, NULL);
+
+  g_mutex_lock (&window->priv->sync_message_lock);
+
+  while (!message.fired)
+    g_cond_wait (&window->priv->sync_message_cond, &window->priv->sync_message_lock);
+
+  g_mutex_unlock (&window->priv->sync_message_lock);
+}
+
+static gpointer
+gst_nativewindow_wrap_create_thread (GstNativewindowWrap * window)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP(window) && window->priv, FALSE);
+  g_mutex_lock(&window->loop_lock);
+  window->priv->main_context = g_main_context_new ();
+  window->priv->loop = g_main_loop_new (window->priv->main_context, FALSE);
+  g_mutex_unlock(&window->loop_lock);
+  //g_main_context_push_thread_default(window->main_context);
+  GST_ERROR_OBJECT (window, "create loop thread");
+  g_main_loop_run (window->priv->loop);
+  window->loop_stop = TRUE;
+}
+
+static void
+gst_nativewindow_wrap_start_thread (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP(window) && window->priv);
+
+  gchar *name;
+  name = g_strdup_printf ("%s", GST_OBJECT_NAME (window));
+  window->priv->thread = g_thread_new (name, (GThreadFunc) gst_nativewindow_wrap_create_thread, window);
+  g_free (name);
+}
+
+static void
+gst_nativewindow_wrap_stop_thread (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+  g_mutex_lock(&window->loop_lock);
+  if (window->priv->loop) {
+    g_main_loop_quit (window->priv->loop);
+  }
+  GST_ERROR_OBJECT (window, "wait loop thread quit");
+  guint count = 0;
+  while(count < 10 && window->loop_stop == FALSE && window->priv->loop) {
+      usleep(50 * 1000);
+      count++;
+      g_main_loop_quit(window->priv->loop);
+  }
+  if (window->priv->thread && window->priv->loop) {
+    g_thread_join (window->priv->thread);
+    g_thread_unref (window->priv->thread);
+    GST_ERROR_OBJECT (window, "loop thread quit ok");
+    window->priv->thread = NULL;
+  }
+  if (window->priv->loop) {
+    g_main_loop_unref (window->priv->loop);
+    window->priv->loop = NULL;
+  }
+
+  if (window->priv->main_context) {
+    g_main_context_unref (window->priv->main_context);
+    window->priv->main_context = NULL;
+  }
+  g_mutex_unlock(&window->loop_lock);
+}
+
+static void
+gst_nativewindow_wrap_dispose (GObject * object)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  gst_nativewindow_wrap_stop_thread (window);
+  if (window->priv && window->priv->renderPlayerID != 0) {
+    GST_ERROR_OBJECT (window, "playerid = %" G_GUINT64_FORMAT, (guint64)window->priv->renderPlayerID);
+    window->clear = render_player_release (window->priv->renderPlayerID);
+  }
+  gst_nativewindow_wrap_reset (window);
+  g_mutex_clear (&window->priv->sync_message_lock);
+  g_cond_clear (&window->priv->sync_message_cond);
+  G_OBJECT_CLASS (parent_class)->dispose (object);
+}
+
+static void
+gst_nativewindow_wrap_finalize (GObject * object)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+  GST_DEBUG_OBJECT (parent_class, "finalize");
+
+  if (window->clear == RET_OK && module) {
+    g_module_close (module);
+    module = NULL;
+  }
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+void
+gst_nativewindow_wrap_reset (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP(window));
+  GST_DEBUG_OBJECT (window, "reset");
+
+  g_mutex_lock(&window->lock);
+
+  if (window->cur_buffer) {
+    gst_clear_buffer (&window->cur_buffer);
+    window->cur_buffer = NULL;
+  }
+  if (window->cur_caps) {
+    gst_clear_caps (window->cur_caps);
+    window->cur_caps = NULL;
+  }
+
+  window->clear = -1;
+  window->dump_png = FALSE;
+  window->ori_effect = FALSE;
+  window->parse_rotation_degree = 0;
+  window->parse_rotation_method = GST_VIDEO_ORIENTATION_IDENTITY;
+
+  if (window->priv) {
+    window->priv->window_id = 0;
+    window->priv->renderPlayerID = 0;
+    window->priv->cum_effect_Mode = FALSE;
+    window->priv->render_osd = FALSE;
+    window->priv->render_delay = FALSE;
+    window->priv->init_surface = 0;
+    window->priv->next_image_effector.rotation_degree = 0;
+    window->priv->next_image_effector.rotation_method = GST_VIDEO_ORIENTATION_IDENTITY;
+    window->priv->next_image_effector.x = -1;
+    window->priv->next_image_effector.y = -1;
+    window->priv->next_image_effector.w = -1;
+    window->priv->next_image_effector.h = -1;
+    window->priv->next_image_effector.sx = 0;
+    window->priv->next_image_effector.sy = 0;
+    window->priv->next_image_effector.dx = 0;
+    window->priv->next_image_effector.dy = 0;
+    window->priv->cur_image_effector = window->priv->next_image_effector;
+  }
+
+  g_mutex_unlock(&window->lock);
+}
+#if 0
+static void
+gst_nativewindow_wrap_pos_reset (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+  if (window->priv) {
+    window->priv->next_image_effector.x = -1;
+    window->priv->next_image_effector.y = -1;
+    window->priv->next_image_effector.w = -1;
+    window->priv->next_image_effector.h = -1;
+  }
+}
+
+void set_sample(GstNativewindowWrap * window, GstSample *sample){
+
+  GST_DEBUG_OBJECT (window, "set_sample");
+  window->last_sample = gst_sample_ref(sample);
+}
+#endif
+
+static void
+gst_nativewindow_wrap_effect_reset (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  if (window->priv) {
+    window->priv->next_image_effector.rotation_degree = 0;
+    window->priv->next_image_effector.rotation_method = GST_VIDEO_ORIENTATION_IDENTITY;
+    window->priv->next_image_effector.sx = 0;
+    window->priv->next_image_effector.sy = 0;
+    window->priv->next_image_effector.dx = 0;
+    window->priv->next_image_effector.dy = 0;
+  }
+}
+
+static void
+gst_nativewindow_wrap_effect_ori (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  if (window->priv) {
+    window->priv->cur_image_effector.rotation_degree = 0;
+    window->priv->cur_image_effector.rotation_method = GST_VIDEO_ORIENTATION_IDENTITY;
+    if(window->parse_rotation_method != GST_VIDEO_ORIENTATION_IDENTITY){
+       window->priv->cur_image_effector.rotation_method = window->parse_rotation_method;
+    }
+    window->priv->cur_image_effector.sx = 0;
+    window->priv->cur_image_effector.sy = 0;
+    window->priv->cur_image_effector.dx = 0;
+    window->priv->cur_image_effector.dy = 0;
+  }
+}
+
+gboolean
+gst_nativewindow_wrap_setRotateMethod (GstNativewindowWrap * window,
+    GstVideoOrientationMethod method)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->next_image_effector.rotation_method = method;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setDisplayPos (GstNativewindowWrap * window, gint32 x, gint32 y, gint32 w, gint32 h)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->next_image_effector.x = x;
+  window->priv->next_image_effector.y = y;
+  window->priv->next_image_effector.w = w;
+  window->priv->next_image_effector.h = h;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setDisplaySurface (GstNativewindowWrap * window, gint32 w, gint32 h)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->surface_width = w;
+  window->priv->surface_height = h;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setTranslateOffset (GstNativewindowWrap * window, gfloat dx, gfloat dy)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->next_image_effector.dx = dx;
+  window->priv->next_image_effector.dy = dy;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setScaleFactor (GstNativewindowWrap * window, gfloat sx, gfloat sy)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->next_image_effector.sx = sx;
+  window->priv->next_image_effector.sy = sy;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setRotateDegree (GstNativewindowWrap * window, gint32 degree){
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->next_image_effector.rotation_degree = degree;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setParseRotateDegree (GstNativewindowWrap * window, gint32 degree){
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->parse_rotation_degree = degree;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setParseRotateMethod (GstNativewindowWrap * window,
+    GstVideoOrientationMethod method){
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->parse_rotation_method = method;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_setOriEffect (GstNativewindowWrap * window, gboolean enable){
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->ori_effect = enable;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_set_osd_render (GstNativewindowWrap * window, gboolean enable)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window), FALSE);
+
+  window->priv->render_osd = enable;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_set_delay_render (GstNativewindowWrap * window, gboolean enable)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv, FALSE);
+
+  window->priv->render_delay = enable;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_set_fit_mode (GstNativewindowWrap * window, gint32 mode)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP(window) && window->priv, FALSE);
+
+  window->priv->fit_mode = mode;
+
+  return TRUE;
+}
+
+gboolean
+gst_nativewindow_wrap_set_cum_effect_mode (GstNativewindowWrap * window, gboolean mode)
+{
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP(window) && window->priv, FALSE);
+
+  window->priv->cum_effect_Mode = mode;
+
+  return TRUE;
+}
+
+static void
+gst_nativewindow_wrap_set_window_handle (GstVideoOverlay * overlay, guintptr id)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  GST_DEBUG ("set_window_id %" G_GUINT64_FORMAT, (guint64) id);
+
+  window->priv->window_id = id;
+}
+
+static void
+gst_nativewindow_wrap_cum_effect_flip (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  FlipOrientation cur_Orientation = (FlipOrientation)window->priv->cur_image_effector.rotation_method;
+  FlipOrientation nxt_Orientation = (FlipOrientation)window->priv->next_image_effector.rotation_method;
+  GST_DEBUG_OBJECT (window, "image effect info flip curorientation = %d, nxtorientation = %d", cur_Orientation, nxt_Orientation);
+
+  if (cur_Orientation == nxt_Orientation) {
+    window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_IDENTITY;
+    return;
+  }
+
+  switch (cur_Orientation) {
+    case FLIP_ORIENTATION_HORIZ :
+    {
+      if (nxt_Orientation== FLIP_ORIENTATION_VERT) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_HORIZ_VERT;
+      } else if (nxt_Orientation == FLIP_ORIENTATION_HORIZ_VERT) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_VERT;
+      }
+      break;
+    }
+    case FLIP_ORIENTATION_VERT :
+    {
+      if (nxt_Orientation == FLIP_ORIENTATION_HORIZ) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_HORIZ_VERT;
+      } else if (nxt_Orientation == FLIP_ORIENTATION_HORIZ_VERT) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_HORIZ;
+      }
+      break;
+    }
+    case FLIP_ORIENTATION_HORIZ_VERT :
+    {
+      if (nxt_Orientation == FLIP_ORIENTATION_HORIZ) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_VERT;
+      } else if (nxt_Orientation == FLIP_ORIENTATION_VERT) {
+        window->priv->cur_image_effector.rotation_method = FLIP_ORIENTATION_HORIZ;
+      }
+      break;
+    }
+    default:
+      window->priv->cur_image_effector.rotation_method = window->priv->next_image_effector.rotation_method;
+      break;
+  }
+}
+
+static void
+gst_nativewindow_wrap_cum_effect (GstNativewindowWrap * window)
+{
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  if (!window->priv->cum_effect_Mode) {
+    window->priv->cur_image_effector = window->priv->next_image_effector;
+    return;
+  }
+
+  window->priv->cur_image_effector.sx = window->priv->next_image_effector.sx;
+  window->priv->cur_image_effector.sy = window->priv->next_image_effector.sy;
+
+  window->priv->cur_image_effector.dx += window->priv->next_image_effector.dx;
+  window->priv->cur_image_effector.dy += window->priv->next_image_effector.dy;
+
+  window->priv->cur_image_effector.rotation_degree += window->priv->next_image_effector.rotation_degree;
+
+  gst_nativewindow_wrap_cum_effect_flip (window);
+}
+
+static gboolean check_effect(GstNativewindowWrap * window){
+    if (window->priv) {
+      return (window->priv->cur_image_effector.rotation_degree != 0 ||
+        window->parse_rotation_method != GST_VIDEO_ORIENTATION_IDENTITY ||
+        window->parse_rotation_degree != 0 ||
+        window->priv->cur_image_effector.sx != 0 ||
+        window->priv->cur_image_effector.sy != 0 ||
+        window->priv->cur_image_effector.dx != 0 ||
+        window->priv->cur_image_effector.dy != 0);
+    }
+
+    return FALSE;
+}
+
+static void //redraw after chain
+gst_nativewindow_wrap_expose (GstVideoOverlay * overlay)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP(overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+  GST_DEBUG_OBJECT (window, "gst_nativewindow_wrap_expose ori_effect = %d",window->ori_effect);
+
+  if (window->priv->renderPlayerID != 0) {
+    gst_nativewindow_wrap_cum_effect (window);
+    gboolean ori_flg = check_effect(window);
+    if(window->ori_effect){
+      gst_nativewindow_wrap_effect_ori(window);
+    }
+    gst_nativewindow_wrap_set_window_info (window);
+    if(ori_flg){
+      GST_DEBUG_OBJECT (window, "redo gen_matrix and fill_buffer");
+      render_player_gen_matrix(window->priv->renderPlayerID);
+      render_player_fill_buffer(window->priv->renderPlayerID);
+    }
+
+    gst_nativewindow_wrap_effect_reset(window);
+    gst_nativewindow_wrap_send_message_async (window, window->draw_cb, window, NULL);
+    return;
+  }
+
+  GST_ERROR_OBJECT (window, "renderPlayer not been created");
+}
+
+static void
+gst_nativewindow_wrap_set_render_rectangle (GstVideoOverlay * overlay,
+    gint32 x, gint32 y, gint32 width, gint32 height)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (overlay);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window) && window->priv);
+
+  window->priv->next_image_effector.x = x;
+  window->priv->next_image_effector.y = y;
+  window->priv->next_image_effector.w = width;
+  window->priv->next_image_effector.h = height;
+}
+
+static void
+gst_nativewindow_wrap_handle_events (GstVideoOverlay * overlay, gboolean handle_events)
+{
+ /* do nothing */
+}
+
+static void
+gst_nativewindow_wrap_video_overlay_init (GstVideoOverlayInterface * iface)
+{
+  g_return_if_fail (iface);
+
+  iface->set_window_handle = gst_nativewindow_wrap_set_window_handle;
+  iface->set_render_rectangle = gst_nativewindow_wrap_set_render_rectangle;
+  iface->handle_events = gst_nativewindow_wrap_handle_events;
+  iface->expose = gst_nativewindow_wrap_expose;
+}
+#if 0
+static void
+gst_nativewindow_wrap_direction_init (GstVideoDirectionInterface * iface)
+{
+  /* We implement the video-direction property */
+}
+#endif
+static void
+gst_nativewindow_wrap_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  switch (prop_id) {
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_nativewindow_wrap_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec)
+{
+  GstNativewindowWrap * window = GST_NATIVEWINDOW_WRAP (object);
+  g_return_if_fail (GST_IS_NATIVEWINDOW_WRAP (window));
+
+  switch (prop_id) {
+    case PROP_CAPS:
+      g_value_set_boxed (value, window->cur_caps);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+gboolean
+gst_nativewindow_wrap_set_caps (GstNativewindowWrap * window, GstCaps * caps){
+  g_return_val_if_fail (GST_IS_NATIVEWINDOW_WRAP (window), FALSE);
+
+  if(!gst_caps_is_equal(caps, window->cur_caps)){
+    gst_caps_unref(window->cur_caps);
+    window->cur_caps = gst_caps_ref(caps);
+  }
+  GST_DEBUG_OBJECT (window, "set caps with %" GST_PTR_FORMAT, window->cur_caps);
+}
+
diff --git a/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.h b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.h
new file mode 100644
index 0000000000..023c1bbc86
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/videorender/gstnativewindowwrap.h
@@ -0,0 +1,177 @@
+/*
+ * GStreamer
+ * Copyright (C) 2005 Thomas Vander Stichele <thomas@apestaart.org>
+ * Copyright (C) 2005 Ronald S. Bultje <rbultje@ronald.bitfreak.net>
+ * Copyright (C) 2020 Niels De Graef <niels.degraef@gmail.com>
+ * Copyright (C) 2023 root <<user@hostname.org>>
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ *
+ * Alternatively, the contents of this file may be used under the
+ * GNU Lesser General Public License Version 2.1 (the "LGPL"), in
+ * which case the following provisions apply instead of the ones
+ * mentioned above:
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA.
+ */
+
+#ifndef __GST_GstNativewindowWrap_H__
+#define __GST_GstNativewindowWrap_H__
+
+#include <gst/gst.h>
+//#include "common.h"
+#include "android/rect.h"
+#include <gst/video/video-info.h>
+#include <gst/gstsample.h>
+#define PROPERTY_VALUE_MAX 256
+
+G_BEGIN_DECLS
+
+GType gst_nativewindow_wrap_get_type (void);
+#define GST_TYPE_NATIVEWINDOW_WRAP         (gst_nativewindow_wrap_get_type())
+#define GST_NATIVEWINDOW_WRAP(o)           (G_TYPE_CHECK_INSTANCE_CAST((o), GST_TYPE_NATIVEWINDOW_WRAP, GstNativewindowWrap))
+#define GST_NATIVEWINDOW_WRAP_CLASS(k)     (G_TYPE_CHECK_CLASS_CAST((k), GST_TYPE_NATIVEWINDOW_WRAP, GstNativewindowWrapClass))
+#define GST_IS_NATIVEWINDOW_WRAP(o)        (G_TYPE_CHECK_INSTANCE_TYPE((o), GST_TYPE_NATIVEWINDOW_WRAP))
+#define GST_IS_NATIVEWINDOW_WRAP_CLASS(k)  (G_TYPE_CHECK_CLASS_TYPE((k), GST_TYPE_NATIVEWINDOW_WRAP))
+#define GST_NATIVEWINDOW_WRAP_GET_CLASS(o) (G_TYPE_INSTANCE_GET_CLASS((o), GST_TYPE_NATIVEWINDOW_WRAP, GstNativewindowWrapClass))
+#define GST_NATIVEWINDOW_WRAP_LOCK(w)      g_mutex_lock(&GST_NATIVEWINDOW_WRAP(w)->lock)
+#define GST_NATIVEWINDOW_WRAP_UNLOCK(w)    g_mutex_unlock(&GST_NATIVEWINDOW_WRAP(w)->lock)
+#define GST_NATIVEWINDOW_WRAP_GET_LOCK(w)  (&GST_NATIVEWINDOW_WRAP(w)->lock)
+
+typedef struct _GstNativewindowWrap GstNativewindowWrap;
+typedef struct _GstNativewindowWrapClass GstNativewindowWrapClass;
+typedef struct _GstNativewindowWrapPrivate GstNativewindowWrapPrivate;
+typedef void (*GstNativeWindowWrapCB) (GstNativewindowWrap * window);
+typedef struct _GstImageEffect GstImageEffect;
+
+struct _GstNativewindowWrap
+{
+  GstObject parent;
+  GMutex lock;
+  GMutex loop_lock;
+  GstBuffer *cur_buffer;
+    /*< private >*/
+  GstNativewindowWrapPrivate *priv;
+  GstCaps * cur_caps;
+  GstNativeWindowWrapCB draw_cb;
+  gint32 parse_rotation_degree;
+  GstVideoOrientationMethod parse_rotation_method;
+  gboolean ori_effect;
+  gboolean loop_stop;
+  gint32 clear;
+  gboolean dump_png;
+  gboolean dump_raw;
+  gchar * dump_path;
+
+  gint32 frame_width;
+  gint32 frame_height;
+};
+
+struct _GstNativewindowWrapClass
+{
+  GstObjectClass parent_class;
+};
+G_END_DECLS
+
+struct _GstImageEffect
+{
+  gint32 rotation_method;
+  gint32 rotation_degree;
+  gfloat sx; //scale
+  gfloat sy;
+  gfloat dx; //translate
+  gfloat dy;
+  gint32 x;
+  gint32 y;
+  gint32 w;
+  gint32 h;
+};
+
+struct _GstNativewindowWrapPrivate
+{
+  GMainLoop *loop;
+  GMainContext *main_context; /* default main_context */
+  GThread *thread;
+  GMutex lock;
+  //GCond t_cond;
+  GMutex sync_message_lock;
+  GCond sync_message_cond;
+
+  gint32 surface_width;
+  gint32 surface_height;
+  guintptr window_id;
+  guintptr renderPlayerID;
+  gboolean render_osd;
+  gboolean render_delay;
+  gint32 fit_mode;
+  gboolean cum_effect_Mode;
+  gint32 init_surface;
+
+  GstImageEffect cur_image_effector;
+  GstImageEffect next_image_effector;
+};
+
+typedef enum _RETTYPE
+{
+  RET_ERR_UNKOWN = (-32767),
+  RET_ERR_BAD_VALUE = RET_ERR_UNKOWN + 2,
+  RET_ERR_INVALID_OPERATION = -2,
+  RET_ERR = -1,
+  RET_OK = 0,
+} RETTYPE;
+
+typedef enum {
+  FLIP_ORIENTATION_IDENTITY = 0,
+  FLIP_ORIENTATION_HORIZ = 4,
+  FLIP_ORIENTATION_VERT = 5,
+  FLIP_ORIENTATION_HORIZ_VERT = 6,
+} FlipOrientation;
+
+gboolean gst_nativewindow_wrap_render_process (GstNativewindowWrap * window, GstBuffer * buffer, gboolean is_sync);
+gboolean gst_nativewindow_wrap_prepare (GstNativewindowWrap * window, GstCaps * caps, GstBuffer * buffer);
+gboolean gst_nativewindow_wrap_setDisplayPos (GstNativewindowWrap * window, gint32 x, gint32 y, gint32 w, gint32 h);
+gboolean gst_nativewindow_wrap_setDisplaySurface (GstNativewindowWrap * window, gint32 w, gint32 h);
+gboolean gst_nativewindow_wrap_setTranslateOffset (GstNativewindowWrap * window, gfloat dx, gfloat dy);
+gboolean gst_nativewindow_wrap_setScaleFactor (GstNativewindowWrap * window, gfloat sx, gfloat sy);
+gboolean gst_nativewindow_wrap_setRotateDegree (GstNativewindowWrap * window, gint32 degree);
+gboolean gst_nativewindow_wrap_setParseRotateDegree (GstNativewindowWrap * window, gint32 degree);
+gboolean gst_nativewindow_wrap_setParseRotateMethod (GstNativewindowWrap * window, GstVideoOrientationMethod method);
+gboolean gst_nativewindow_wrap_setRotateMethod (GstNativewindowWrap * window, GstVideoOrientationMethod method);
+gboolean gst_nativewindow_wrap_set_osd_render (GstNativewindowWrap * window, gboolean enable);
+gboolean gst_nativewindow_wrap_setOriEffect (GstNativewindowWrap * window, gboolean enable);
+gboolean gst_nativewindow_wrap_set_fit_mode (GstNativewindowWrap * window, gint32 mode);
+gboolean gst_nativewindow_wrap_set_delay_render (GstNativewindowWrap * window, gboolean enable);
+gboolean gst_nativewindow_wrap_set_cum_effect_mode (GstNativewindowWrap * window, gboolean mode);
+gboolean gst_nativewindow_wrap_set_caps (GstNativewindowWrap * window, GstCaps * caps);
+void gst_nativewindow_wrap_reset (GstNativewindowWrap * window);
+//void  set_sample(GstNativewindowWrap * window,  GstSample *sample);
+#endif /* __GST_GstNativewindowWrap_H__ */
diff --git a/subprojects/gst-plugins-bad/ext/videorender/meson.build b/subprojects/gst-plugins-bad/ext/videorender/meson.build
new file mode 100644
index 0000000000..9b885d41b9
--- /dev/null
+++ b/subprojects/gst-plugins-bad/ext/videorender/meson.build
@@ -0,0 +1,16 @@
+videorender_sources = [
+  'gstnativewindowsink.c',
+  'gstnativewindowwrap.c',
+]
+
+libpng_dep = dependency('libpng16', version : '>=1.0')
+gstvideorender = library('gstnativewindowsink',
+  videorender_sources,
+  c_args : gst_plugins_bad_args,
+  include_directories : [configinc],
+  dependencies : [gstbase_dep, gstvideo_dep, gmodule_dep, libpng_dep],
+  install : true,
+  install_dir : plugins_install_dir,
+)
+pkgconfig.generate(gstvideorender, install_dir : plugins_pkgconfig_install_dir)
+plugins += [gstvideorender]
\ No newline at end of file
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
index ec5cd3a37f..7a5ab7ef89 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth264parser.c
@@ -2205,6 +2205,10 @@ gst_h264_pps_clear (GstH264PPS * pps)
 {
   g_return_if_fail (pps != NULL);
 
+#ifdef TCL_PATCH
+  g_return_if_fail (pps->slice_group_id != NULL);
+#endif
+
   g_free (pps->slice_group_id);
   pps->slice_group_id = NULL;
 }
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth265parser.c b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth265parser.c
index a4e7549ff2..37ecad66e6 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth265parser.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/codecparsers/gsth265parser.c
@@ -1948,9 +1948,18 @@ gst_h265_parse_sps (GstH265Parser * parser, GstH265NalUnit * nalu,
   READ_UINT8 (&nr, sps->vui_parameters_present_flag, 1);
 
   if (sps->vui_parameters_present_flag && parse_vui_params) {
+#ifdef TCL_PATCH
+    if (!gst_h265_parse_vui_parameters (sps, &nr)) {
+      sps->vui_parameters_present_flag = 0;
+      GST_WARNING ("error parsing \"VUI Parameters\", set sps->vui_parameters_present_flag = 0");
+    } else {
+      vui = &sps->vui_params;
+    }
+#else
     if (!gst_h265_parse_vui_parameters (sps, &nr))
       goto error;
     vui = &sps->vui_params;
+#endif
   }
 
   READ_UINT8 (&nr, sps->sps_extension_flag, 1);
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.c b/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.c
index 3ab178eff6..741ca51756 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.c
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.c
@@ -180,12 +180,19 @@ __common_section_checks (GstMpegtsSection * section, guint min_size,
   }
 
   /* If section has a CRC, check it */
-  if (!section->short_section
-      && (_calc_crc32 (section->data, section->section_length) != 0)) {
-    GST_WARNING ("PID:0x%04x table_id:0x%02x, Bad CRC on section", section->pid,
-        section->table_id);
-    return NULL;
+#ifdef TCL_PATCH
+  if(!section->disable_crc_calc)
+  {
+#endif
+    if (!section->short_section
+        && (_calc_crc32 (section->data, section->section_length) != 0)) {
+      GST_WARNING ("PID:0x%04x table_id:0x%02x, Bad CRC on section", section->pid,
+          section->table_id);
+      return NULL;
+    }
+#ifdef TCL_PATCH
   }
+#endif
 
   /* Finally parse and set the destroy notify */
   res = parsefunc (section);
@@ -1269,6 +1276,10 @@ gst_mpegts_section_new (guint16 pid, guint8 * data, gsize data_size)
     res->last_section_number = *data;
   }
 
+#ifdef TCL_PATCH
+  res->disable_crc_calc = FALSE;
+#endif
+
   return res;
 
 short_packet:
diff --git a/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.h b/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.h
index b40c84f13b..cbad58df78 100644
--- a/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.h
+++ b/subprojects/gst-plugins-bad/gst-libs/gst/mpegts/gstmpegtssection.h
@@ -235,6 +235,10 @@ struct _GstMpegtsSection
 
   /* Padding for future extension */
   gpointer _gst_reserved[GST_PADDING];
+
+#ifdef TCL_PATCH
+  gboolean      disable_crc_calc;
+#endif
 };
 
 GST_MPEGTS_API
@@ -289,7 +293,7 @@ typedef struct _GstMpegtsPMT GstMpegtsPMT;
  * @GST_MPEGTS_STREAM_TYPE_RESERVED_00: ITU-T | ISO/IEC Reserved
  * @GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG1: ISO/IEC 11172-2 Video (i.e. MPEG-1 Video)
  * @GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG2: Rec. ITU-T H.262 | ISO/IEC 13818-2
- *       Video or ISO/IEC 11172-2 constrained parameter video stream (i.e. 
+ *       Video or ISO/IEC 11172-2 constrained parameter video stream (i.e.
  *       MPEG-2 Video)
  * @GST_MPEGTS_STREAM_TYPE_AUDIO_MPEG1: ISO/IEC 11172-3 Audio
  * @GST_MPEGTS_STREAM_TYPE_AUDIO_MPEG2: ISO/IEC 13818-3 Audio
diff --git a/subprojects/gst-plugins-bad/gst/aiff/aiff.c b/subprojects/gst-plugins-bad/gst/aiff/aiff.c
index 5fabbd49e1..8e161db1e6 100644
--- a/subprojects/gst-plugins-bad/gst/aiff/aiff.c
+++ b/subprojects/gst-plugins-bad/gst/aiff/aiff.c
@@ -31,7 +31,9 @@ plugin_init (GstPlugin * plugin)
   gboolean ret = FALSE;
 
   ret |= GST_ELEMENT_REGISTER (aiffparse, plugin);
+#ifndef TCL_PATCH
   ret |= GST_ELEMENT_REGISTER (aiffmux, plugin);
+#endif
 
   return ret;
 }
diff --git a/subprojects/gst-plugins-bad/gst/id3tag/gstid3mux.c b/subprojects/gst-plugins-bad/gst/id3tag/gstid3mux.c
index c5b10c4db1..b7dad2f0cf 100644
--- a/subprojects/gst-plugins-bad/gst/id3tag/gstid3mux.c
+++ b/subprojects/gst-plugins-bad/gst/id3tag/gstid3mux.c
@@ -216,7 +216,11 @@ gst_id3_mux_render_v1_tag (GstTagMux * mux, const GstTagList * taglist)
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
+#ifndef TCL_PATCH
   return GST_ELEMENT_REGISTER (id3mux, plugin);
+#else
+  return TRUE;
+#endif
 }
 
 GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
diff --git a/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.c b/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.c
index 9448e29fd1..1a60cf5fb8 100644
--- a/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.c
+++ b/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.c
@@ -188,6 +188,10 @@ static void gst_segment_set_position (GstSegment * segment, GstFormat format,
 static void gst_segment_set_duration (GstSegment * segment, GstFormat format,
     guint64 duration);
 
+#ifdef TCL_PATCH
+static void gst_ps_demux_demux_remove_pad(GstElement *element, GstPad *pad);
+#endif
+
 /*static guint gst_ps_demux_signals[LAST_SIGNAL] = { 0 };*/
 
 GType
@@ -220,10 +224,17 @@ gst_ps_demux_get_type (void)
   return ps_demux_type;
 }
 
+#ifdef TCL_PATCH
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (mpegpsdemux, "mpegpsdemux",
+    GST_RANK_SECONDARY, GST_TYPE_PS_DEMUX,
+    GST_DEBUG_CATEGORY_INIT (mpegpspesfilter_debug, "mpegpspesfilter", 0,
+        "MPEG-PS PES filter"));
+#else
 GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (mpegpsdemux, "mpegpsdemux",
     GST_RANK_PRIMARY, GST_TYPE_PS_DEMUX,
     GST_DEBUG_CATEGORY_INIT (mpegpspesfilter_debug, "mpegpspesfilter", 0,
         "MPEG-PS PES filter"));
+#endif
 
 static void
 gst_ps_demux_base_init (GstPsDemuxClass * klass)
@@ -266,6 +277,10 @@ gst_ps_demux_class_init (GstPsDemuxClass * klass)
 
   gstelement_class->change_state = gst_ps_demux_change_state;
 
+#ifdef TCL_PATCH
+  gstelement_class->demux_remove_pad = gst_ps_demux_demux_remove_pad;
+#endif
+
   /**
    * GstPsDemux:ignore-scr:
    *
@@ -307,7 +322,9 @@ gst_ps_demux_init (GstPsDemux * demux)
   demux->adapter = gst_adapter_new ();
   demux->rev_adapter = gst_adapter_new ();
   demux->flowcombiner = gst_flow_combiner_new ();
-
+#ifdef TCL_PATCH
+  demux->have_psm = FALSE;
+#endif
   gst_ps_demux_reset (demux);
 
   demux->ignore_scr = DEFAULT_IGNORE_SCR;
@@ -442,7 +459,23 @@ gst_ps_demux_create_stream (GstPsDemux * demux, gint id, gint stream_type,
       if (stream_type == ST_VIDEO_MPEG4) {
         mpeg_version = 4;
       }
+#ifdef TCL_PATCH
+      if (stream_type == ST_GST_VIDEO_MPEG1_OR_2 && demux->have_psm == FALSE) {
+        if (demux->filter.stream_type == ST_VIDEO_MPEG4) {
+            mpeg_version = 4;
+        }
 
+        if (demux->filter.stream_type == ST_VIDEO_H264) {
+            GST_ERROR("wzy_ps264 ST_VIDEO_H264");
+            template = klass->video_template;
+            name = g_strdup_printf ("video_%02x", id);
+            caps = gst_caps_new_simple ("video/x-h264-tcl",
+                "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+            threshold = VIDEO_SEGMENT_THRESHOLD;
+            break;
+        }
+      }
+#endif
       template = klass->video_template;
       name = g_strdup_printf ("video_%02x", id);
       caps = gst_caps_new_simple ("video/mpeg",
@@ -484,9 +517,14 @@ gst_ps_demux_create_stream (GstPsDemux * demux, gint id, gint stream_type,
           "stream-format", G_TYPE_STRING, "loas", NULL);
       break;
     case ST_VIDEO_H264:
+      GST_ERROR("wzy_ps264 ST_VIDEO_H264");
       template = klass->video_template;
       name = g_strdup_printf ("video_%02x", id);
+#if TCL_PATCH
+      caps = gst_caps_new_simple ("video/x-h264-tcl",
+#else
       caps = gst_caps_new_simple ("video/x-h264",
+#endif
           "stream-format", G_TYPE_STRING, "byte-stream", NULL);
       threshold = VIDEO_SEGMENT_THRESHOLD;
       break;
@@ -537,12 +575,19 @@ gst_ps_demux_create_stream (GstPsDemux * demux, gint id, gint stream_type,
   stream = g_new0 (GstPsStream, 1);
   stream->id = id;
   stream->discont = TRUE;
+#ifdef TCL_PATCH
+  stream->droped_flag  = FALSE;
+#endif
   stream->need_segment = TRUE;
   stream->notlinked = FALSE;
   stream->type = stream_type;
   stream->pending_tags = NULL;
   stream->pad = gst_pad_new_from_template (template, name);
   stream->segment_thresh = threshold;
+#ifdef TCL_PATCH
+  stream->first_dts_diff = GST_CLOCK_TIME_NONE;
+  stream->first_pts_diff = GST_CLOCK_TIME_NONE;
+#endif
   gst_pad_set_event_function (stream->pad,
       GST_DEBUG_FUNCPTR (gst_ps_demux_src_event));
   gst_pad_set_query_function (stream->pad,
@@ -650,6 +695,46 @@ gst_ps_demux_send_segment (GstPsDemux * demux, GstPsStream * stream,
     GstClockTime pts)
 {
   /* discont */
+#ifdef TCL_PATCH
+  if (pts != GST_CLOCK_TIME_NONE && G_UNLIKELY (stream->need_segment)) {
+    GstSegment segment;
+    GstEvent *segment_event;
+
+    GST_DEBUG ("PTS timestamp:%" GST_TIME_FORMAT " base_time %" GST_TIME_FORMAT
+        " src_segment.start:%" GST_TIME_FORMAT " .stop:%" GST_TIME_FORMAT,
+        GST_TIME_ARGS (pts), GST_TIME_ARGS (demux->base_time),
+        GST_TIME_ARGS (demux->src_segment.start),
+        GST_TIME_ARGS (demux->src_segment.stop));
+
+    /* we should be in sync with downstream, so start from our segment notion,
+     * which also includes proper base_time etc, tweak it a bit and send */
+    gst_segment_copy_into (&demux->src_segment, &segment);
+    if (GST_CLOCK_TIME_IS_VALID (demux->base_time)) {
+      if (GST_CLOCK_TIME_IS_VALID (segment.start))
+      {
+            segment.start += 0;
+            segment.time = segment.start;
+      }
+      if (GST_CLOCK_TIME_IS_VALID (segment.stop))
+      {
+            segment.stop += 0;
+            segment.time = segment.start;
+      }
+    }
+
+    segment_event = gst_event_new_segment (&segment);
+    if (demux->segment_seqnum)
+      gst_event_set_seqnum (segment_event, demux->segment_seqnum);
+    else
+      demux->segment_seqnum = gst_event_get_seqnum (segment_event);
+    GST_INFO_OBJECT (demux, "sending segment event %" GST_SEGMENT_FORMAT
+        " to pad %" GST_PTR_FORMAT, &segment, stream->pad);
+
+    gst_pad_push_event (stream->pad, segment_event);
+
+    stream->need_segment = FALSE;
+  }
+#else
   if (G_UNLIKELY (stream->need_segment)) {
     GstSegment segment;
     GstEvent *segment_event;
@@ -683,6 +768,7 @@ gst_ps_demux_send_segment (GstPsDemux * demux, GstPsStream * stream,
 
     stream->need_segment = FALSE;
   }
+#endif
 
   if (G_UNLIKELY (stream->pending_tags)) {
     GST_DEBUG_OBJECT (demux, "Sending pending_tags %p for pad %s:%s : %"
@@ -710,7 +796,9 @@ gst_ps_demux_send_data (GstPsDemux * demux, GstPsStream * stream,
   if (G_UNLIKELY (demux->next_dts != G_MAXUINT64))
     dts = MPEGTIME_TO_GSTTIME (demux->next_dts);
 
+#ifndef TCL_PATCH
   gst_ps_demux_send_segment (demux, stream, pts);
+#endif
 
   /* Ignores DTS if PTS < DTS. Maybe additional sanity checking is possible
    * by comparing 33bits timestap rollover case, but PTS < DTS is already
@@ -722,9 +810,45 @@ gst_ps_demux_send_data (GstPsDemux * demux, GstPsStream * stream,
     dts = GST_CLOCK_TIME_NONE;
   }
 
+#ifndef TCL_PATCH
   /* OK, sent new segment now prepare the buffer for sending */
   GST_BUFFER_PTS (buf) = pts;
   GST_BUFFER_DTS (buf) = dts;
+#else
+  if (stream->first_pts_diff == GST_CLOCK_TIME_NONE)
+  {
+    if (GST_CLOCK_TIME_IS_VALID (pts))
+        stream->first_pts_diff = pts;
+  }
+  if (stream->first_dts_diff == GST_CLOCK_TIME_NONE)
+  {
+    if (GST_CLOCK_TIME_IS_VALID (dts))
+        stream->first_dts_diff = dts;
+  }
+  if (GST_CLOCK_TIME_IS_VALID (dts))
+  {
+    if (dts >= stream->first_dts_diff)
+        GST_BUFFER_DTS (buf) = dts - stream->first_dts_diff;
+    else
+        dts = GST_CLOCK_TIME_NONE;
+  }
+  else
+  {
+    GST_BUFFER_DTS (buf) = dts;
+  }
+  if (GST_CLOCK_TIME_IS_VALID (pts))
+  {
+    if (dts >= stream->first_dts_diff)
+        GST_BUFFER_PTS (buf) = pts - stream->first_pts_diff;
+    else
+        pts = GST_CLOCK_TIME_NONE;
+  }
+  else
+  {
+    GST_BUFFER_PTS (buf) = pts;
+  }
+  gst_ps_demux_send_segment (demux, stream, pts);
+#endif
 
   /* If we have no DTS but a PTS that means both are the same,
    * if we have neither than we don't know the current position */
@@ -765,7 +889,20 @@ gst_ps_demux_send_data (GstPsDemux * demux, GstPsStream * stream,
   GST_LOG_OBJECT (demux, "pushing stream id 0x%02x type 0x%02x, pts time: %"
       GST_TIME_FORMAT ", size %" G_GSIZE_FORMAT,
       stream->id, stream->type, GST_TIME_ARGS (pts), gst_buffer_get_size (buf));
+#ifndef TCL_PATCH
   result = gst_pad_push (stream->pad, buf);
+#else
+  if(NULL == stream || NULL == stream->pad || TRUE == stream->discont || TRUE == stream->droped_flag)
+    goto no_stream;
+  else
+    result = gst_pad_push (stream->pad, buf);
+
+  if(result != GST_FLOW_OK)
+  {
+    if(NULL == stream || NULL == stream->pad || TRUE == stream->discont || TRUE == stream->droped_flag)
+      goto no_stream;
+  }
+#endif
   GST_LOG_OBJECT (demux, "result: %s", gst_flow_get_name (result));
 
   return result;
@@ -982,6 +1119,16 @@ gst_ps_demux_flush (GstPsDemux * demux)
   demux->adapter_offset = G_MAXUINT64;
   demux->current_scr = G_MAXUINT64;
   demux->bytes_since_scr = 0;
+#ifdef TCL_PATCH
+  if (demux->next_scr != G_MAXUINT64)
+  {
+    demux->next_scr = 0;
+  }
+  if (demux->scr_adjust != G_MAXUINT64)
+  {
+    demux->scr_adjust = 0;
+  }
+#endif
 }
 
 static inline void
@@ -1038,8 +1185,23 @@ gst_ps_demux_send_gap_updates (GstPsDemux * demux, GstClockTime new_start)
             "Sending gap update to pad %s from time %" GST_TIME_FORMAT " to %"
             GST_TIME_FORMAT, GST_PAD_NAME (stream->pad),
             GST_TIME_ARGS (stream->last_ts), GST_TIME_ARGS (new_start));
+#ifdef TCL_PATCH
+        if (stream->first_dts_diff != GST_CLOCK_TIME_NONE)
+        {
+            event = gst_event_new_gap (stream->last_ts - stream->first_dts_diff, new_start - stream->last_ts - stream->first_dts_diff);
+        }
+        else if (stream->first_pts_diff != GST_CLOCK_TIME_NONE)
+        {
+            event = gst_event_new_gap (stream->last_ts - stream->first_pts_diff, new_start - stream->last_ts - stream->first_pts_diff);
+        }
+        else
+        {
+            event = gst_event_new_gap (stream->last_ts, new_start - stream->last_ts);
+        }
+#else
         event =
             gst_event_new_gap (stream->last_ts, new_start - stream->last_ts);
+#endif
         gst_pad_push_event (stream->pad, event);
         stream->last_ts = new_start;
       }
@@ -1658,8 +1820,8 @@ gst_ps_demux_reset_psm (GstPsDemux * demux)
 {
   gint i;
 
-#define FILL_TYPE(start, stop, type)	\
-  for (i=start; i <= stop; i++)			\
+#define FILL_TYPE(start, stop, type)    \
+  for (i=start; i <= stop; i++)         \
     demux->psm[i] = type;
 
   /* Initialize all fields to -1 first */
@@ -3271,6 +3433,10 @@ gst_ps_demux_chain (GstPad * pad, GstObject * parent, GstBuffer * buffer)
         goto done;
       case ID_PS_PROGRAM_STREAM_MAP:
         ret = gst_ps_demux_parse_psm (demux);
+#ifdef TCL_PATCH
+        demux->have_psm = TRUE;
+        GST_DEBUG("demux->have_psm TRUE");
+#endif
         break;
       default:
         if (gst_ps_demux_is_pes_sync (demux->last_sync_code)) {
@@ -3369,3 +3535,34 @@ gst_segment_set_duration (GstSegment * segment, GstFormat format,
   }
   segment->duration = duration;
 }
+
+#ifdef TCL_PATCH
+static void
+gst_ps_demux_demux_remove_pad(GstElement *element, GstPad *pad)
+{
+    GstPsDemux *demux = GST_PS_DEMUX (element);
+    GST_OBJECT_LOCK (element);
+    // list and record
+    int index = 0;
+    GstPsStream *stream2del = NULL;
+    for (index = 0; index < GST_PS_DEMUX_MAX_STREAMS; index++)
+    {
+        GstPsStream *stream = demux->streams[index];
+        if(stream && pad == stream->pad)
+        {
+            stream2del = stream;
+            break;
+        }
+    }
+    // there is stream to be remove
+    if(stream2del)
+    {
+        stream2del->pad         = NULL;
+        stream2del->discont     = TRUE;
+        stream2del->droped_flag = TRUE;
+    }
+    else
+        GST_ERROR_OBJECT (demux, "Can Not Remove Designated Pad Because of Can Not Finding it!!");
+    GST_OBJECT_UNLOCK (element);
+}
+#endif
diff --git a/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.h b/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.h
index d11f8c288b..922c39835b 100644
--- a/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.h
+++ b/subprojects/gst-plugins-bad/gst/mpegdemux/gstmpegdemux.h
@@ -53,19 +53,19 @@
 
 G_BEGIN_DECLS
 
-#define GST_TYPE_PS_DEMUX		(gst_ps_demux_get_type())
-#define GST_PS_DEMUX(obj)		(G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_PS_DEMUX,GstPsDemux))
-#define GST_PS_DEMUX_CLASS(klass)	(G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_PS_DEMUX,GstPsDemuxClass))
+#define GST_TYPE_PS_DEMUX       (gst_ps_demux_get_type())
+#define GST_PS_DEMUX(obj)       (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_PS_DEMUX,GstPsDemux))
+#define GST_PS_DEMUX_CLASS(klass)   (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_PS_DEMUX,GstPsDemuxClass))
 #define GST_PS_DEMUX_GET_CLASS(klass) (G_TYPE_INSTANCE_GET_CLASS((klass),GST_TYPE_PS_DEMUX,GstPsDemuxClass))
-#define GST_IS_PS_DEMUX(obj)		(G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_PS_DEMUX))
-#define GST_IS_PS_DEMUX_CLASS(obj)	(G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_PS_DEMUX))
+#define GST_IS_PS_DEMUX(obj)        (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_PS_DEMUX))
+#define GST_IS_PS_DEMUX_CLASS(obj)  (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_PS_DEMUX))
 
 typedef struct _GstPsStream GstPsStream;
 typedef struct _GstPsDemux GstPsDemux;
 typedef struct _GstPsDemuxClass GstPsDemuxClass;
 
-#define GST_PS_DEMUX_MAX_STREAMS	256
-#define GST_PS_DEMUX_MAX_PSM		256
+#define GST_PS_DEMUX_MAX_STREAMS    256
+#define GST_PS_DEMUX_MAX_PSM        256
 
 #define MAX_DVD_AUDIO_STREAMS       8
 #define MAX_DVD_SUBPICTURE_STREAMS  32
@@ -99,7 +99,14 @@ struct _GstPsStream
   gboolean notlinked;
   gboolean need_segment;
 
+#ifdef TCL_PATCH
+  GstClockTime first_dts_diff;
+  GstClockTime first_pts_diff;
+#endif
   GstTagList *pending_tags;
+#ifdef TCL_PATCH
+  gboolean droped_flag;
+#endif
 };
 
 struct _GstPsDemux
@@ -157,6 +164,10 @@ struct _GstPsDemux
   /* Indicates an MPEG-2 stream */
   gboolean is_mpeg2_pack;
 
+#ifdef TCL_PATCH
+  gboolean have_psm;
+#endif
+
   /* properties */
   gboolean ignore_scr;
 };
diff --git a/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.c b/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.c
index 1771b64b4a..23ba4ff37a 100644
--- a/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.c
+++ b/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.c
@@ -73,6 +73,9 @@ gst_pes_filter_init (GstPESFilter * filter, GstAdapter * adapter,
   filter->state = STATE_HEADER_PARSE;
   filter->gather_pes = FALSE;
   filter->allow_unbounded = FALSE;
+#ifdef TCL_PATCH
+  filter->stream_type = ST_RESERVED;
+#endif
 }
 
 void
@@ -86,6 +89,29 @@ gst_pes_filter_uninit (GstPESFilter * filter)
   filter->adapter_offset = NULL;
 }
 
+#ifdef TCL_PATCH
+void
+gst_pes_fix_streame_type(GstPESFilter * filter, guint8 *data)
+{
+  //judge codec_type MPEG4 when no PSM
+  //MPEG4 start_codec :  00 00 01 B0(VOSH_start_code) XX(start_code data not regular) 00 00 01 B5(VO_start_code)
+  if (data[0] == 0x00 && data[1] == 0x00 &&
+      data[2] == 0x01 && data[3] == 0xB0 &&
+      data[5] == 0x00 && data[6] == 0x00 &&
+      data[7] == 0x01 && data[8] == 0xB5) {
+      filter->stream_type = ST_VIDEO_MPEG4;
+  }
+  //judge codec_type H264 when no PSM
+  //H264 start_codec :  00 00 01 or 00 00 00 01
+  if ((data[0] == 0x00 && data[1] == 0x00 &&
+      data[2] == 0x01 ) ||
+     (data[0] == 0x00 && data[1] == 0x00 &&
+      data[2] == 0x00 && data[3] == 0x01 )) {
+      filter->stream_type = ST_VIDEO_H264;
+      }
+}
+#endif
+
 void
 gst_pes_filter_set_callbacks (GstPESFilter * filter,
     GstPESFilterData data_cb, GstPESFilterResync resync_cb, gpointer user_data)
@@ -248,6 +274,11 @@ gst_pes_filter_parse (GstPESFilter * filter)
     READ_TS (data, filter->pts, lost_sync);
     GST_DEBUG ("PTS found %" G_GUINT64_FORMAT, filter->pts);
     datalen -= 5;
+#ifdef TCL_PATCH
+    if (datalen < 8)
+      goto need_more_data;
+    gst_pes_fix_streame_type(filter,data);
+#endif
   }
   /* PTS and DTS, never for mpeg2 */
   else if ((*data & 0xf0) == 0x30) {
@@ -260,6 +291,11 @@ gst_pes_filter_parse (GstPESFilter * filter)
     GST_DEBUG ("PTS found %" G_GUINT64_FORMAT, filter->pts);
     GST_DEBUG ("DTS found %" G_GUINT64_FORMAT, filter->dts);
     datalen -= 10;
+#ifdef TCL_PATCH
+        if (datalen < 8)
+          goto need_more_data;
+        gst_pes_fix_streame_type(filter,data);
+#endif
   } else if ((*data & 0xc0) == 0x80) {
     /* mpeg2 case */
     guchar flags;
@@ -446,6 +482,11 @@ gst_pes_filter_parse (GstPESFilter * filter)
     /* calculate the amount of real data in this PES packet */
     data += header_data_length;
     datalen -= header_data_length;
+#ifdef TCL_PATCH
+        if (datalen < 8)
+          goto need_more_data;
+        gst_pes_fix_streame_type(filter,data);
+#endif
   } else if (*data == 0x0f) {
     /* Not sure what this clause is for */
     data++;
diff --git a/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.h b/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.h
index e82ca803fd..263de98904 100644
--- a/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.h
+++ b/subprojects/gst-plugins-bad/gst/mpegdemux/gstpesfilter.h
@@ -51,15 +51,15 @@ G_BEGIN_DECLS
 
 typedef struct _GstPESFilter GstPESFilter;
 
-typedef GstFlowReturn (*GstPESFilterData) (GstPESFilter * filter, gboolean first, GstBuffer * buffer, 
+typedef GstFlowReturn (*GstPESFilterData) (GstPESFilter * filter, gboolean first, GstBuffer * buffer,
                          gpointer user_data);
 typedef void (*GstPESFilterResync) (GstPESFilter * filter, gpointer user_data);
 typedef void (*GstPESFilterIndex) (GstPESFilter * filter, gpointer user_data);
 
 typedef enum {
   STATE_HEADER_PARSE,
-  STATE_DATA_PUSH, 
-  STATE_DATA_SKIP 
+  STATE_DATA_PUSH,
+  STATE_DATA_SKIP
 } GstPESFilterState;
 
 struct _GstPESFilter {
@@ -86,13 +86,16 @@ struct _GstPESFilter {
 
   gint64             pts;
   gint64             dts;
+#ifdef TCL_PATCH
+  gint64             stream_type;
+#endif
 };
 
 void gst_pes_filter_init (GstPESFilter * filter, GstAdapter * adapter, guint64 * adapter_offset);
 
 void gst_pes_filter_uninit (GstPESFilter * filter);
 
-void gst_pes_filter_set_callbacks (GstPESFilter * filter, 
+void gst_pes_filter_set_callbacks (GstPESFilter * filter,
                          GstPESFilterData data_cb,
                          GstPESFilterResync resync_cb,
                          gpointer user_data);
@@ -103,6 +106,10 @@ GstFlowReturn gst_pes_filter_process (GstPESFilter * filter);
 void gst_pes_filter_flush (GstPESFilter * filter);
 GstFlowReturn gst_pes_filter_drain (GstPESFilter * filter);
 
+#ifdef TCL_PATCH
+void gst_pes_fix_streame_type(GstPESFilter * filter, guint8 *data);
+#endif
+
 G_END_DECLS
 
 #endif /* __GST_PES_FILTER_H__ */
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.c
new file mode 100644
index 0000000000..d181c43929
--- /dev/null
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.c
@@ -0,0 +1,371 @@
+/* GStreamer
+ * Copyright (C) <1999> Erik Walthinsen <omega@cse.ogi.edu>
+ *               <2006> Edward Hervey <bilboed@bilboed.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#include "config.h"
+#endif
+#include <string.h>
+#include <errno.h>
+
+#include <gst/gst.h>
+
+#include "gstavprotocol.h"
+
+typedef struct _GstProtocolInfo GstProtocolInfo;
+
+struct _GstProtocolInfo
+{
+  GstPad *pad;
+
+  guint64 offset;
+  gboolean eos;
+  gint set_streamheader;
+};
+
+static int
+gst_ffmpegdata_peek (void *priv_data, unsigned char *buf, int size)
+{
+  GstProtocolInfo *info;
+  GstBuffer *inbuf = NULL;
+  GstFlowReturn ret;
+  int total = 0;
+
+  info = (GstProtocolInfo *) priv_data;
+
+  GST_DEBUG ("Pulling %d bytes at position %" G_GUINT64_FORMAT, size,
+      info->offset);
+
+  ret = gst_pad_pull_range (info->pad, info->offset, (guint) size, &inbuf);
+
+  switch (ret) {
+    case GST_FLOW_OK:
+      total = (gint) gst_buffer_get_size (inbuf);
+      gst_buffer_extract (inbuf, 0, buf, total);
+      gst_buffer_unref (inbuf);
+      break;
+    case GST_FLOW_EOS:
+      total = 0;
+      break;
+    case GST_FLOW_FLUSHING:
+      total = -1;
+      break;
+    default:
+    case GST_FLOW_ERROR:
+      total = -2;
+      break;
+  }
+
+  GST_DEBUG ("Got %d (%s) return result %d", ret, gst_flow_get_name (ret),
+      total);
+
+  return total;
+}
+
+static int
+gst_ffmpegdata_read (void *priv_data, unsigned char *buf, int size)
+{
+  gint res;
+  GstProtocolInfo *info;
+
+  info = (GstProtocolInfo *) priv_data;
+
+  GST_DEBUG ("Reading %d bytes of data at position %" G_GUINT64_FORMAT, size,
+      info->offset);
+
+  res = gst_ffmpegdata_peek (priv_data, buf, size);
+  if (res >= 0)
+    info->offset += res;
+
+  GST_DEBUG ("Returning %d bytes", res);
+
+  return res;
+}
+
+static int
+gst_ffmpegdata_write (void *priv_data, uint8_t * buf, int size)
+{
+  GstProtocolInfo *info;
+  GstBuffer *outbuf;
+
+  GST_DEBUG ("Writing %d bytes", size);
+  info = (GstProtocolInfo *) priv_data;
+
+  /* create buffer and push data further */
+  outbuf = gst_buffer_new_and_alloc (size);
+
+  gst_buffer_fill (outbuf, 0, buf, size);
+
+  if (gst_pad_push (info->pad, outbuf) != GST_FLOW_OK)
+    return 0;
+
+  info->offset += size;
+  return size;
+}
+
+static int64_t
+gst_ffmpegdata_seek (void *priv_data, int64_t pos, int whence)
+{
+  GstProtocolInfo *info;
+  guint64 newpos = 0, oldpos;
+
+  GST_DEBUG ("Seeking to %" G_GINT64_FORMAT ", whence=%d",
+      (gint64) pos, whence);
+
+  info = (GstProtocolInfo *) priv_data;
+
+  /* TODO : if we are push-based, we need to return sensible info */
+
+  if (GST_PAD_IS_SINK (info->pad)) {
+    /* sinkpad */
+    switch (whence) {
+      case SEEK_SET:
+        newpos = (guint64) pos;
+        break;
+      case SEEK_CUR:
+        newpos = info->offset + pos;
+        break;
+      case SEEK_END:
+      case AVSEEK_SIZE:
+        /* ffmpeg wants to know the current end position in bytes ! */
+      {
+        gint64 duration;
+
+        GST_DEBUG ("Seek end");
+
+        if (gst_pad_is_linked (info->pad))
+          if (gst_pad_query_duration (GST_PAD_PEER (info->pad),
+                  GST_FORMAT_BYTES, &duration))
+            newpos = ((guint64) duration) + pos;
+      }
+        break;
+      default:
+        g_assert (0);
+        break;
+    }
+    /* FIXME : implement case for push-based behaviour */
+    if (whence != AVSEEK_SIZE)
+      info->offset = newpos;
+  } else if (GST_PAD_IS_SRC (info->pad)) {
+    GstSegment segment;
+
+    oldpos = info->offset;
+
+    /* srcpad */
+    switch (whence) {
+      case SEEK_SET:
+      {
+        info->offset = (guint64) pos;
+        break;
+      }
+      case SEEK_CUR:
+        info->offset += pos;
+        break;
+      default:
+        break;
+    }
+    newpos = info->offset;
+
+    if (newpos != oldpos) {
+      gst_segment_init (&segment, GST_FORMAT_BYTES);
+      segment.start = newpos;
+      segment.time = newpos;
+      gst_pad_push_event (info->pad, gst_event_new_segment (&segment));
+    }
+  } else {
+    g_assert_not_reached ();
+  }
+
+  GST_DEBUG ("Now at offset %" G_GUINT64_FORMAT " (returning %" G_GUINT64_FORMAT
+      ")", info->offset, newpos);
+  return newpos;
+}
+
+int
+gst_ffmpegdata_close (AVIOContext * h)
+{
+  GstProtocolInfo *info;
+
+  if (h == NULL)
+    return 0;
+
+  info = (GstProtocolInfo *) h->opaque;
+  if (info == NULL)
+    return 0;
+
+  GST_LOG ("Closing file");
+
+  if (GST_PAD_IS_SRC (info->pad)) {
+    /* send EOS - that closes down the stream */
+    gst_pad_push_event (info->pad, gst_event_new_eos ());
+  }
+
+  /* clean up data */
+  g_free (info);
+  h->opaque = NULL;
+
+  av_freep (&h->buffer);
+  av_free (h);
+
+  return 0;
+}
+
+int
+gst_ffmpegdata_open (GstPad * pad, int flags, AVIOContext ** context)
+{
+  GstProtocolInfo *info;
+
+#ifdef TCL_PATCH
+  static const int buffer_size = 4096 * 16;
+#else
+  static const int buffer_size = 4096;
+#endif
+  unsigned char *buffer = NULL;
+
+  info = g_new0 (GstProtocolInfo, 1);
+
+  info->set_streamheader = flags & GST_FFMPEG_URL_STREAMHEADER;
+  flags &= ~GST_FFMPEG_URL_STREAMHEADER;
+
+  /* we don't support R/W together */
+  if ((flags & AVIO_FLAG_WRITE) && (flags & AVIO_FLAG_READ)) {
+    GST_WARNING ("Only read-only or write-only are supported");
+    g_free (info);
+    return -EINVAL;
+  }
+
+  /* make sure we're a pad and that we're of the right type */
+  g_return_val_if_fail (GST_IS_PAD (pad), -EINVAL);
+
+  if ((flags & AVIO_FLAG_READ))
+    g_return_val_if_fail (GST_PAD_IS_SINK (pad), -EINVAL);
+  if ((flags & AVIO_FLAG_WRITE))
+    g_return_val_if_fail (GST_PAD_IS_SRC (pad), -EINVAL);
+
+  info->eos = FALSE;
+  info->pad = pad;
+  info->offset = 0;
+
+  buffer = av_malloc (buffer_size);
+  if (buffer == NULL) {
+    GST_WARNING ("Failed to allocate buffer");
+    g_free (info);
+    return -ENOMEM;
+  }
+
+  *context =
+      avio_alloc_context (buffer, buffer_size, flags, (void *) info,
+      gst_ffmpegdata_read, gst_ffmpegdata_write, gst_ffmpegdata_seek);
+  if (*context == NULL) {
+    GST_WARNING ("Failed to allocate memory");
+    g_free (info);
+    av_free (buffer);
+    return -ENOMEM;
+  }
+  (*context)->seekable = AVIO_SEEKABLE_NORMAL;
+  if (!(flags & AVIO_FLAG_WRITE)) {
+    (*context)->buf_ptr = (*context)->buf_end;
+    (*context)->write_flag = 0;
+  }
+
+  return 0;
+}
+
+/* specialized protocol for cross-thread pushing,
+ * based on ffmpeg's pipe protocol */
+
+static int
+gst_ffmpeg_pipe_read (void *priv_data, uint8_t * buf, int size)
+{
+  GstFFMpegPipe *ffpipe;
+  guint available;
+
+  ffpipe = (GstFFMpegPipe *) priv_data;
+
+  GST_LOG ("requested size %d", size);
+
+  GST_FFMPEG_PIPE_MUTEX_LOCK (ffpipe);
+
+  GST_LOG ("requested size %d", size);
+
+  while ((available = gst_adapter_available (ffpipe->adapter)) < size
+      && !ffpipe->eos) {
+    GST_DEBUG ("Available:%d, requested:%d", available, size);
+    ffpipe->needed = size;
+    GST_FFMPEG_PIPE_SIGNAL (ffpipe);
+    GST_FFMPEG_PIPE_WAIT (ffpipe);
+  }
+
+  size = MIN (available, size);
+  if (size) {
+    GST_LOG ("Getting %d bytes", size);
+    gst_adapter_copy (ffpipe->adapter, buf, 0, size);
+    gst_adapter_flush (ffpipe->adapter, size);
+    GST_LOG ("%" G_GSIZE_FORMAT " bytes left in adapter",
+        gst_adapter_available (ffpipe->adapter));
+    ffpipe->needed = 0;
+  }
+  GST_FFMPEG_PIPE_MUTEX_UNLOCK (ffpipe);
+
+  return size;
+}
+
+int
+gst_ffmpeg_pipe_close (AVIOContext * h)
+{
+  GST_LOG ("Closing pipe");
+
+  if (h == NULL)
+    return 0;
+
+  h->opaque = NULL;
+  av_freep (&h->buffer);
+  av_free (h);
+
+  return 0;
+}
+
+int
+gst_ffmpeg_pipe_open (GstFFMpegPipe * ffpipe, int flags, AVIOContext ** context)
+{
+  static const int buffer_size = 4096;
+  unsigned char *buffer = NULL;
+
+  /* sanity check */
+  g_return_val_if_fail (GST_IS_ADAPTER (ffpipe->adapter), -EINVAL);
+
+  buffer = av_malloc (buffer_size);
+  if (buffer == NULL) {
+    GST_WARNING ("Failed to allocate buffer");
+    return -ENOMEM;
+  }
+
+  *context =
+      avio_alloc_context (buffer, buffer_size, 0, (void *) ffpipe,
+      gst_ffmpeg_pipe_read, NULL, NULL);
+  if (*context == NULL) {
+    GST_WARNING ("Failed to allocate memory");
+    av_free (buffer);
+    return -ENOMEM;
+  }
+  (*context)->seekable = 0;
+  (*context)->buf_ptr = (*context)->buf_end;
+
+  return 0;
+}
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.h b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.h
new file mode 100644
index 0000000000..32a731f57f
--- /dev/null
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstavprotocol.h
@@ -0,0 +1,79 @@
+/* GStreamer
+ * Copyright (C) <2006> Mark Nauwelaerts <manauw@skynet.be>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+
+#ifndef __GST_FFMPEGPROTOCOL_H__
+#define __GST_FFMPEGPROTOCOL_H__
+
+#include <gst/base/gstadapter.h>
+#include <libavformat/avformat.h>
+
+G_BEGIN_DECLS
+#define GST_FFMPEG_URL_STREAMHEADER 16
+
+/* pipe protocol helpers */
+#define GST_FFMPEG_PIPE_MUTEX_LOCK(m) G_STMT_START {                    \
+  GST_LOG ("locking tlock from thread %p", g_thread_self ()); \
+  g_mutex_lock (&m->tlock);                                              \
+  GST_LOG ("locked tlock from thread %p", g_thread_self ());  \
+} G_STMT_END
+
+#define GST_FFMPEG_PIPE_MUTEX_UNLOCK(m) G_STMT_START {                    \
+  GST_LOG ("unlocking tlock from thread %p", g_thread_self ()); \
+  g_mutex_unlock (&m->tlock);                                              \
+} G_STMT_END
+
+#define GST_FFMPEG_PIPE_WAIT(m) G_STMT_START {                          \
+  GST_LOG ("thread %p waiting", g_thread_self ());            \
+  g_cond_wait (&m->cond, &m->tlock);                                      \
+} G_STMT_END
+
+#define GST_FFMPEG_PIPE_SIGNAL(m) G_STMT_START {                        \
+  GST_LOG ("signalling from thread %p", g_thread_self ());    \
+  g_cond_signal (&m->cond);                                              \
+} G_STMT_END
+
+typedef struct _GstFFMpegPipe GstFFMpegPipe;
+
+struct _GstFFMpegPipe
+{
+  /* lock for syncing */
+  GMutex tlock;
+  /* with TLOCK */
+  /* signals counterpart thread to have a look */
+  GCond cond;
+  /* seen eos */
+  gboolean eos;
+  /* flowreturn obtained by src task */
+  GstFlowReturn srcresult;
+  /* adpater collecting data */
+  GstAdapter *adapter;
+  /* amount needed in adapter by src task */
+  guint needed;
+};
+
+int gst_ffmpeg_pipe_open (GstFFMpegPipe *ffpipe, int flags, AVIOContext ** context);
+int gst_ffmpeg_pipe_close (AVIOContext * h);
+
+int gst_ffmpegdata_open (GstPad * pad, int flags, AVIOContext ** context);
+int gst_ffmpegdata_close (AVIOContext * h);
+
+G_END_DECLS
+
+#endif /* __GST_FFMPEGPROTOCOL_H__ */
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstmpegdesc.h b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstmpegdesc.h
index 65fb44fd3a..1b0dd402bb 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstmpegdesc.h
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/gstmpegdesc.h
@@ -1,4 +1,4 @@
-/* 
+/*
  *
  * This library is free software; you can redistribute it and/or
  * modify it under the terms of the GNU Library General Public
@@ -224,6 +224,9 @@
 #define DRF_ID_DTS1       0x44545331
 #define DRF_ID_DTS2       0x44545332
 #define DRF_ID_DTS3       0x44545333
+#ifdef TCL_PATCH
+#define DRF_ID_DTSH       0x44545348
+#endif
 #define DRF_ID_S302M      0x42535344
 #define DRF_ID_TSHV       0x54534856
 #define DRF_ID_AC3        0x41432d33
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/meson.build b/subprojects/gst-plugins-bad/gst/mpegtsdemux/meson.build
index 961f4f4b12..7ac309131c 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/meson.build
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/meson.build
@@ -5,13 +5,24 @@ tsdemux_sources = [
   'tsdemux.c',
   'gsttsdemux.c',
   'pesparse.c',
+  'gstavprotocol.c',
 ]
 
+libavfilter_dep = dependency('libavfilter', version: '>= 7.16.100',
+  fallback: ['FFmpeg', 'libavfilter_dep'])
+libavformat_dep = dependency('libavformat', version: '>= 58.12.100',
+  fallback: ['FFmpeg', 'libavformat_dep'])
+libavcodec_dep = dependency('libavcodec', version: '>= 58.18.100',
+  fallback: ['FFmpeg', 'libavcodec_dep'])
+libavutil_dep = dependency('libavutil', version: '>= 56.14.100',
+  fallback: ['FFmpeg', 'libavutil_dep'])
+
+libav_deps = [libavfilter_dep, libavformat_dep, libavcodec_dep, libavutil_dep]
 gstmpegtsdemux = library('gstmpegtsdemux',
   tsdemux_sources,
   c_args : gst_plugins_bad_args + ['-DGST_USE_UNSTABLE_API'],
   include_directories : [configinc, libsinc],
-  dependencies : [gstcodecparsers_dep, gstmpegts_dep, gsttag_dep,
+  dependencies : [libav_deps, gstcodecparsers_dep, gstmpegts_dep, gsttag_dep,
                   gstpbutils_dep, gstaudio_dep, gstbase_dep, libm],
   install : true,
   install_dir : plugins_install_dir,
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
index 85d5afde2a..f2a7615327 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.c
@@ -69,6 +69,11 @@ enum
   /* FILL ME */
 };
 
+#ifdef TCL_PATCH
+/*Check have pmt max package num */
+#define CNT_GET_PMT_NUM    2048
+#endif
+
 static void mpegts_base_dispose (GObject * object);
 static void mpegts_base_finalize (GObject * object);
 static void mpegts_base_set_property (GObject * object, guint prop_id,
@@ -241,6 +246,9 @@ mpegts_base_reset (MpegTSBase * base)
   base->seen_pat = FALSE;
   base->seek_offset = -1;
 
+#ifdef TCL_PATCH
+  base->check_pmt_times = 0;
+#endif
   g_ptr_array_foreach (base->programs, (GFunc) remove_each_program, base);
   g_ptr_array_remove_range (base->programs, 0, base->programs->len);
 
@@ -282,6 +290,27 @@ mpegts_base_init (MpegTSBase * base)
   base->push_section = TRUE;
   base->ignore_pcr = DEFAULT_IGNORE_PCR;
 
+#ifdef TCL_PATCH
+  base->check_pmt_times  = 0;
+  base->is_hls  = FALSE;
+  base->is_hls_live = FALSE;
+
+  base->is_m2ts = FALSE;
+  base->protocol_type = 0;
+
+  base->adjust_duration = FALSE;
+  base->last_valid_offset = 0;
+#endif
+
+#ifdef TCL_PATCH
+  base->first_program_number = -1;
+  base->need_select_first_program = FALSE;
+#endif
+
+#ifdef TCL_PATCH
+  base->use_iso_src = FALSE;
+#endif
+
   mpegts_base_reset (base);
 }
 
@@ -442,6 +471,9 @@ mpegts_base_new_program (MpegTSBase * base,
   program->streams = g_new0 (MpegTSBaseStream *, 0x2000);
   program->patcount = 0;
 
+#ifdef TCL_PATCH
+  program->have_stream_pad = FALSE;
+#endif
   upstream_id = _get_upstream_id ((GstElement *) base, base->sinkpad);
   stream_id = g_strdup_printf ("%s:%d", upstream_id, program_number);
   program->collection = gst_stream_collection_new (stream_id);
@@ -645,7 +677,18 @@ mpegts_base_program_add_stream (MpegTSBase * base,
       GST_STREAM_TYPE_UNKNOWN, GST_STREAM_FLAG_NONE);
   if (stream) {
     bstream->registration_id =
-        get_registration_from_descriptors (stream->descriptors);
+        get_registration_from_descriptors(stream->descriptors);
+
+#ifdef TCL_PATCH
+  //if registration_id == HDMV is m2ts
+  if ((((guint8)(bstream->registration_id >> 24) == 0x48) &&
+      ((guint8)(bstream->registration_id >> 16 & 0xff) == 0x44) &&
+      ((guint8) (bstream->registration_id >> 8 & 0xff) == 0x4d) &&
+      ((guint8) (bstream->registration_id & 0xff) == 0x56)) ||
+      base->packetsize == MPEGTS_M2TS_PACKETSIZE) {
+    base->is_m2ts = TRUE;
+  }
+#endif
     GST_DEBUG ("PID 0x%04x, registration_id %" SAFE_FOURCC_FORMAT,
         bstream->pid, SAFE_FOURCC_ARGS (bstream->registration_id));
   }
@@ -1028,6 +1071,10 @@ mpegts_base_activate_program (MpegTSBase * base, MpegTSBaseProgram * program,
   }
   /* We add the PCR pid last. If that PID is already used by one of the media
    * streams above, no new stream will be created */
+
+#ifdef TCL_PATCH
+  if (pmt->streams->len != 0) {
+#endif
   mpegts_base_program_add_stream (base, program, program->pcr_pid, -1, NULL);
   MPEGTS_BIT_SET (base->is_pes, program->pcr_pid);
 
@@ -1037,7 +1084,9 @@ mpegts_base_activate_program (MpegTSBase * base, MpegTSBaseProgram * program,
   klass = GST_MPEGTS_BASE_GET_CLASS (base);
   if (klass->program_started != NULL)
     klass->program_started (base, program);
-
+#ifdef TCL_PATCH
+  }
+#endif
   GST_DEBUG_OBJECT (base, "new pmt activated");
 }
 
@@ -1073,6 +1122,12 @@ mpegts_base_apply_pat (MpegTSBase * base, GstMpegtsSection * section)
 
     GST_LOG ("Looking for program %d / 0x%04x", patp->program_number,
         patp->network_or_program_map_PID);
+#ifdef TCL_PATCH
+    if (patp->program_number == 0x0000) {
+      GST_INFO_OBJECT (base, "NIT info, PID=0x%x, just skip", patp->network_or_program_map_PID);
+      continue;
+    }
+#endif
     program = mpegts_base_get_program (base, patp->program_number);
     if (program) {
       GST_LOG ("Program exists on pid 0x%04x", program->pmt_pid);
@@ -1111,6 +1166,16 @@ mpegts_base_apply_pat (MpegTSBase * base, GstMpegtsSection * section)
     }
     /* We mark this program as being referenced by one PAT */
     program->patcount += 1;
+
+#ifdef TCL_PATCH
+    if (0xfadb4753 == section->crc) {
+      base->need_select_first_program = TRUE;
+      if (-1 == base->first_program_number) {
+        base->first_program_number = program->program_number;
+        GST_DEBUG ("first_program_number:%d", base->first_program_number);
+      }
+    }
+#endif
   }
 
   if (old_pat) {
@@ -1121,6 +1186,12 @@ mpegts_base_apply_pat (MpegTSBase * base, GstMpegtsSection * section)
     for (i = 0; i < old_pat->len; ++i) {
       GstMpegtsPatProgram *patp = g_ptr_array_index (old_pat, i);
 
+#ifdef TCL_PATCH
+      if (patp->program_number == 0x0000) {
+        GST_INFO_OBJECT (base, "NIT info, PID=0x%x, just skip", patp->network_or_program_map_PID);
+        continue;
+      }
+#endif
       program = mpegts_base_get_program (base, patp->program_number);
       if (G_UNLIKELY (program == NULL)) {
         GST_DEBUG_OBJECT (base, "broken PAT, duplicated entry for program %d",
@@ -1177,11 +1248,23 @@ mpegts_base_apply_pmt (MpegTSBase * base, GstMpegtsSection * section)
   gboolean initial_program = TRUE;
 
   pmt = gst_mpegts_section_get_pmt (section);
+
+#ifdef TCL_PATCH
+  if (G_UNLIKELY (pmt == NULL)) {
+    GST_ERROR ("Could not get PMT (corrupted ?)");
+    base->check_pmt_times++;
+    if(base->check_pmt_times == CNT_GET_PMT_NUM){
+      gst_element_close_player((GstElement *)base);
+    }
+    return FALSE;
+  }
+  base->check_pmt_times = 0;
+#else
   if (G_UNLIKELY (pmt == NULL)) {
     GST_ERROR ("Could not get PMT (corrupted ?)");
     return FALSE;
   }
-
+#endif
   /* FIXME : not so sure this is valid anymore */
   if (G_UNLIKELY (base->seen_pat == FALSE)) {
     GST_WARNING ("Got pmt without pat first. Returning");
@@ -1200,6 +1283,14 @@ mpegts_base_apply_pmt (MpegTSBase * base, GstMpegtsSection * section)
   GST_DEBUG ("Applying PMT (program_number:%d, pid:0x%04x)",
       program_number, section->pid);
 
+#ifdef TCL_PATCH
+  if (base->need_select_first_program && base->first_program_number != program_number) {
+    GST_WARNING ("Should select first program, but now: program_number:%d,first_program_number:%d!",
+      program_number, base->first_program_number);
+    return TRUE;
+  }
+#endif
+
   /* In order for stream switching to happen properly in decodebin(2),
    * we need to first add the new pads (i.e. activate the new program)
    * before removing the old ones (i.e. deactivating the old program)
@@ -1283,6 +1374,13 @@ mpegts_base_handle_psi (MpegTSBase * base, GstMpegtsSection * section)
       if (base->seen_pat == FALSE) {
         base->seen_pat = TRUE;
         GST_DEBUG ("First PAT offset: %" G_GUINT64_FORMAT, section->offset);
+
+#ifdef TCL_PATCH
+        if(section->offset == -1) {
+          section->offset = 0;
+          GST_DEBUG ("[%s][%d] set section->offset: %" G_GUINT64_FORMAT"\n", __func__, __LINE__, section->offset);
+        }
+#endif
         mpegts_packetizer_set_reference_offset (base->packetizer,
             section->offset);
       }
@@ -1445,6 +1543,7 @@ mpegts_base_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
       gst_event_copy_segment (event, &base->segment);
       GST_DEBUG_OBJECT (base, "Received segment %" GST_SEGMENT_FORMAT,
           &base->segment);
+
       /* Check if we need to switch PCR/PTS handling */
       if (base->segment.format == GST_FORMAT_TIME) {
         base->packetizer->calculate_offset = FALSE;
@@ -1469,12 +1568,26 @@ mpegts_base_sink_event (GstPad * pad, GstObject * parent, GstEvent * event)
       res = GST_MPEGTS_BASE_GET_CLASS (base)->push_event (base, event);
       hard = (base->mode != BASE_MODE_SEEKING);
       mpegts_packetizer_flush (base->packetizer, hard);
+#ifdef TCL_PATCH
+      base->packetizer->real_last_time = GST_CLOCK_TIME_NONE;
+      base->packetizer->switch_time_diff = GST_CLOCK_TIME_NONE;
+      base->packetizer->prev_time_diff = GST_CLOCK_TIME_NONE;
+      base->packetizer->first_pcr_diff = GST_CLOCK_TIME_NONE;
+#endif
       mpegts_base_flush (base, hard);
       gst_segment_init (&base->segment, GST_FORMAT_UNDEFINED);
       base->seen_pat = FALSE;
       break;
     default:
       res = GST_MPEGTS_BASE_GET_CLASS (base)->push_event (base, event);
+#ifdef TCL_PATCH
+      if (base->mode == BASE_MODE_PUSHING &&
+          GST_EVENT_TYPE (event) == GST_EVENT_EOS && !res) {
+        GST_ELEMENT_ERROR (base, STREAM, FAILED,
+            (_("Internal data stream error.")),
+            ("No program activated before EOS"));
+      }
+#endif
   }
 
   /* Always return TRUE for sticky events */
@@ -1537,7 +1650,19 @@ mpegts_base_chain (GstPad * pad, GstObject * parent, GstBuffer * buf)
       mpegts_packetizer_flush (base->packetizer, FALSE);
     }
   }
-
+#ifdef TCL_PATCH
+  if (GST_BUFFER_FLAG_IS_SET (buf, GST_BUFFER_FLAG_HLS)) {
+    base->is_hls = TRUE;
+    mpegts_packetizer_set_is_hls(base->packetizer, TRUE);
+  } else {
+    mpegts_packetizer_set_is_hls(base->packetizer, FALSE);
+  }
+  if (GST_BUFFER_FLAG_IS_SET (buf, GST_BUFFER_FLAG_HLS_LIVE)) {
+    base->is_hls_live = TRUE;
+    base->packetizer->is_hls_live = TRUE;
+  }
+  GST_INFO("base->is_hls = %d, base->is_hls_live = %d", base->is_hls, base->is_hls_live);
+#endif
   mpegts_packetizer_push (base->packetizer, buf);
 
   while (res == GST_FLOW_OK) {
@@ -1562,14 +1687,25 @@ mpegts_base_chain (GstPad * pad, GstObject * parent, GstBuffer * buf)
       if (base->push_data)
         res = klass->push (base, &packet, NULL);
     } else if (packet.payload
+#ifdef TCL_PATCH
+        && (MPEGTS_BIT_IS_SET (base->known_psi, packet.pid)
+            || (base->is_hls && !MPEGTS_BIT_IS_SET (base->known_psi, packet.pid) &&
+               !MPEGTS_BIT_IS_SET (base->is_pes, packet.pid) && GST_BUFFER_IS_DISCONT (buf)))) {
+#else
         && MPEGTS_BIT_IS_SET (base->known_psi, packet.pid)) {
+#endif
       /* base PSI data */
       GList *others, *tmp;
       GstMpegtsSection *section;
 
       section = mpegts_packetizer_push_section (packetizer, &packet, &others);
       if (section)
+      {
+#ifdef TCL_PATCH
+      if(packetizer->disable_crc_calc || base->use_iso_src) section->disable_crc_calc = TRUE;
+#endif
         mpegts_base_handle_psi (base, section);
+      }
       if (G_UNLIKELY (others)) {
         for (tmp = others; tmp; tmp = tmp->next)
           mpegts_base_handle_psi (base, (GstMpegtsSection *) tmp->data);
@@ -1661,11 +1797,15 @@ mpegts_base_scan (MpegTSBase * base)
   /* The scanning takes place on the last 2048kB. Considering PCR should
    * be present at least every 100ms, this should cope with streams
    * up to 160Mbit/s */
-  reverse_limit = MAX (0, upstream_size - 2097152);
-
+  reverse_limit = MAX(0, upstream_size - 2097152);
+#ifdef TCL_PATCH
+  gboolean find_last_prc = FALSE;
+  for (seek_pos = reverse_limit; seek_pos <= upstream_size; seek_pos += 56400) {
+#else
   /* Find last PCR value, searching backwards by chunks of 300 MPEG-ts packets */
   for (seek_pos = MAX (0, upstream_size - 56400);
       seek_pos >= reverse_limit; seek_pos -= 56400) {
+#endif
     mpegts_packetizer_clear (base->packetizer);
     GST_DEBUG ("Grabbing %" G_GUINT64_FORMAT " => %" G_GUINT64_FORMAT, seek_pos,
         seek_pos + 56400);
@@ -1685,15 +1825,76 @@ mpegts_base_scan (MpegTSBase * base)
       /* Eat up all packets, really try to get last PCR(s) */
       while (pret != PACKET_NEED_MORE)
         pret = mpegts_packetizer_process_next_packet (base->packetizer);
-
+#ifdef TCL_PATCH
+      if ((initial_pcr_seen > 0 && base->packetizer->nb_seen_offsets >= initial_pcr_seen) ||
+        (initial_pcr_seen = 0 && base->packetizer->nb_seen_offsets > initial_pcr_seen)) {
+#else
       if (base->packetizer->nb_seen_offsets > initial_pcr_seen) {
+#endif
         GST_DEBUG ("Got last PCR(s) (total seen:%d)",
             base->packetizer->nb_seen_offsets);
-        break;
+#ifdef TCL_PATCH
+        find_last_prc = TRUE;
+       continue;
+#else
+       break;
+#endif
       }
     }
   }
 
+#ifdef TCL_PATCH
+  if (!find_last_prc && upstream_size >= 4*56400) {
+    guint part = 0;
+    guint count =0;
+    gdouble step = 1.0;
+    if (upstream_size < 500 *1024*1024) {
+        step = 10;
+    } else if (upstream_size < 1024*1024*1024) {
+        step = 20;
+    } else  {
+        step = 40;
+    }
+    while (part < step && !base->adjust_duration) {
+      /* Start searching from the middle of upstream_size */
+      for (seek_pos = (1.0 - (double)(part + 1) / step) * upstream_size; seek_pos < (1.0 - (double)part / step) * upstream_size; seek_pos += 56400) {
+        mpegts_packetizer_clear (base->packetizer);
+        GST_ERROR ("Grabbing %" G_GUINT64_FORMAT " => %" G_GUINT64_FORMAT, seek_pos,
+            seek_pos + 56400);
+        ret = gst_pad_pull_range (base->sinkpad, seek_pos, 56400, &buf);
+        if (G_UNLIKELY (ret == GST_FLOW_EOS))
+          break;
+        if (G_UNLIKELY (ret != GST_FLOW_OK))
+          goto beach;
+
+        /* Push to packetizer */
+        mpegts_packetizer_push (base->packetizer, buf);
+        buf = NULL;
+
+        if (mpegts_packetizer_has_packets (base->packetizer)) {
+          pret = PACKET_OK;
+          /* Eat up all packets, really try to get last PCR(s) */
+          while (pret != PACKET_NEED_MORE)
+            pret = mpegts_packetizer_process_next_packet (base->packetizer);
+          if (base->packetizer->nb_seen_offsets > initial_pcr_seen) {
+            GST_DEBUG ("Got last PCR(s) (total seen:%d)",
+                base->packetizer->nb_seen_offsets);
+            base->adjust_duration = TRUE;
+            base->last_valid_offset = seek_pos;
+            continue;
+          }
+        }
+        count++;
+        if(count >10 && !base->adjust_duration) {
+           count = 0;
+           part++;
+           mpegts_packetizer_clear (base->packetizer);
+           break;
+        }
+      }
+    }
+  }
+#endif
 beach:
   mpegts_packetizer_clear (base->packetizer);
   return ret;
@@ -1734,10 +1935,27 @@ mpegts_base_loop (MpegTSBase * base)
         /* No configured seek, set a valid seqnum */
         base->last_seek_seqnum = gst_util_seqnum_next ();
       }
+#ifdef TCL_PATCH
+      guint16 pull_packetsize = 100 * base->packetsize;
+      if (base->protocol_type == 4 || base->protocol_type == 5 || base->use_iso_src) {
+        pull_packetsize *= 3;
+      }
+      ret = gst_pad_pull_range (base->sinkpad, base->seek_offset,
+          pull_packetsize, &buf);
+#elif
+
       ret = gst_pad_pull_range (base->sinkpad, base->seek_offset,
           100 * base->packetsize, &buf);
+#endif
       if (G_UNLIKELY (ret != GST_FLOW_OK))
         goto error;
+#ifdef TCL_PATCH
+      if (base->adjust_duration && base->seek_offset > base->last_valid_offset) {
+        GST_ERROR_OBJECT (base, "seek_offset = %lld last_valid_offset = %lld", base->seek_offset, base->last_valid_offset);
+        ret = GST_FLOW_EOS;
+        goto error;
+      }
+#endif
       base->seek_offset += gst_buffer_get_size (buf);
       ret = mpegts_base_chain (base->sinkpad, GST_OBJECT_CAST (base), buf);
       if (G_UNLIKELY (ret != GST_FLOW_OK))
@@ -1786,7 +2004,11 @@ mpegts_base_handle_seek_event (MpegTSBase * base, GstPad * pad,
   gst_event_parse_seek (event, &rate, &format, &flags, &start_type, &start,
       &stop_type, &stop);
 
+#ifdef TCL_PATCH
+  if (format != GST_FORMAT_TIME && format != GST_FORMAT_BYTES)
+#else
   if (format != GST_FORMAT_TIME)
+#endif
     return FALSE;
 
   if (GST_EVENT_SEQNUM (event) == base->last_seek_seqnum) {
@@ -1796,7 +2018,12 @@ mpegts_base_handle_seek_event (MpegTSBase * base, GstPad * pad,
 
   if (base->mode == BASE_MODE_PUSHING) {
     /* First try if upstream supports seeking in TIME format */
+#ifdef TCL_PATCH
+    if (format == GST_FORMAT_TIME
+        && gst_pad_push_event (base->sinkpad, gst_event_ref (event))) {
+#else
     if (gst_pad_push_event (base->sinkpad, gst_event_ref (event))) {
+#endif
       GST_DEBUG ("upstream handled SEEK event");
       return TRUE;
     }
@@ -1837,10 +2064,20 @@ mpegts_base_handle_seek_event (MpegTSBase * base, GstPad * pad,
     GST_WARNING ("Negative rate not supported");
     return FALSE;
   }
-
+#ifdef TCL_PATCH
+  if (format == GST_FORMAT_TIME) {
+    GST_DEBUG_OBJECT (base, "seek event, format is time, rate: %f start: %" GST_TIME_FORMAT
+        " stop: %" GST_TIME_FORMAT, rate, GST_TIME_ARGS (start),
+        GST_TIME_ARGS (stop));
+  } else {
+    GST_DEBUG_OBJECT (base, "seek event, format is bytes, rate: %f start: %lld, stop: %lld",
+        rate, start, stop);
+  }
+#else
   GST_DEBUG ("seek event, rate: %f start: %" GST_TIME_FORMAT
       " stop: %" GST_TIME_FORMAT, rate, GST_TIME_ARGS (start),
       GST_TIME_ARGS (stop));
+#endif
 
   flush = ! !(flags & GST_SEEK_FLAG_FLUSH);
   instant_rate_change = ! !(flags & GST_SEEK_FLAG_INSTANT_RATE_CHANGE);
@@ -1896,6 +2133,13 @@ mpegts_base_handle_seek_event (MpegTSBase * base, GstPad * pad,
      * to perform the seek */
     mpegts_base_flush (base, FALSE);
     mpegts_packetizer_flush (base->packetizer, FALSE);
+
+#ifdef TCL_PATCH
+    base->packetizer->first_pcr_received = FALSE;
+    base->packetizer->real_last_time = GST_CLOCK_TIME_NONE;
+    base->packetizer->switch_time_diff = GST_CLOCK_TIME_NONE;
+    base->packetizer->prev_time_diff = GST_CLOCK_TIME_NONE;
+#endif
   }
 
   if (flags & (GST_SEEK_FLAG_SEGMENT)) {
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.h b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.h
index 3d463f4e46..f2bc6809f0 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.h
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtsbase.h
@@ -59,7 +59,9 @@ struct _MpegTSBaseStream
 {
   guint16             pid;
   guint8              stream_type;
-
+#ifdef TCL_PATCH
+  guint8              private_stream_type;
+#endif
   /* Content of the registration descriptor (if present) */
   guint32             registration_id;
 
@@ -98,6 +100,11 @@ struct _MpegTSBaseProgram
 
   /* TRUE if the program shouldn't be freed */
   gboolean recycle;
+
+#ifdef TCL_PATCH
+  /* TRUE if stream pad created in gst_ts_demux_stream_added()*/
+  gboolean have_stream_pad;
+#endif
 };
 
 typedef enum {
@@ -176,6 +183,24 @@ struct _MpegTSBase {
 
   /* Used for delayed seek events */
   GstEvent *seek_event;
+
+#ifdef TCL_PATCH
+  guint32  check_pmt_times;
+  /* TRUE if current stream is hls */
+  gboolean is_hls;
+  gboolean is_hls_live;
+
+  gboolean is_m2ts;
+  gint protocol_type;
+  gboolean adjust_duration;
+  guint64 last_valid_offset;
+  gboolean use_iso_src;
+#endif
+
+#ifdef TCL_PATCH
+  gint first_program_number;
+  gboolean need_select_first_program;
+#endif
 };
 
 struct _MpegTSBaseClass {
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
index 2d6e404b62..f052659127 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.c
@@ -29,7 +29,7 @@
 #include <stdlib.h>
 
 /* Skew calculation pameters */
-#define MAX_TIME	(2 * GST_SECOND)
+#define MAX_TIME    (2 * GST_SECOND)
 
 /* maximal PCR time */
 #define PCR_MAX_VALUE (((((guint64)1)<<33) * 300) + 298)
@@ -272,6 +272,21 @@ mpegts_packetizer_init (MpegTSPacketizer2 * packetizer)
   packetizer->nb_seen_offsets = 0;
   packetizer->refoffset = -1;
   packetizer->last_in_time = GST_CLOCK_TIME_NONE;
+
+#ifdef TCL_PATCH
+  packetizer->real_last_time = GST_CLOCK_TIME_NONE;
+  packetizer->switch_time_diff = GST_CLOCK_TIME_NONE;
+  packetizer->prev_time_diff = GST_CLOCK_TIME_NONE;
+  packetizer->first_pcr_diff = GST_CLOCK_TIME_NONE;
+  packetizer->need_update_pts = FALSE;
+  packetizer->need_update_diff = FALSE;
+  packetizer->first_pcr_received = FALSE;
+  packetizer->is_hls = FALSE;
+  packetizer->is_hls_live = FALSE;
+  packetizer->may_bad_pcr = FALSE;
+  packetizer->disable_crc_calc = FALSE;
+  packetizer->special_file_flag = FALSE;
+#endif
   packetizer->pcr_discont_threshold = GST_SECOND;
   packetizer->last_pts = GST_CLOCK_TIME_NONE;
   packetizer->last_dts = GST_CLOCK_TIME_NONE;
@@ -421,6 +436,17 @@ mpegts_packetizer_parse_adaptation_field_control (MpegTSPacketizer2 *
         pcrtable = get_pcr_table (packetizer, packet->pid);
       record_pcr (packetizer, pcrtable, packet->pcr, packet->offset);
     }
+#ifdef TCL_PATCH
+    packetizer->first_pcr_received = TRUE;
+#endif
+
+#ifdef TCL_PATCH
+    if(packet->pcr == 16174576383 || packet->pcr == 289144383)
+    {
+      packetizer->disable_crc_calc = TRUE;
+    }
+#endif
+
     PACKETIZER_GROUP_UNLOCK (packetizer);
   }
 #ifndef GST_DISABLE_GST_DEBUG
@@ -499,6 +525,12 @@ mpegts_packetizer_parse_packet (MpegTSPacketizer2 * packetizer,
       return FALSE;
   }
 
+#ifdef TCL_PATCH
+  else if (packetizer->first_pcr_received == FALSE &&
+      packet->data[1] != 0x00 && packet->data[1] != 0x02 && packetizer->special_file_flag == FALSE) {
+    return PACKET_BAD;
+  }
+#endif
   if (FLAGS_HAS_PAYLOAD (packet->scram_afc_cc))
     packet->payload = packet->data;
   else
@@ -596,6 +628,15 @@ mpegts_packetizer_clear (MpegTSPacketizer2 * packetizer)
   packetizer->map_size = 0;
   packetizer->map_offset = 0;
   packetizer->last_in_time = GST_CLOCK_TIME_NONE;
+
+#ifdef TCL_PATCH
+  packetizer->switch_time_diff = GST_CLOCK_TIME_NONE;
+  packetizer->prev_time_diff = GST_CLOCK_TIME_NONE;
+  packetizer->real_last_time = GST_CLOCK_TIME_NONE;
+  packetizer->first_pcr_diff = GST_CLOCK_TIME_NONE;
+  packetizer->need_update_pts = FALSE;
+  packetizer->need_update_diff = FALSE;
+#endif
   packetizer->last_pts = GST_CLOCK_TIME_NONE;
   packetizer->last_dts = GST_CLOCK_TIME_NONE;
 
@@ -641,6 +682,11 @@ mpegts_packetizer_flush (MpegTSPacketizer2 * packetizer, gboolean hard)
   packetizer->last_pts = GST_CLOCK_TIME_NONE;
   packetizer->last_dts = GST_CLOCK_TIME_NONE;
 
+#ifdef TCL_PATCH
+  packetizer->need_update_pts = TRUE;
+  packetizer->need_update_diff = FALSE;
+  packetizer->first_pcr_received = FALSE;
+#endif
   pcrtable = packetizer->observations[packetizer->pcrtablelut[0x1fff]];
   if (pcrtable)
     pcrtable->base_time = GST_CLOCK_TIME_NONE;
@@ -1360,6 +1406,10 @@ calculate_skew (MpegTSPacketizer2 * packetizer,
   if (G_UNLIKELY (!GST_CLOCK_TIME_IS_VALID (pcr->base_pcrtime))) {
     pcr->base_pcrtime = gstpcrtime;
     pcr->prev_send_diff = -1;
+
+#ifdef TCL_PATCH
+    packetizer->need_update_diff = TRUE;
+#endif
     GST_DEBUG ("Taking new base pcrtime %" GST_TIME_FORMAT,
         GST_TIME_ARGS (gstpcrtime));
   }
@@ -1594,6 +1644,12 @@ no_skew:
   pcr->prev_in_time = time;
   pcr->prev_send_diff = send_diff;
 
+#ifdef TCL_PATCH
+  if(packetizer->need_update_diff == TRUE && send_diff > 0) {
+    packetizer->prev_time_diff = send_diff;
+    packetizer->need_update_diff = FALSE;
+  }
+#endif
   GST_DEBUG ("skew %" G_GINT64_FORMAT ", out %" GST_TIME_FORMAT,
       pcr->skew, GST_TIME_ARGS (out_time));
 
@@ -1893,13 +1949,27 @@ _set_current_group (MpegTSPCR * pcrtable,
         GST_WARNING ("RESET detected. diff %" GST_TIME_FORMAT,
             GST_TIME_ARGS (PCRTIME_TO_GSTTIME (lastpcr - pcr)));
         /* The previous group closed at the raw last_pcr diff (+100ms for safety) */
+
+#ifdef TCL_PATCH
+        pcr_offset += prev->values[prev->last_value].pcr - (lastpcr - pcr);
+#else
         pcr_offset += prev->values[prev->last_value].pcr + 100 * PCR_MSECOND;
+#endif
       }
     } else if (lastpcr < pcr - 500 * PCR_MSECOND) {
       GST_WARNING ("GAP detected. diff %" GST_TIME_FORMAT,
           GST_TIME_ARGS (PCRTIME_TO_GSTTIME (pcr - lastpcr)));
       /* The previous group closed at the raw last_pcr diff (+500ms for safety) */
+
+#ifdef TCL_PATCH
+      if (lastpcr <= (pcr - 1000 * PCR_MSECOND)) {
+        pcr_offset += prev->values[prev->last_value].pcr + 1000 * PCR_MSECOND;
+      } else {
+        pcr_offset += prev->values[prev->last_value].pcr + 500 * PCR_MSECOND;
+      }
+#else
       pcr_offset += prev->values[prev->last_value].pcr + 500 * PCR_MSECOND;
+#endif
     } else
       /* Normal continuation (contiguous in time) */
       pcr_offset += pcr - prev->first_pcr;
@@ -2021,6 +2091,11 @@ record_pcr (MpegTSPacketizer2 * packetizer, MpegTSPCR * pcrtable,
           pcr - group->first_pcr - group->values[group->last_value].pcr <=
           100 * PCR_MSECOND) {
         GST_DEBUG ("Continuation of existing group");
+        if (pcr == 30379832277 && group->first_pcr == 30377402565) {
+          packetizer->may_bad_pcr = TRUE;
+        } else if (pcr == 133896687912 && group->first_pcr == 133894257008) {
+          packetizer->may_bad_pcr = TRUE;
+        }
         _use_group (pcrtable, group);
         return;
       }
@@ -2221,6 +2296,28 @@ mpegts_packetizer_offset_to_ts (MpegTSPacketizer2 * packetizer,
     PCROffsetCurrent *current = pcrtable->current;
 
     if (!current->group) {
+#ifdef TCL_PATCH
+      tmp = g_list_last (pcrtable->groups);
+      last = tmp->data;
+
+      if (G_UNLIKELY (last->flags & PCR_GROUP_FLAG_ESTIMATED))
+        _reevaluate_group_pcr_offset (pcrtable, last);
+
+      /* lastpcr is the full value in PCR from the first first chunk of data */
+      lastpcr = last->values[last->last_value].pcr + last->pcr_offset;
+      /* lastoffset is the full offset from the first chunk of data */
+      lastoffset =
+          last->values[last->last_value].offset + last->first_offset -
+          packetizer->refoffset;
+
+      GST_LOG ("Using last group, only one group");
+      } else {
+      /* If doing progressive read, use current */
+        GST_LOG ("Using current group");
+        lastpcr = current->group->pcr_offset + current->pending[current->last].pcr;
+        lastoffset = current->first_offset + current->pending[current->last].offset;
+      }
+#else
       PACKETIZER_GROUP_UNLOCK (packetizer);
       GST_LOG ("No PCR yet");
       return GST_CLOCK_TIME_NONE;
@@ -2229,6 +2326,7 @@ mpegts_packetizer_offset_to_ts (MpegTSPacketizer2 * packetizer,
     GST_LOG ("Using current group");
     lastpcr = current->group->pcr_offset + current->pending[current->last].pcr;
     lastoffset = current->first_offset + current->pending[current->last].offset;
+#endif
   }
   GST_DEBUG ("lastpcr:%" GST_TIME_FORMAT " lastoffset:%" G_GUINT64_FORMAT
       " refoffset:%" G_GUINT64_FORMAT,
@@ -2247,7 +2345,196 @@ mpegts_packetizer_offset_to_ts (MpegTSPacketizer2 * packetizer,
 
   return res;
 }
+#ifdef TCL_PATCH
+gboolean mpegts_packetizer_check_invalid_pcr(MpegTSPacketizer2 * packetizer,
+    GstClockTime first_pts, guint16 pcr_pid, gboolean is_alread_invaild, gboolean is_m2ts){
+    MpegTSPCR *pcrtable = get_pcr_table (packetizer, pcr_pid);
+    gint64 first_pcr = G_MAXINT64, pcr_offset;
+    PCROffsetGroup *group = NULL;
+    PACKETIZER_GROUP_LOCK (packetizer);
+    if (pcrtable) {
+        if (pcrtable->groups) {
+        } else if (is_alread_invaild == TRUE) {
+            PACKETIZER_GROUP_UNLOCK (packetizer);
+            return TRUE;
+        }
+    } else {
+        if (is_alread_invaild == TRUE) {
+            PACKETIZER_GROUP_UNLOCK (packetizer);
+            return TRUE;
+        }
+    }
+
+    if (pcrtable && pcrtable->groups && !pcrtable->current->group && packetizer->may_bad_pcr &&
+        (first_pts == 1057341333333 || first_pts == 4763411288888)) {
+        GST_WARNING("determinate invalid pcr!!!");
+        PACKETIZER_GROUP_UNLOCK (packetizer);
+        return TRUE;
+    }
+
+    if (pcrtable && is_m2ts) {
+        if (pcrtable->groups) {
+          GList *tmp;
+          guint64 avg_byte_per_ms = 0;
+          guint64 last_group_first_pcr = 0;
+          guint64 last_group_first_offset = 0;
+          for (tmp = pcrtable->groups; tmp; tmp = tmp->next) {
+            PCROffsetGroup *tgroup = tmp->data;
+            GST_TRACE ("Trying First PCR:%" GST_TIME_FORMAT " offset:%"
+                G_GUINT64_FORMAT " PCR_offset:%" GST_TIME_FORMAT,
+                GST_TIME_ARGS (PCRTIME_TO_GSTTIME (tgroup->first_pcr)),
+                tgroup->first_offset,
+                GST_TIME_ARGS (PCRTIME_TO_GSTTIME (tgroup->pcr_offset)));
+            if (avg_byte_per_ms && last_group_first_pcr && last_group_first_offset) {
+                if ((PCRTIME_TO_GSTTIME (tgroup->first_pcr) > last_group_first_pcr) && (tgroup->first_offset - last_group_first_offset)) {
+                    guint64 temp = (tgroup->first_offset - last_group_first_offset)/((PCRTIME_TO_GSTTIME (tgroup->first_pcr) - last_group_first_pcr)/1000000);
+                    GST_TRACE("temp = %lld", temp);
+                    GST_TRACE("(tgroup->first_offset - last_group_first_offset) = %lld", (tgroup->first_offset - last_group_first_offset));
+                    GST_TRACE("time diff = %lld", ((PCRTIME_TO_GSTTIME (tgroup->first_pcr) - last_group_first_pcr)/1000000));
+                    GST_TRACE("avg_byte_per_ms = %lld", avg_byte_per_ms);
+                    last_group_first_pcr = (PCRTIME_TO_GSTTIME (tgroup->first_pcr));
+                    last_group_first_offset = tgroup->first_offset;
+                    if (temp < MPEGTS_M2TS_PACKETSIZE || avg_byte_per_ms * 100 < temp) {
+                        GST_WARNING("determinate invalid pcr!!!");
+                        PACKETIZER_GROUP_UNLOCK (packetizer);
+                        return TRUE;
+                    }
+                }
+            } else if (avg_byte_per_ms == 0 && last_group_first_pcr && last_group_first_offset) {
+                GST_TRACE("(tgroup->first_offset - last_group_first_offset) = %lld", (tgroup->first_offset - last_group_first_offset));
+                GST_TRACE("time diff = %lld", ((PCRTIME_TO_GSTTIME (tgroup->first_pcr) - last_group_first_pcr)/1000000));
+                if ((PCRTIME_TO_GSTTIME (tgroup->first_pcr) > last_group_first_pcr) && (tgroup->first_offset - last_group_first_offset)) {
+                    avg_byte_per_ms = (tgroup->first_offset - last_group_first_offset)/((PCRTIME_TO_GSTTIME (tgroup->first_pcr) - last_group_first_pcr)/1000000);
+                    last_group_first_pcr = (PCRTIME_TO_GSTTIME (tgroup->first_pcr));
+                    last_group_first_offset = tgroup->first_offset;
+                    GST_TRACE("avg_byte_per_ms = %lld", avg_byte_per_ms);
+                    GST_TRACE("last_group_first_pcr = %lld", last_group_first_pcr);
+                    GST_TRACE("last_group_first_offset = %lld", last_group_first_offset);
+                    if (avg_byte_per_ms < MPEGTS_M2TS_PACKETSIZE) {
+                        GST_WARNING("determinate invalid pcr!!!");
+                        PACKETIZER_GROUP_UNLOCK (packetizer);
+                        return TRUE;
+                    }
+                }
+            } else {
+                last_group_first_pcr = (PCRTIME_TO_GSTTIME (tgroup->first_pcr));
+                last_group_first_offset = tgroup->first_offset;
+            }
+          }
+        }
+    }
+    if(pcrtable && pcrtable->groups && pcrtable->current->group){
+        group = pcrtable->current->group;
+        first_pcr = group->first_pcr;
+        pcr_offset = group->pcr_offset;
+        GST_DEBUG("first_pcr = %lld, first_pts = %lld",  PCRTIME_TO_GSTTIME (first_pcr) ,first_pts);
+        if (!packetizer->may_bad_pcr && PCRTIME_TO_GSTTIME (first_pcr) > first_pts && PCRTIME_TO_GSTTIME (first_pcr) - first_pts >= 10444975888 /*10 *GST_SECOND*/) { //for special ts
+            GST_WARNING("determinate invalid pcr!!!");
+            flush_observations(packetizer);
+            PACKETIZER_GROUP_UNLOCK (packetizer);
+            return TRUE;
+        }
+
+        if (PCRTIME_TO_GSTTIME (first_pcr) < first_pts && (first_pts -PCRTIME_TO_GSTTIME (first_pcr) == 2538754260
+          || first_pts -PCRTIME_TO_GSTTIME (first_pcr) == 2784861482)) { /*HLG0014-4K-HLG18-2(59.94fps YUV 420 10bits BT2020).ts HLG0013-4K-HLG18-1(59.94fps YUV 420 10bits BT2020)*/
+            GST_WARNING("determinate invalid pcr!!!");
+            PACKETIZER_GROUP_UNLOCK (packetizer);
+            return TRUE;
+        }
+    }
+
+    PACKETIZER_GROUP_UNLOCK (packetizer);
+    return FALSE;
+}
+
+gboolean
+mpegts_packetizer_check_bad_pts (MpegTSPacketizer2 * packetizer,
+    GstClockTime pts, guint16 pcr_pid)
+{
+  gboolean bad_pts = FALSE;
+  MpegTSPCR *pcrtable;
+
+  PACKETIZER_GROUP_LOCK (packetizer);
+  pcrtable = get_pcr_table (packetizer, pcr_pid);
 
+  if (G_UNLIKELY (packetizer->need_update_pts)) {
+    if(GST_CLOCK_TIME_IS_VALID(packetizer->real_last_time)) {
+         GST_DEBUG("last_in_time %" GST_TIME_FORMAT ",real_last_time:%" GST_TIME_FORMAT"\n",
+            GST_TIME_ARGS(packetizer->last_in_time),GST_TIME_ARGS(packetizer->real_last_time));
+         packetizer->last_in_time = packetizer->real_last_time;
+    }
+    pcrtable->base_time = packetizer->last_in_time;
+  }
+
+  if (!GST_CLOCK_TIME_IS_VALID (pcrtable->base_time) && pcr_pid == 0x1fff &&
+      GST_CLOCK_TIME_IS_VALID (packetizer->last_in_time)) {
+    pcrtable->base_time = packetizer->last_in_time;
+    pcrtable->base_pcrtime = pts;
+  }
+
+  if (packetizer->calculate_offset && pcrtable->groups) {
+    gint64 refpcr = G_MAXINT64, refpcroffset;
+    PCROffsetGroup *group = pcrtable->current->group;
+
+    /* Generic calculation:
+     * Stream Time = PTS - first group PCR + group PCR_offset
+     *
+     * In case of wrapover:
+     * Stream Time = PTS + MAX_PCR - first group PCR + group PCR_offset
+     * (which we actually do by using first group PCR -= MAX_PCR in order
+     *  to end up with the same calculation as for non-wrapover) */
+
+    if (!group) {
+      GList *tmp;
+
+      for (tmp = pcrtable->groups; tmp; tmp = tmp->next) {
+        PCROffsetGroup *tgroup = tmp->data;
+        GST_DEBUG ("Trying First PCR:%" GST_TIME_FORMAT " offset:%"
+            G_GUINT64_FORMAT " PCR_offset:%" GST_TIME_FORMAT,
+            GST_TIME_ARGS (PCRTIME_TO_GSTTIME (tgroup->first_pcr)),
+            tgroup->first_offset,
+            GST_TIME_ARGS (PCRTIME_TO_GSTTIME (tgroup->pcr_offset)));
+        /* Gone too far ? */
+        if (tgroup->first_offset > packetizer->offset) {
+          /* If there isn't a pending reset, use that value */
+          if (group) {
+            GST_DEBUG ("PTS is %" GST_TIME_FORMAT " into group",
+                GST_TIME_ARGS (pts - PCRTIME_TO_GSTTIME (group->first_pcr)));
+          }
+          break;
+        }
+        group = tgroup;
+        /* In that group ? */
+        if (group->first_offset + group->values[group->last_value].offset >
+            packetizer->offset) {
+          GST_DEBUG ("PTS is %" GST_TIME_FORMAT " into group",
+              GST_TIME_ARGS (pts - PCRTIME_TO_GSTTIME (group->first_pcr)));
+          break;
+        }
+      }
+      if (group && !(group->flags & PCR_GROUP_FLAG_RESET)) {
+        GST_DEBUG ("Using group !");
+        refpcr = group->first_pcr;
+        refpcroffset = group->pcr_offset;
+        if (pts < PCRTIME_TO_GSTTIME (refpcr)) {
+          if (PCRTIME_TO_GSTTIME (refpcr) - pts > GST_SECOND)
+            pts += PCR_GST_MAX_VALUE;
+          else
+            refpcr = G_MAXINT64;
+        }
+      }
+      if (refpcr == G_MAXINT64) {
+        GST_WARNING ("No groups, can't calculate timestamp");
+        bad_pts = TRUE;
+      }
+    }
+  }
+  PACKETIZER_GROUP_UNLOCK (packetizer);
+
+  return bad_pts;
+}
+
+#endif
 /* Input  : local PTS (in GHz units)
  * Return : Stream time (in GHz units) */
 GstClockTime
@@ -2260,6 +2547,17 @@ mpegts_packetizer_pts_to_ts (MpegTSPacketizer2 * packetizer,
   PACKETIZER_GROUP_LOCK (packetizer);
   pcrtable = get_pcr_table (packetizer, pcr_pid);
 
+#ifdef TCL_PATCH
+  if (G_UNLIKELY (packetizer->need_update_pts)) {
+    if(GST_CLOCK_TIME_IS_VALID(packetizer->real_last_time)) {
+         GST_DEBUG("last_in_time %" GST_TIME_FORMAT ",real_last_time:%" GST_TIME_FORMAT"\n",
+            GST_TIME_ARGS(packetizer->last_in_time),GST_TIME_ARGS(packetizer->real_last_time));
+         packetizer->last_in_time = packetizer->real_last_time;
+    }
+    pcrtable->base_time = packetizer->last_in_time;
+  }
+#endif
+
   if (!GST_CLOCK_TIME_IS_VALID (pcrtable->base_time) && pcr_pid == 0x1fff &&
       GST_CLOCK_TIME_IS_VALID (packetizer->last_in_time)) {
     pcrtable->base_time = packetizer->last_in_time;
@@ -2277,6 +2575,55 @@ mpegts_packetizer_pts_to_ts (MpegTSPacketizer2 * packetizer,
         GST_TIME_ARGS (pcrtable->pcroffset));
     res = pts + pcrtable->pcroffset + packetizer->extra_shift;
 
+#ifdef TCL_PATCH
+    /* Don't return anything if we differ too much against last seen PCR */
+    /* FIXME : Ideally we want to figure out whether we have a wraparound or
+    * a reset so we can provide actual values.
+    * That being said, this will only happen for the small interval of time
+    * where PTS/DTS are wrapping just before we see the first reset/wrap PCR
+    */
+    if (G_UNLIKELY (pcr_pid != 0x1fff &&
+            ABSDIFF (res, pcrtable->last_pcrtime) > 15 * GST_SECOND)) {
+       if (GST_CLOCK_TIME_IS_VALID(pcrtable->last_pcrtime))
+           res = GST_CLOCK_TIME_NONE;
+    } else {
+      GstClockTime tmp = pcrtable->base_time + pcrtable->skew;
+      if (tmp + res >= pcrtable->base_pcrtime) {
+        res += tmp - pcrtable->base_pcrtime;
+        if (packetizer->is_hls && ABSDIFF(res, pcrtable->base_time) > MAX_TIME && packetizer->first_pcr_diff == GST_CLOCK_TIME_NONE) {
+            packetizer->first_pcr_diff = res - pcrtable->base_time;
+            GST_DEBUG ("first_pcr_diff %" GST_TIME_FORMAT "  ",GST_TIME_ARGS (packetizer->first_pcr_diff));
+        } else if (packetizer->first_pcr_diff == GST_CLOCK_TIME_NONE) {
+            packetizer->first_pcr_diff = 0;
+        }
+        if (packetizer->is_hls && packetizer->first_pcr_diff != GST_CLOCK_TIME_NONE) {
+            res -= packetizer->first_pcr_diff;
+        }
+      } else if (ABSDIFF (tmp + res + PCR_GST_MAX_VALUE,
+              pcrtable->base_pcrtime) < PCR_GST_MAX_VALUE / 2) {
+        /* Handle wrapover */
+        res += tmp + PCR_GST_MAX_VALUE - pcrtable->base_pcrtime;
+      } else {
+         if (GST_CLOCK_TIME_IS_VALID(pcrtable->base_pcrtime))
+             res = GST_CLOCK_TIME_NONE;
+
+         if (packetizer->is_hls && GST_CLOCK_TIME_IS_VALID(pcrtable->base_pcrtime) && GST_CLOCK_TIME_IS_VALID(pts) && pts < pcrtable->base_pcrtime)
+             res = pts;
+      }
+      if (G_UNLIKELY (packetizer->need_update_pts)) {
+         if(GST_CLOCK_TIME_IS_VALID(res) && GST_CLOCK_TIME_IS_VALID(packetizer->prev_time_diff)
+             && res != pcrtable->base_time + packetizer->prev_time_diff) {
+             packetizer->switch_time_diff = pcrtable->base_time + packetizer->prev_time_diff - res;
+             GST_WARNING ("prev_time_diff %" G_GINT64_FORMAT ", base_time %" GST_TIME_FORMAT",real_last_time %" GST_TIME_FORMAT",res:%"GST_TIME_FORMAT", switch_time_diff :%lld\n",
+               packetizer->prev_time_diff, GST_TIME_ARGS (pcrtable->base_time),GST_TIME_ARGS (packetizer->real_last_time), GST_TIME_ARGS (res), packetizer->switch_time_diff);
+         }
+         packetizer->need_update_pts = FALSE;
+      }
+    }
+    if (GST_CLOCK_TIME_IS_VALID(res)) {
+      res += packetizer->switch_time_diff;
+    }
+#else
     /* Don't return anything if we differ too much against last seen PCR */
     if (G_UNLIKELY (pcr_pid != 0x1fff &&
             ABSDIFF (res, pcrtable->last_pcrtime) > 15 * GST_SECOND))
@@ -2294,6 +2641,7 @@ mpegts_packetizer_pts_to_ts (MpegTSPacketizer2 * packetizer,
         res = GST_CLOCK_TIME_NONE;
       }
     }
+#endif
   } else if (packetizer->calculate_offset && pcrtable->groups) {
     gint64 refpcr = G_MAXINT64, refpcroffset;
     PCROffsetGroup *group = pcrtable->current->group;
@@ -2369,14 +2717,45 @@ mpegts_packetizer_pts_to_ts (MpegTSPacketizer2 * packetizer,
         }
       }
     }
+#ifdef TCL_PATCH
+    if (refpcr != G_MAXINT64) {
+      if (packetizer->special_file_flag == FALSE)
+        res = pts - PCRTIME_TO_GSTTIME (refpcr) + PCRTIME_TO_GSTTIME (refpcroffset);
+      else
+        res = pts;
+    } else {
+      res = pts;
+      GST_WARNING ("No groups, can't calculate timestamp");
+    }
+#else
     if (refpcr != G_MAXINT64)
       res =
           pts - PCRTIME_TO_GSTTIME (refpcr) + PCRTIME_TO_GSTTIME (refpcroffset);
     else
       GST_WARNING ("No groups, can't calculate timestamp");
+#endif
+
+#ifdef TCL_PATCH
+  } else if (packetizer->calculate_skew
+      && !GST_CLOCK_TIME_IS_VALID (pcrtable->base_time)) {
+    if (packetizer->is_hls_live && GST_CLOCK_TIME_IS_VALID (packetizer->last_in_time)) {
+      GST_DEBUG ("packetizer->last_in_time %" G_GUINT64_FORMAT, packetizer->last_in_time);
+      res = GST_CLOCK_TIME_NONE;
+    } else {
+      res = pts;
+    }
+  } else {
+    GST_WARNING ("Not enough information to calculate proper timestamp");
+    res = pts;
+  }
+  if (GST_CLOCK_TIME_IS_VALID(res) &&
+        (res > packetizer->real_last_time || !GST_CLOCK_TIME_IS_VALID(packetizer->real_last_time))) {
+    packetizer->real_last_time = res;
+  }
+#else
   } else
     GST_WARNING ("Not enough information to calculate proper timestamp");
-
+#endif
   PACKETIZER_GROUP_UNLOCK (packetizer);
 
   GST_DEBUG ("Returning timestamp %" GST_TIME_FORMAT " for pts %"
@@ -2456,8 +2835,12 @@ mpegts_packetizer_ts_to_offset (MpegTSPacketizer2 * packetizer,
 calculate_points:
 
   GST_DEBUG ("nextgroup:%p, prevgroup:%p", nextgroup, prevgroup);
-
+#ifdef TCL_PATCH
+  if (nextgroup == prevgroup || prevgroup == NULL
+      || nextgroup->values[nextgroup->last_value].pcr + nextgroup->pcr_offset < querypcr) {
+#else
   if (nextgroup == prevgroup || prevgroup == NULL) {
+#endif
     /* We use the current group to calculate position:
      * * if the PCR is within this group
      * * if there is only one group to use for calculation
@@ -2544,8 +2927,32 @@ mpegts_packetizer_set_current_pcr_offset (MpegTSPacketizer2 * packetizer,
   pcr_offset = GSTTIME_TO_PCRTIME (offset);
 
   /* Pick delta from *first* group */
-  if (pcrtable->groups)
+  if (pcrtable->groups) {
+#ifdef TCL_PATCH
+    PCROffsetGroup *last_group = NULL;
+    group = pcrtable->groups->data;
+    if (offset != 0) {
+      for (tmp = pcrtable->groups; tmp; tmp = tmp->next) {
+        PCROffsetGroup *tgroup = (tmp->data);
+        GST_DEBUG ("tgroup->first_offset = %lld, packetizer->offset = %lld,pcrtable->current->group->first_offset = %lld",
+            tgroup->first_offset,
+            packetizer->offset,
+            pcrtable->current->group->first_offset);
+        if (tgroup->first_offset < packetizer->offset) {
+          last_group = tgroup;
+          continue;
+        }
+        if (tgroup->first_offset > packetizer->offset && last_group != NULL) {
+          group = last_group;
+          GST_DEBUG("set start to %lld", group->first_offset);
+          break;
+        }
+      }
+    }
+#else
     group = pcrtable->groups->data;
+#endif
+  }
   else
     group = pcrtable->current->group;
   GST_DEBUG ("Current group PCR %" GST_TIME_FORMAT " (offset %"
@@ -2586,3 +2993,14 @@ mpegts_packetizer_set_current_pcr_offset (MpegTSPacketizer2 * packetizer,
   }
   PACKETIZER_GROUP_UNLOCK (packetizer);
 }
+
+#ifdef TCL_PATCH
+void
+mpegts_packetizer_set_is_hls (MpegTSPacketizer2 * packetizer,
+    gboolean is_hls)
+{
+  packetizer->is_hls = is_hls;
+  GST_DEBUG("packetizer->is_hls = %d", packetizer->is_hls);
+  return;
+}
+#endif
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.h b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.h
index f8ee1b96e2..16ff3f06cf 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.h
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/mpegtspacketizer.h
@@ -1,7 +1,7 @@
 /*
- * mpegtspacketizer.h - 
+ * mpegtspacketizer.h -
  * Copyright (C) 2007 Alessandro Decina
- * 
+ *
  * Authors:
  *   Alessandro Decina <alessandro@nnva.org>
  *
@@ -278,6 +278,23 @@ struct _MpegTSPacketizer2 {
   /* Last inputted timestamp */
   GstClockTime last_in_time;
 
+#ifdef TCL_PATCH
+  GstClockTime real_last_time;
+  gboolean need_update_pts;
+  gint64 switch_time_diff;
+  gint64 prev_time_diff;
+  gboolean need_update_diff;
+  gboolean first_pcr_received;
+  gboolean is_hls;
+  gboolean is_hls_live;
+
+  gboolean may_bad_pcr;
+  GstClockTime first_pcr_diff;
+
+  gboolean disable_crc_calc;
+
+  gboolean special_file_flag;
+#endif
   /* offset to observations table */
   guint8 pcrtablelut[0x2000];
   MpegTSPCR *observations[MAX_PCR_OBS_CHANNELS];
@@ -321,8 +338,8 @@ typedef struct
 typedef struct
 {
   guint8 table_id;
-  /* the spec says sub_table_extension is the fourth and fifth byte of a 
-   * section when the section_syntax_indicator is set to a value of "1". If 
+  /* the spec says sub_table_extension is the fourth and fifth byte of a
+   * section when the section_syntax_indicator is set to a value of "1". If
    * section_syntax_indicator is 0, sub_table_extension will be set to 0 */
   guint16  subtable_extension;
   guint8   version_number;
@@ -355,35 +372,49 @@ G_GNUC_INTERNAL MpegTSPacketizerPacketReturn mpegts_packetizer_next_packet (Mpeg
 G_GNUC_INTERNAL MpegTSPacketizerPacketReturn
 mpegts_packetizer_process_next_packet(MpegTSPacketizer2 * packetizer);
 G_GNUC_INTERNAL void mpegts_packetizer_clear_packet (MpegTSPacketizer2 *packetizer,
-				     MpegTSPacketizerPacket *packet);
+                     MpegTSPacketizerPacket *packet);
 G_GNUC_INTERNAL void mpegts_packetizer_remove_stream(MpegTSPacketizer2 *packetizer,
   gint16 pid);
 
 G_GNUC_INTERNAL GstMpegtsSection *mpegts_packetizer_push_section (MpegTSPacketizer2 *packetzer,
-								  MpegTSPacketizerPacket *packet, GList **remaining);
+                                  MpegTSPacketizerPacket *packet, GList **remaining);
 
 /* Only valid if calculate_offset is TRUE */
 G_GNUC_INTERNAL GstClockTime
 mpegts_packetizer_offset_to_ts (MpegTSPacketizer2 * packetizer,
-				guint64 offset, guint16 pcr_pid);
+                guint64 offset, guint16 pcr_pid);
 G_GNUC_INTERNAL guint64
 mpegts_packetizer_ts_to_offset (MpegTSPacketizer2 * packetizer,
-				GstClockTime ts, guint16 pcr_pid);
+                GstClockTime ts, guint16 pcr_pid);
 G_GNUC_INTERNAL GstClockTime
 mpegts_packetizer_pts_to_ts (MpegTSPacketizer2 * packetizer,
-			     GstClockTime pts, guint16 pcr_pid);
+                 GstClockTime pts, guint16 pcr_pid);
+#ifdef TCL_PATCH
+G_GNUC_INTERNAL gboolean
+mpegts_packetizer_check_invalid_pcr (MpegTSPacketizer2 * packetizer,
+                 GstClockTime first_pts, guint16 pcr_pid, gboolean is_alread_invaild, gboolean is_m2ts);
+G_GNUC_INTERNAL gboolean
+mpegts_packetizer_check_bad_pts (MpegTSPacketizer2 * packetizer,
+    GstClockTime pts, guint16 pcr_pid);
+#endif
 G_GNUC_INTERNAL GstClockTime
 mpegts_packetizer_get_current_time (MpegTSPacketizer2 * packetizer,
-				    guint16 pcr_pid);
+                    guint16 pcr_pid);
 G_GNUC_INTERNAL void
 mpegts_packetizer_set_current_pcr_offset (MpegTSPacketizer2 * packetizer,
-			  GstClockTime offset, guint16 pcr_pid);
+              GstClockTime offset, guint16 pcr_pid);
 G_GNUC_INTERNAL void
 mpegts_packetizer_set_reference_offset (MpegTSPacketizer2 * packetizer,
-					guint64 refoffset);
+                    guint64 refoffset);
 G_GNUC_INTERNAL void
 mpegts_packetizer_set_pcr_discont_threshold (MpegTSPacketizer2 * packetizer,
-					GstClockTime threshold);
+                    GstClockTime threshold);
+
+#ifdef TCL_PATCH
+G_GNUC_INTERNAL void
+mpegts_packetizer_set_is_hls (MpegTSPacketizer2 * packetizer,
+    gboolean is_hls);
+#endif
 G_END_DECLS
 
 #endif /* GST_MPEGTS_PACKETIZER_H */
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/pesparse.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/pesparse.c
index e0f11f2a08..6a1aac20c3 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/pesparse.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/pesparse.c
@@ -143,7 +143,11 @@ mpegts_parse_pes_header (const guint8 * data, gsize length, PESHeader * res)
 
   /* PTS_DTS_flags == 0x01 is invalid */
   if (G_UNLIKELY ((flags >> 6) == 0x01)) {
+#ifdef TCL_PATCH
+    GST_DEBUG ("Invalid PTS_DTS_flag (0x01 is forbidden)");
+#else
     GST_WARNING ("Invalid PTS_DTS_flag (0x01 is forbidden)");
+#endif
   }
 
   if ((flags & 0x80) == 0x80) {
@@ -404,24 +408,45 @@ need_more_data:
   return ret;
 
 bad_start_code:
+#ifdef TCL_PATCH
+  GST_DEBUG ("Wrong packet start code 0x%x != 0x000001xx", val32);
+#else
   GST_WARNING ("Wrong packet start code 0x%x != 0x000001xx", val32);
+#endif
   return PES_PARSING_BAD;
 
 bad_marker_1:
+#ifdef TCL_PATCH
+  GST_DEBUG ("Wrong '0x10' marker before PES_scrambling_control (0x%02x)",
+      val8);
+#else
   GST_WARNING ("Wrong '0x10' marker before PES_scrambling_control (0x%02x)",
       val8);
+#endif
   return PES_PARSING_BAD;
 
 bad_PTS_value:
+#ifdef TCL_PATCH
+  GST_DEBUG ("bad PTS value");
+#else
   GST_WARNING ("bad PTS value");
+#endif
   return PES_PARSING_BAD;
 
 bad_DTS_value:
+#ifdef TCL_PATCH
+  GST_DEBUG ("bad DTS value");
+#else
   GST_WARNING ("bad DTS value");
+#endif
   return PES_PARSING_BAD;
 
 bad_ESCR_value:
+#ifdef TCL_PATCH
+  GST_DEBUG ("bad ESCR value");
+#else
   GST_WARNING ("bad ESCR value");
+#endif
   return PES_PARSING_BAD;
 
 bad_ES_rate:
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
index 6174850c57..ea125644d5 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.c
@@ -34,6 +34,11 @@
 #include <stdlib.h>
 #include <string.h>
 
+#ifdef TCL_PATCH
+#include "gstavprotocol.h"
+#include <unistd.h>
+#endif
+
 #include <glib.h>
 #include <gst/tag/tag.h>
 #include <gst/pbutils/pbutils.h>
@@ -47,10 +52,17 @@
 #include "mpegtspacketizer.h"
 #include "pesparse.h"
 #include <gst/codecparsers/gsth264parser.h>
+
+#ifdef TCL_PATCH
+#include <gst/codecparsers/gsth265parser.h>
+#endif
 #include <gst/codecparsers/gstmpegvideoparser.h>
 #include <gst/video/video-color.h>
 
 #include <math.h>
+#ifdef TCL_PATCH
+#include <sys/system_properties.h>
+#endif
 
 #define _gst_log2(x) (log(x)/log(2))
 
@@ -62,6 +74,8 @@
 
 #define CONTINUITY_UNSET 255
 #define MAX_CONTINUITY 15
+#define VC1_DEFAULT_WIDTH 1920
+#define VC1_DEFAULT_HEIGHT 1080
 
 /* Seeking/Scanning related variables */
 
@@ -82,6 +96,10 @@
  * up to this size */
 #define MAX_PES_PAYLOAD (32 * 1024 * 1024)
 
+#define LIMIT_M2TS_FILE_SIZE (10ULL *1024 * 1024 * 1024)
+
+#define LIMIT_TS_FILE_SIZE (30ULL * 1024 * 1024 * 1024)
+
 GST_DEBUG_CATEGORY_STATIC (ts_demux_debug);
 #define GST_CAT_DEFAULT ts_demux_debug
 
@@ -227,8 +245,52 @@ struct _TSDemuxStream
   TSDemuxH264ParsingInfos h264infos;
   TSDemuxJP2KParsingInfos jp2kInfos;
   TSDemuxADTSParsingInfos atdsInfos;
+
+#ifdef TCL_PATCH
+  guint64 pts_skew,dts_skew;
+  GstClockTime first_dts_diff;
+  GstClockTime first_pts_diff;
+
+  gboolean     is_subtitle;
+  gboolean     is_video;
+  gboolean     is_audio;
+  gboolean     is_send_caps;
+  gboolean     diff_send_flag;
+  GstClockTime pre_push_pts;
+  gboolean     unsupport;
+  gboolean     is_set_channels;
+
+  gint64       first_pts_offset_for_base;
+#endif
+};
+
+#ifdef TCL_PATCH
+enum {
+  // Add dobly vision support
+  DESCRIPTOR_AVC_VIDEO            = 0x28,
+  DESCRIPTOR_HEVC_VIDEO           = 0x38,
+  DESCRIPTOR_DOVI_VIDEO_STREAM    = 0xB0,
+  DRF_ID_DOVI                     = 0x444F5649, // 'DOVI'
+  // End dobly vision support
 };
+#endif
 
+#ifdef TCL_PATCH
+#define VIDEO_CAPS \
+  GST_STATIC_CAPS (\
+    "video/mpeg, " \
+      "mpegversion = (int) { 1, 2, 4 }, " \
+      "systemstream = (boolean) FALSE; " \
+    "video/x-h264-tcl,stream-format=(string)byte-stream;" \
+    "video/x-h265-tcl,stream-format=(string)byte-stream;" \
+    "video/x-dirac;" \
+    "video/x-cavs;" \
+    "video/x-wmv," \
+      "wmvversion = (int) 3, " \
+      "format = (string) WVC1;" \
+      "image/x-jpc;" \
+)
+#else
 #define VIDEO_CAPS \
   GST_STATIC_CAPS (\
     "video/mpeg, " \
@@ -243,7 +305,33 @@ struct _TSDemuxStream
       "format = (string) WVC1;" \
       "image/x-jpc;" \
 )
+#endif
 
+#ifdef TCL_PATCH
+#define AUDIO_CAPS \
+  GST_STATIC_CAPS ( \
+    "audio/mpeg, " \
+      "mpegversion = (int) 1;" \
+    "audio/mpeg, " \
+      "mpegversion = (int) { 2, 4 }, " \
+      "stream-format = (string) adts; " \
+    "audio/mpeg, " \
+      "mpegversion = (int) 4, " \
+      "stream-format = (string) loas; " \
+    "audio/x-lpcm, " \
+      "width = (int) { 16, 20, 24 }, " \
+      "rate = (int) { 48000, 96000 }, " \
+      "channels = (int) [ 1, 8 ], " \
+      "dynamic_range = (int) [ 0, 255 ], " \
+      "emphasis = (boolean) { FALSE, TRUE }, " \
+      "mute = (boolean) { FALSE, TRUE }; " \
+    "audio/x-ac3; audio/x-eac3;" \
+    "audio/x-ac4-tcl;" \
+    "audio/x-dts;" \
+    "audio/x-opus;" \
+    "audio/x-private-ts-lpcm" \
+  )
+#else
 #define AUDIO_CAPS \
   GST_STATIC_CAPS ( \
     "audio/mpeg, " \
@@ -267,6 +355,7 @@ struct _TSDemuxStream
     "audio/x-opus;" \
     "audio/x-private-ts-lpcm" \
   )
+#endif
 
 /* Can also use the subpicture pads for text subtitles? */
 #define SUBPICTURE_CAPS \
@@ -302,6 +391,17 @@ enum
   PROP_EMIT_STATS,
   PROP_LATENCY,
   PROP_SEND_SCTE35_EVENTS,
+
+#ifdef TCL_PATCH
+  PROP_LATEST_PUSHED_BUFFER_PTS,
+  PROP_PTS_TO_OFFSET,
+  PROP_SEEK_POSITION,
+  PROP_PROGRAM_COUNT,
+  PROP_PROGRAM_NUMBERS,
+  PROP_PROTOCOL_TYPE,
+  PROP_H265_NAL_LENGTH_SIZE,
+  PROP_USE_ISO_SRC,
+#endif
   /* FILL ME */
 };
 
@@ -347,6 +447,19 @@ static void gst_ts_demux_check_and_sync_streams (GstTSDemux * demux,
     GstClockTime time);
 static void handle_psi (MpegTSBase * base, GstMpegtsSection * section);
 
+#ifdef TCL_PATCH
+static void
+tsdemux_h264_parsing_info_clear (TSDemuxH264ParsingInfos * h264infos);
+static void
+calculate_and_push_newsegment (GstTSDemux * demux, TSDemuxStream * stream,
+                                            MpegTSBaseProgram * target_program);
+
+static void
+gst_ts_demux_get_video_buffered_time(MpegTSBase * base);
+static GstStateChangeReturn
+gst_ts_demux_change_state (GstElement * element, GstStateChange transition);
+#endif
+
 static void
 _extra_init (void)
 {
@@ -376,6 +489,10 @@ gst_ts_demux_dispose (GObject * object)
 
   gst_flow_combiner_free (demux->flowcombiner);
 
+#ifdef TCL_PATCH
+  demux->video_diff_pts = GST_CLOCK_TIME_NONE;
+  demux->video_diff_dts = GST_CLOCK_TIME_NONE;
+#endif
   GST_CALL_PARENT (G_OBJECT_CLASS, dispose, (object));
 }
 
@@ -435,6 +552,50 @@ gst_ts_demux_class_init (GstTSDemuxClass * klass)
           G_MAXINT, DEFAULT_LATENCY,
           G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
 
+#ifdef TCL_PATCH
+  g_object_class_install_property (gobject_class, PROP_LATEST_PUSHED_BUFFER_PTS,
+      g_param_spec_uint ("latest-pushed-buffer-pts", "Latest pushed buffer pts",
+          "The pts of the latest pushed buffer pts",
+          0, G_MAXUINT, 0,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class, PROP_PTS_TO_OFFSET,
+      g_param_spec_uint64 ("pts-to-offset", "pts to offset",
+          "pts to offset",
+          0, G_MAXUINT64, 0,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class, PROP_SEEK_POSITION,
+      g_param_spec_int64 ("seek-position", "seek to position",
+          "pts to offset",
+          0, G_MAXINT64, 0,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class, PROP_PROGRAM_COUNT,
+      g_param_spec_int ("program-count", "Program count",
+          "Program Count to demux for (-1 to ignore)", -1, G_MAXINT,
+          -1, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class, PROP_PROGRAM_NUMBERS,
+      g_param_spec_string ("program-numbers", "program-numbers", "Program Numbers of demux",
+          NULL, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+  g_object_class_install_property (gobject_class, PROP_PROTOCOL_TYPE,
+      g_param_spec_int ("protocol-type", "protocol type", "media protocol type",
+          0, 8, 0,  G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+  g_object_class_install_property (gobject_class,  PROP_H265_NAL_LENGTH_SIZE,
+      g_param_spec_uint ("h265-nal-length-size",
+            "video h265 nal length size",
+            "The h265 video h265 nal length size",
+            0, G_MAXUINT, 0,
+            G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+   g_object_class_install_property (gobject_class, PROP_USE_ISO_SRC,
+      g_param_spec_boolean ("use-iso-src", "use iso src",
+          "param for iso bd play", FALSE,
+          G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+#endif
+
   element_class = GST_ELEMENT_CLASS (klass);
   gst_element_class_add_pad_template (element_class,
       gst_static_pad_template_get (&video_template));
@@ -467,6 +628,12 @@ gst_ts_demux_class_init (GstTSDemuxClass * klass)
   ts_class->seek = GST_DEBUG_FUNCPTR (gst_ts_demux_do_seek);
   ts_class->flush = GST_DEBUG_FUNCPTR (gst_ts_demux_flush);
   ts_class->drain = GST_DEBUG_FUNCPTR (gst_ts_demux_drain);
+
+#ifdef TCL_PATCH
+  element_class->change_state = GST_DEBUG_FUNCPTR (gst_ts_demux_change_state);
+
+  parent_class = g_type_class_peek_parent (klass);
+#endif
 }
 
 static void
@@ -496,6 +663,18 @@ gst_ts_demux_reset (MpegTSBase * base)
   demux->program_generation = 0;
 
   demux->mpeg_pts_offset = 0;
+
+#ifdef TCL_PATCH
+  demux->latest_pushed_buffer_pts = 0;
+  demux->pts_to_offset = 0;
+  demux->seek_position = 0;
+  demux->program_started = FALSE;
+  demux->subtitle_idx  = 0;
+  memset(demux->program_numbers, 0, sizeof(guint) * 16);
+  demux->program_count = 0;
+  memset(&demux->audio_info_list, 0, sizeof(media_audio_info_list_s));
+  demux->h265_Nal_length_size = 4;
+#endif
 }
 
 static void
@@ -512,6 +691,24 @@ gst_ts_demux_init (GstTSDemux * demux)
   demux->requested_program_number = -1;
   demux->program_number = -1;
   demux->latency = DEFAULT_LATENCY;
+
+#ifdef TCL_PATCH
+  demux->audio_info = NULL;
+  demux->video_info = NULL;
+  demux->video_diff_pts = GST_CLOCK_TIME_NONE;
+  demux->video_diff_dts = GST_CLOCK_TIME_NONE;
+#endif
+
+#ifdef TCL_PATCH
+  demux->is_seeking = FALSE;
+  demux->is_invalid_pcr = -1;
+  demux->is_bad_pts = -1;
+  demux->file_size = -1;
+
+  demux->special_file_flag = FALSE;
+  demux->use_iso_src = FALSE;
+  demux->first_pts_base = GST_CLOCK_TIME_NONE;
+#endif
   gst_ts_demux_reset (base);
 
   g_mutex_init (&demux->lock);
@@ -539,6 +736,34 @@ gst_ts_demux_set_property (GObject * object, guint prop_id,
     case PROP_LATENCY:
       demux->latency = g_value_get_int (value);
       break;
+
+#ifdef TCL_PATCH
+    case PROP_LATEST_PUSHED_BUFFER_PTS:
+      demux->latest_pushed_buffer_pts= g_value_get_uint (value);
+      break;
+    case PROP_PTS_TO_OFFSET:
+      demux->pts_to_offset = g_value_get_uint64 (value);
+      GST_LOG_OBJECT (demux, "pts: %llu", demux->pts_to_offset);
+      break;
+    case PROP_PROGRAM_COUNT:
+      /* FIXME: do something if program is switched as opposed to set at
+       * beginning */
+      demux->program_count = g_value_get_int (value);
+      break;
+    case PROP_PROGRAM_NUMBERS:
+      break;
+    case PROP_PROTOCOL_TYPE:
+      GST_MPEGTS_BASE (demux)->protocol_type = g_value_get_int (value);
+      GST_INFO_OBJECT (demux, "protocol_type is :%d", g_value_get_int (value));
+      break;
+    case PROP_H265_NAL_LENGTH_SIZE:
+        demux->h265_Nal_length_size = g_value_get_uint (value);
+      break;
+    case PROP_USE_ISO_SRC:
+      demux->use_iso_src = g_value_get_boolean (value);
+      GST_MPEGTS_BASE (demux)->use_iso_src = demux->use_iso_src;
+      break;
+#endif
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
   }
@@ -563,11 +788,165 @@ gst_ts_demux_get_property (GObject * object, guint prop_id,
     case PROP_LATENCY:
       g_value_set_int (value, demux->latency);
       break;
+#ifdef TCL_PATCH
+    case PROP_LATEST_PUSHED_BUFFER_PTS:
+     gst_ts_demux_get_video_buffered_time((MpegTSBase *)demux);
+     GST_INFO_OBJECT (demux, "latest-pushed-buffer-pts %lld(range percent)", demux->latest_pushed_buffer_pts);
+     g_value_set_uint (value, demux->latest_pushed_buffer_pts);
+     break;
+    case PROP_PTS_TO_OFFSET:
+    {
+      guint64 offset = 0;
+      if (demux->program != NULL){
+          offset = mpegts_packetizer_ts_to_offset (MPEG_TS_BASE_PACKETIZER (demux),
+                                                             demux->pts_to_offset, demux->program->pcr_pid);
+         GST_LOG_OBJECT (demux, "pts-to-offset pts: %llu, offset: %llu", demux->pts_to_offset, offset);
+      }
+      g_value_set_uint64 (value, offset);
+      break;
+    }
+    case PROP_SEEK_POSITION:
+      g_value_set_int64 (value, demux->seek_position);
+      GST_INFO_OBJECT (demux, "seek_position: %lld", demux->seek_position);
+      break;
+    case PROP_PROGRAM_COUNT:
+      g_value_set_int (value, demux->program_count);
+      break;
+    case PROP_PROGRAM_NUMBERS:
+    {
+      gchar programs[1024] = {0};
+      if (demux->program_count > 0) {
+        guint i = 0;
+        sprintf(programs, "%d", demux->program_numbers[0]);
+        for(i = 1; i < demux->program_count; i++) {
+            sprintf(programs, "%s,%d", programs, demux->program_numbers[i]);
+        }
+      }
+      g_value_set_string (value, programs);
+      break;
+    }
+    case PROP_PROTOCOL_TYPE:
+      g_value_set_int (value, GST_MPEGTS_BASE (demux)->protocol_type);
+      break;
+    case PROP_H265_NAL_LENGTH_SIZE:
+      g_value_set_uint (value, demux->h265_Nal_length_size);
+      break;
+#endif
     default:
       G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
   }
 }
 
+#ifdef TCL_PATCH
+#define MAXPARSEPESNUM 50000*188
+static guint64 gst_mpegts_offset_to_pts(MpegTSBase * base, gint64 seek_offset, gboolean search_back)
+{
+  GstBuffer *buf = NULL;
+  guint8 *data = NULL;
+  gsize data_size = 0;
+  PESHeader header;
+  header.PTS = -1;
+  gsize len = STEP_LENGTH;
+  GstFormat format;
+  gint64 upstream_size;
+  gint64 headPts = -1;
+  gint tryParsePESNum = 0;
+  PESParsingResult ret;
+  GstFlowReturn flowReturn;
+  /* Get the size of upstream */
+  format = GST_FORMAT_BYTES;
+  if (!gst_pad_peer_query_duration (base->sinkpad, format, &upstream_size)) {
+    GST_ERROR("!gst_pad_peer_query_duration (base->sinkpad, format, &tmpval");
+    return headPts;
+  }
+  if (seek_offset < 0 || (seek_offset + len) > upstream_size) {
+    GST_ERROR("seek_offset < 0 || (seek_offset + len) > upstream_size");
+    return headPts;
+  }
+  flowReturn = gst_pad_pull_range (base->sinkpad, seek_offset, len, &buf);
+  if (G_UNLIKELY (flowReturn != GST_FLOW_OK)) {
+    GST_ERROR("flowReturn != GST_FLOW_OK");
+    if (buf != NULL) {
+      gst_buffer_unref (buf);
+    }
+    return headPts;
+  }
+  if (buf == NULL) {
+    return headPts;
+  }
+
+  GstMapInfo info;
+  gst_buffer_map(buf, &info, GST_MAP_READ);
+  data = (guint8 *)info.data;
+  data_size = info.size;
+  ret = mpegts_parse_pes_header(data , data_size, &header);
+  while ((ret != PES_PARSING_OK) && (seek_offset < upstream_size) && tryParsePESNum < MAXPARSEPESNUM) {
+    ret = mpegts_parse_pes_header(data , data_size, &header);
+    if(ret == PES_PARSING_BAD){
+      tryParsePESNum++;
+    }
+    if ((ret == PES_PARSING_BAD || ret == PES_PARSING_NEED_MORE) && (data_size >= 6)) {
+      data += 1;
+      data_size-= 1;
+      continue;
+    }
+    if (G_UNLIKELY(data_size < 6)) {
+      GST_ERROR("start new read");
+      gst_buffer_unmap(buf, &info);
+      gst_buffer_unref (buf);
+      buf = NULL;
+      if(data != NULL) {
+        data = NULL;
+        data_size = 0;
+      }
+
+      if (search_back) {
+        seek_offset -= len;
+      } else {
+        seek_offset += len;
+      }
+
+      if (seek_offset < 0 || (seek_offset + len) > upstream_size) {
+        GST_ERROR("seek_offset < 0 || (seek_offset + len) > upstream_size");
+        return headPts;
+      }
+      flowReturn = gst_pad_pull_range (base->sinkpad, seek_offset, len, &buf);
+      if (G_UNLIKELY (flowReturn != GST_FLOW_OK)) {
+        GST_ERROR("flowReturn != GST_FLOW_OK");
+        if (buf != NULL) {
+          gst_buffer_unref (buf);
+        }
+        return headPts;
+      }
+      if (buf == NULL) {
+        return headPts;
+      }
+      gst_buffer_map(buf, &info, GST_MAP_READ);
+      data = (guint8 *)info.data;
+      data_size = info.size;
+      continue;
+    }
+    if (ret == PES_PARSING_OK) {
+      if (header.PTS == -1) {
+        data += 1;
+        data_size-= 1;
+        ret = PES_PARSING_BAD;
+        continue;
+      }
+      GST_ERROR ("PTS %" G_GUINT64_FORMAT " %" GST_TIME_FORMAT,header.PTS, GST_TIME_ARGS (MPEGTIME_TO_GSTTIME (header.PTS)));
+      break;
+    }
+  }
+
+  gst_buffer_unmap(buf, &info);
+  gst_buffer_unref (buf);
+  if(header.PTS != -1){
+    headPts = MPEGTIME_TO_GSTTIME(header.PTS);
+  }
+  return headPts;
+}
+#endif
+
 static gboolean
 gst_ts_demux_get_duration (GstTSDemux * demux, GstClockTime * dur)
 {
@@ -580,12 +959,53 @@ gst_ts_demux_get_duration (GstTSDemux * demux, GstClockTime * dur)
     return FALSE;
   }
 
-  /* Get total size in bytes */
+#ifdef TCL_PATCH
+  if(demux->use_iso_src){
+    if (gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_TIME, &val)) {
+        demux->duration = val;
+        *dur = demux->duration;
+        GST_ERROR_OBJECT (demux, "demux query duration from src:%lld",demux->duration);
+    }
+    if (gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val)) {
+    /* Convert it to duration */
+      if (base->adjust_duration) {
+        val = base->last_valid_offset;
+      }
+      demux->file_size = val;
+    }
+    return TRUE;
+  }
+#endif
+      /* Get total size in bytes */
   if (gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val)) {
     /* Convert it to duration */
+
+#ifdef TCL_PATCH
+  if (base->adjust_duration) {
+    val = base->last_valid_offset;
+  }
+#endif
     *dur =
         mpegts_packetizer_offset_to_ts (base->packetizer, val,
         demux->program->pcr_pid);
+
+#ifdef TCL_PATCH
+    demux->file_size = val;
+    if (*dur == 0 && demux->is_bad_pts && demux->duration > 0) {
+      *dur = demux->duration;
+    }
+    if ((*dur == 0 && demux->is_bad_pts) || demux->special_file_flag == TRUE) {
+      gint64 first_pts = gst_mpegts_offset_to_pts(base, 0, FALSE);
+      // 900*188, The setting of this number follows some experience, because STEP_LENGTH 300*188
+      gint64 last_pts = gst_mpegts_offset_to_pts(base, val - 900*188, FALSE);
+      if (last_pts != GST_CLOCK_TIME_NONE && first_pts != GST_CLOCK_TIME_NONE && last_pts > first_pts) {
+        *dur = last_pts - first_pts;
+      } else {
+        GST_ERROR_OBJECT (demux, "get pts fail,  val = %lld, first_pts = %lld, last_pts = %lld",
+            val, first_pts, last_pts);
+      }
+    }
+#endif
     if (GST_CLOCK_TIME_IS_VALID (*dur))
       res = TRUE;
   }
@@ -909,6 +1329,182 @@ gst_ts_demux_adjust_seek_offset_for_keyframe (TSDemuxStream * stream,
   return TRUE;
 }
 
+#ifdef TCL_PATCH
+static guint64 gst_ts_demux_offset_to_pts(MpegTSBase * base, gint64 seek_offset, gint64* offset, gboolean search_back, gint64* num_len_back)
+{
+    GstBuffer *buf = NULL;
+    guint8 *data = NULL;
+    gsize data_size = 0;
+    PESHeader header;
+    header.PTS = -1;
+    gsize len  = STEP_LENGTH;
+    GstFormat format;
+    gint64 tmpval;
+    gint64 upstream_size;
+    gint64 headPts = -1;
+    gint tryParsePESNum = 0;
+    PESParsingResult ret;
+    *offset = 0;
+    GstFlowReturn flowReturn;
+    *num_len_back = 0;
+    int retries = 0;
+    /* Get the size of upstream */
+    format = GST_FORMAT_BYTES;
+    GstTSDemux *demux = GST_TS_DEMUX (base);
+    if (demux->file_size > 0) {
+        upstream_size = demux->file_size;
+    } else {
+        if (!gst_pad_peer_query_duration (base->sinkpad, format, &tmpval)) {
+            GST_ERROR("!gst_pad_peer_query_duration (base->sinkpad, format, &tmpval");
+            return GST_FLOW_ERROR;
+        }
+        upstream_size = tmpval;
+    }
+
+    if (seek_offset < 0 || (seek_offset + len) > upstream_size) {
+        GST_ERROR("seek_offset < 0 || (seek_offset + len) > upstream_size");
+        return GST_FLOW_ERROR;
+    }
+    flowReturn = gst_pad_pull_range (base->sinkpad, seek_offset, len, &buf);
+    if (G_UNLIKELY (flowReturn != GST_FLOW_OK)) {
+        GST_ERROR("flowReturn != GST_FLOW_OK");
+        return GST_FLOW_ERROR;
+    }
+    if (buf == NULL) {
+        return GST_FLOW_ERROR;
+    }
+
+    GstMapInfo info;
+    gst_buffer_map(buf, &info, GST_MAP_READ);
+    data = (guint8 *)info.data;
+    data_size = info.size;
+
+    ret = mpegts_parse_pes_header(data , data_size, &header);
+    while (((ret == PES_PARSING_OK && header.PTS == -1) || ret != PES_PARSING_OK) && (seek_offset < upstream_size) && tryParsePESNum < MAXPARSEPESNUM) {
+        ret = mpegts_parse_pes_header(data , data_size, &header);
+        if(ret == PES_PARSING_BAD){
+            tryParsePESNum++;
+        }
+        if ((ret == PES_PARSING_BAD || ret == PES_PARSING_NEED_MORE) && (data_size >= 6)) {
+            data += 1;
+            data_size-= 1;
+            *offset += 1;
+            continue;
+        }
+        if (G_UNLIKELY(data_size < 6)) {
+            gst_buffer_unmap(buf, &info);
+            gst_buffer_unref (buf);
+            buf = NULL;
+           if(data != NULL) {
+                data = NULL;
+                data_size = 0;
+            }
+            if (search_back) {
+                seek_offset -= len;
+                *num_len_back += 1;
+            } else {
+                seek_offset += len;
+                *offset += len;
+            }
+
+            if (seek_offset < 0 || (seek_offset + len) > upstream_size) {
+                GST_ERROR("seek_offset < 0 || (seek_offset + len) > upstream_size");
+                return GST_FLOW_ERROR;
+            }
+            retries = 0;
+            while (retries < 5) {
+                flowReturn = gst_pad_pull_range(base->sinkpad, seek_offset, len, &buf);
+                if (G_LIKELY(flowReturn == GST_FLOW_OK)) {
+                    break; // 成功拉取数据，退出循环
+                } else {
+                    GST_ERROR("search_back = %d Attempt %d: flowReturn = %d, headPts = %lld, seek_offset = %lld, upstream_size = %lld",
+                              search_back, retries + 1, flowReturn, headPts, seek_offset, upstream_size);
+                    retries++;
+                   // 如果 buf 不为 NULL，释放资源
+                    if (buf != NULL) {
+                        gst_buffer_unref(buf);
+                        buf = NULL; // 重置 buf 以避免重复释放
+                    }
+                }
+            }
+            if (flowReturn != GST_FLOW_OK) {
+                // 如果五次尝试都失败，则返回 headPts
+                return GST_FLOW_ERROR;
+            }
+            if (buf == NULL) {
+                return GST_FLOW_ERROR;
+            }
+            gst_buffer_map(buf, &info, GST_MAP_READ);
+            data = (guint8 *)info.data;
+            data_size = info.size;
+
+            continue;
+        }
+        if (ret == PES_PARSING_OK) {
+            if (header.PTS == -1) {
+                data += 1;
+                data_size-= 1;
+                *offset += 1;
+                ret = PES_PARSING_BAD;
+                continue;
+            }
+            GST_DEBUG("header.PTS =%lld",   header.PTS);
+            GST_DEBUG ("PTS %" G_GUINT64_FORMAT " %" GST_TIME_FORMAT,header.PTS, GST_TIME_ARGS (MPEGTIME_TO_GSTTIME (header.PTS)));
+            break;
+        }
+    }
+
+    gst_buffer_unmap(buf, &info);
+    gst_buffer_unref (buf);
+    buf = NULL;
+    if(header.PTS != -1){
+        headPts = MPEGTIME_TO_GSTTIME(header.PTS);
+    }
+    GST_DEBUG ("PTS %" G_GUINT64_FORMAT " %" GST_TIME_FORMAT" , header.stream_id = %d",header.PTS, GST_TIME_ARGS (MPEGTIME_TO_GSTTIME (header.PTS)), header.stream_id);
+    return  headPts;
+}
+
+static void gst_ts_demux_calc_offset_for_search_pts(MpegTSBase * base, gint64 diff_second, gint64 byte_per_seceond)
+{
+    gint64 try_offset = (diff_second/1000000000) * byte_per_seceond * 1.2;
+    if (base->seek_offset >= try_offset)
+        base->seek_offset -= try_offset;
+    else if (base->seek_offset >= try_offset * 0.8)
+        base->seek_offset -= try_offset * 0.8;
+    else if (base->seek_offset >= try_offset/2)
+        base->seek_offset -= try_offset/2;
+    else if (base->seek_offset >= try_offset/3)
+        base->seek_offset -= try_offset/3;
+    else
+        base->seek_offset = 0;
+    return;
+}
+
+static gboolean gst_ts_demux_need_search_seek_point(gint64 start, MpegTSBase * base)
+{
+    if (base->mode == BASE_MODE_PUSHING) {
+        return FALSE;
+    }
+
+    if (start < SEEK_THRESHOLD) {
+        return FALSE;
+    }
+
+    GstTSDemux *demux = (GstTSDemux *) base;
+
+    if (base->is_m2ts && demux->file_size > LIMIT_M2TS_FILE_SIZE) {
+        return FALSE;
+    }
+
+    if (!base->is_m2ts && demux->file_size > LIMIT_TS_FILE_SIZE) {
+        return FALSE;
+    }
+
+    return TRUE;
+}
+
+
+#endif
 static GstFlowReturn
 gst_ts_demux_do_seek (MpegTSBase * base, GstEvent * event)
 {
@@ -942,6 +1538,19 @@ gst_ts_demux_do_seek (MpegTSBase * base, GstEvent * event)
     goto done;
   }
 
+#ifdef TCL_PATCH
+  if (format == GST_FORMAT_BYTES) {
+    GST_INFO_OBJECT (demux, "seek format is bytes, transform into time, start=%lld", start);
+    start = mpegts_packetizer_offset_to_ts(base->packetizer, start, demux->program->pcr_pid);
+    format = GST_FORMAT_TIME;
+  }
+  demux->seek_position = start;
+
+  GST_INFO_OBJECT (demux, "seek event, rate: %f start: %" GST_TIME_FORMAT
+      " stop: %" GST_TIME_FORMAT, rate, GST_TIME_ARGS (start),
+      GST_TIME_ARGS (stop));
+#endif
+
   if (flags & (GST_SEEK_FLAG_SEGMENT)) {
     GST_WARNING_OBJECT (demux, "seek flags 0x%x are not supported",
         (int) flags);
@@ -974,9 +1583,27 @@ gst_ts_demux_do_seek (MpegTSBase * base, GstEvent * event)
     else
       target = 0;
 
+#ifdef TCL_PATCH
+// if pcr is invalid, we can't get an accurate offset, so we use file size to estimate it
+    if (demux->use_iso_src && demux->duration == 7926918000000 && demux->file_size == 84234559488) {
+        demux->is_bad_pts = TRUE;
+    }
+    if (demux->is_bad_pts == TRUE && demux->duration > 0 && demux->file_size > 0) {
+      start_offset = gst_util_uint64_scale (demux->file_size, target, demux->duration);
+    } else {
+      start_offset =
+          mpegts_packetizer_ts_to_offset (base->packetizer, target,
+          demux->program->pcr_pid);
+       if (demux->file_size > 0 && demux->duration > 0 && start_offset > demux->file_size) {
+           start_offset = gst_util_uint64_scale (demux->file_size, target, demux->duration);
+       }
+    }
+#else
     start_offset =
         mpegts_packetizer_ts_to_offset (base->packetizer, target,
         demux->program->pcr_pid);
+#endif
+
     if (G_UNLIKELY (start_offset == -1)) {
       GST_WARNING_OBJECT (demux,
           "Couldn't convert start position to an offset");
@@ -985,6 +1612,152 @@ gst_ts_demux_do_seek (MpegTSBase * base, GstEvent * event)
     }
 
     base->seek_offset = start_offset;
+    GST_WARNING_OBJECT(demux, "start_offset = %lld", start_offset);
+
+#ifdef TCL_PATCH
+    gint trycount = 0;
+    if (gst_ts_demux_need_search_seek_point(start, base)) {
+        gint64 offset = 0;
+        gint64 current_pts = -1;
+        gint64 last_pts = -1;
+        gint64 num_len_back = 0;
+        gboolean search_back =TRUE;
+        gint64 offset_first = 0;
+        gint64 num_len_back_first = 0;
+        gint64 first_pts = gst_ts_demux_offset_to_pts(base, 0 , &offset_first, FALSE, &num_len_back_first);
+        gint64 byte_per_second = 0;
+        gint64 last_offset = 0;
+        gint64 time_diff = 1;
+        GST_DEBUG_OBJECT (demux, "first_pts %" G_GUINT64_FORMAT " %" GST_TIME_FORMAT" offset = %lld",first_pts, GST_TIME_ARGS(first_pts), offset);
+        current_pts = gst_ts_demux_offset_to_pts(base, base->seek_offset , &offset, FALSE, &num_len_back);
+        if (current_pts == GST_FLOW_ERROR) {
+            GST_ERROR("gst_ts_demux_offset_to_pts fail");
+            g_mutex_unlock (&demux->lock);
+            goto done;
+        }
+        if (first_pts != -1 && current_pts != -1 ) {
+            if (first_pts > current_pts) {
+                first_pts = 0;
+            }
+            // add end
+            GST_DEBUG_OBJECT(demux, "current_pts =%lld start =%lld", current_pts, start);
+            // 检查除数是否为零
+            time_diff = current_pts - first_pts;
+            if (time_diff >= GST_SECOND) {
+                byte_per_second = start_offset / (time_diff / GST_SECOND);
+            } else {
+                base->seek_offset = start_offset;
+                goto seekTo;
+            }
+            if ((current_pts - first_pts) < (start - SEEK_THRESHOLD)) {
+                search_back = FALSE;
+                while (current_pts != -1 && ((current_pts - first_pts) < (start - SEEK_THRESHOLD))) {
+                    last_pts = current_pts;
+                    last_offset = base->seek_offset;
+                    GST_DEBUG_OBJECT(demux, "1-1 current_pts =%" GST_TIME_FORMAT" start =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(start), base->seek_offset);
+                    base->seek_offset = base->seek_offset + STEP_LENGTH + offset;
+                    current_pts = gst_ts_demux_offset_to_pts(base, base->seek_offset , &offset, search_back, &num_len_back);
+                    if (current_pts == GST_FLOW_ERROR) {
+                        GST_ERROR("gst_ts_demux_offset_to_pts fail");
+                        g_mutex_unlock (&demux->lock);
+                        goto done;
+                    }
+                    GST_DEBUG_OBJECT(demux, "1-2 current_pts =%" GST_TIME_FORMAT" last_pts =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(last_pts), base->seek_offset);
+                    if (ABSDIFF (current_pts, last_pts) > 60 * GST_SECOND * 60) {
+                        current_pts = last_pts;
+                        GST_ERROR("error pts, skip last_pts = %" GST_TIME_FORMAT"", GST_TIME_ARGS(last_pts));
+                        if (last_offset == base->seek_offset)
+                            trycount++;
+                        if (trycount > 5)
+                            break;
+                        continue;
+                    }
+                }
+                base->seek_offset += offset;
+            }
+            trycount = 0;
+            GST_DEBUG_OBJECT(demux, "1-3 current_pts =%" GST_TIME_FORMAT" start =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(start), base->seek_offset);
+            if ((current_pts - first_pts) > (start + SEEK_THRESHOLD)) {
+                gst_ts_demux_calc_offset_for_search_pts(base, (current_pts - first_pts) - start, byte_per_second);
+                search_back = TRUE;
+                while (current_pts != -1 && ((current_pts - first_pts) > (start + SEEK_THRESHOLD))) {
+                    last_pts = current_pts;
+                    last_offset = base->seek_offset;
+                    GST_DEBUG_OBJECT(demux, "2-1 current_pts =%" GST_TIME_FORMAT" start =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(start), base->seek_offset);
+                    if (base->seek_offset < (num_len_back + 1) * STEP_LENGTH)
+                        base->seek_offset = 0;
+                    else
+                        base->seek_offset = base->seek_offset - (num_len_back + 1) * STEP_LENGTH;
+                    current_pts = gst_ts_demux_offset_to_pts(base, base->seek_offset , &offset, search_back, &num_len_back);
+                    if (current_pts == GST_FLOW_ERROR) {
+                        GST_ERROR("gst_ts_demux_offset_to_pts fail");
+                        g_mutex_unlock (&demux->lock);
+                        goto done;
+                    }
+                    if (base->seek_offset == 0 || current_pts == last_pts) {
+                        trycount++;
+                        if (trycount > 5) {
+                            base->seek_offset = start_offset;
+                            goto seekTo;
+                        }
+                    }
+                    GST_DEBUG_OBJECT(demux, "2-2 current_pts =%" GST_TIME_FORMAT" last_pts =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(last_pts), base->seek_offset);
+                    if (ABSDIFF (current_pts, last_pts) > 60 * GST_SECOND * 60) {
+                        current_pts = last_pts;
+                        GST_ERROR("error pts, skip last_pts = %" GST_TIME_FORMAT"", GST_TIME_ARGS(last_pts));
+                        if (last_offset == base->seek_offset)
+                            trycount++;
+                        if (trycount > 5)
+                            break;
+                        continue;
+                    }
+                    if ((current_pts - first_pts) - start > 5 * GST_SECOND) {
+                        gst_ts_demux_calc_offset_for_search_pts(base, (current_pts - first_pts) - start, byte_per_second);
+                    }
+                }
+                base->seek_offset += offset;
+            }
+
+            if ((current_pts - first_pts) < (start - SEEK_THRESHOLD)) {
+                search_back = FALSE;
+                while (current_pts != -1 && ((current_pts - first_pts) < (start - SEEK_THRESHOLD))) {
+                    GST_DEBUG_OBJECT(demux, "3-1 current_pts =%" GST_TIME_FORMAT" start =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(start), base->seek_offset);
+                    last_pts = current_pts;
+                    last_offset = base->seek_offset;
+                    base->seek_offset = base->seek_offset + STEP_LENGTH + offset;
+                    current_pts = gst_ts_demux_offset_to_pts(base, base->seek_offset , &offset, search_back, &num_len_back);
+                    if (current_pts == GST_FLOW_ERROR) {
+                        GST_ERROR("gst_ts_demux_offset_to_pts fail");
+                        g_mutex_unlock (&demux->lock);
+                        goto done;
+                    }
+                    GST_DEBUG_OBJECT(demux, "3-2 current_pts =%" GST_TIME_FORMAT" last_pts =%" GST_TIME_FORMAT" base->seek_offset = %lld", GST_TIME_ARGS(current_pts), GST_TIME_ARGS(last_pts), base->seek_offset);
+                    if (ABSDIFF (current_pts, last_pts) > 60 * GST_SECOND * 60) {
+                        current_pts = last_pts;
+                        GST_ERROR("error pts, skip last_pts = %" GST_TIME_FORMAT"", GST_TIME_ARGS(last_pts));
+                        if (last_offset == base->seek_offset)
+                            trycount++;
+                        if (trycount > 5)
+                            break;
+                        continue;
+                    }
+                }
+                base->seek_offset += offset;
+            }
+            time_diff = current_pts - first_pts;
+            if (time_diff <= 0 || time_diff > (start + 3*GST_SECOND) || time_diff < (start - 3*GST_SECOND)
+                || (time_diff > GST_SECOND && base->seek_offset / (time_diff / GST_SECOND) > 37500000)
+                || (time_diff > GST_SECOND && base->seek_offset / (time_diff / GST_SECOND) < 12500)) { //当前pts小于第一帧pts;当前pts-第一帧pts在seek点的3s外;计算出的码率大于300Mbps 或小于100Kbps
+                base->seek_offset = start_offset;
+                goto seekTo;
+            }
+        }
+    }
+    if (trycount > 5)
+        base->seek_offset = start_offset;
+    GST_DEBUG_OBJECT(demux, "base->seek_offset =%lld",base->seek_offset);
+seekTo:
+#endif
     demux->last_seek_offset = base->seek_offset;
     /* Reset segment if we're not doing an accurate seek */
     demux->reset_segment = (!(flags & GST_SEEK_FLAG_ACCURATE));
@@ -1041,6 +1814,91 @@ gst_ts_demux_srcpad_event (GstPad * pad, GstObject * parent, GstEvent * event)
         GST_WARNING_OBJECT (pad, "seeking failed");
       gst_event_unref (event);
       break;
+#ifdef TCL_PATCH
+    case GST_EVENT_CUSTOM_UPSTREAM:
+      if (gst_event_has_name (event, "application/x-custom-stream-drop")) {
+        GList *tmp = NULL;
+        TSDemuxStream *stream =  NULL;
+        //
+        if(demux->program != NULL && demux->program->stream_list != NULL
+              && g_list_length(demux->program->stream_list) == 1){
+          gst_element_close_player((GstElement *)demux);
+          return TRUE;
+        }
+        for (tmp = demux->program->stream_list; tmp; tmp = tmp->next) {
+          stream = tmp->data;
+          if(stream != NULL && stream->pad == pad){
+              if (stream->pad) {
+                gst_flow_combiner_remove_pad (demux->flowcombiner, stream->pad);
+                if (stream->active) {
+                  if (gst_pad_is_active (stream->pad)) {
+                    /* Flush out all data */
+                    GST_DEBUG_OBJECT (stream->pad, "Flushing out pending data");
+                    calculate_and_push_newsegment (demux, stream, NULL);
+                    GST_DEBUG_OBJECT (stream->pad, "Pushing out EOS");
+                    gst_pad_push_event (stream->pad, gst_event_new_eos());
+                    gst_pad_set_active (stream->pad, FALSE);
+                  }
+                  GST_DEBUG_OBJECT (stream->pad, "Removing pad");
+                  gst_element_remove_pad (GST_ELEMENT_CAST ((MpegTSBase *) demux), stream->pad);
+                  stream->active = FALSE;
+                }
+                stream->pad = NULL;
+              }
+              {
+                GST_DEBUG ("flushing stream %p", stream);
+                stream->state = PENDING_PACKET_EMPTY;
+                stream->expected_size = 0;
+                stream->allocated_size = 0;
+                stream->current_size = 0;
+                stream->discont = TRUE;
+                stream->pts = GST_CLOCK_TIME_NONE;
+                stream->dts = GST_CLOCK_TIME_NONE;
+                stream->raw_pts = -1;
+                stream->raw_dts = -1;
+                stream->pts_skew = 0;
+                stream->dts_skew = 0;
+                stream->pending_ts = TRUE;
+                stream->nb_out_buffers = 0;
+                stream->gap_ref_buffers = 0;
+                stream->gap_ref_pts = GST_CLOCK_TIME_NONE;
+                stream->continuity_counter = CONTINUITY_UNSET;
+
+                if (G_UNLIKELY (stream->pending)) {
+                  GList *tmp;
+
+                  GST_DEBUG ("clearing pending %p", stream);
+                  for (tmp = stream->pending; tmp; tmp = tmp->next) {
+                    PendingBuffer *pend = (PendingBuffer *) tmp->data;
+                    gst_buffer_unref (pend->buffer);
+                    g_slice_free (PendingBuffer, pend);
+                  }
+                  g_list_free (stream->pending);
+                  stream->pending = NULL;
+                }
+                stream->first_pts = GST_CLOCK_TIME_NONE;
+                stream->need_newsegment = TRUE;
+             }
+
+             if (stream->taglist != NULL) {
+                gst_tag_list_unref (stream->taglist);
+                stream->taglist = NULL;
+             }
+             tsdemux_h264_parsing_info_clear (&stream->h264infos);
+             {
+               guint16  pid = stream->stream.pid;
+               demux->program->stream_list = g_list_remove_all (demux->program->stream_list, stream);
+               demux->program->streams[pid] = NULL;
+               usleep(300 * 1000);
+               g_free (stream);
+             }
+             break;
+          }
+        }
+        gst_event_unref(event);
+      }
+      break;
+#endif
     default:
       res = gst_pad_event_default (pad, parent, event);
   }
@@ -1255,10 +2113,16 @@ add_iso639_language_to_tags (TSDemuxStream * stream, gchar * lang_code)
   /* descriptor contains ISO 639-2 code, we want the ISO 639-1 code */
   lc = gst_tag_get_language_code (lang_code);
 
+#ifdef TCL_PATCH
+  if (lang_code)
+      gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
+          GST_TAG_LANGUAGE_CODE, lang_code, NULL);
+#else
   /* Only set tag if we have a valid one */
   if (lc || (lang_code[0] && lang_code[1]))
     gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
         GST_TAG_LANGUAGE_CODE, (lc) ? lc : lang_code, NULL);
+#endif
 }
 
 static void
@@ -1334,6 +2198,302 @@ gst_ts_demux_create_tags (TSDemuxStream * stream)
   }
 }
 
+#ifdef TCL_PATCH
+static void
+gst_ts_demux_send_texttrack_for_subtitle(GstTSDemux* demux, const char* id, const char* language, guint pid)
+{
+  demux->subtitle_idx++;
+  const char* _id   = id;
+  const char* _lang = language;
+  if(NULL == id)
+    _id   = "";
+
+  if(NULL == language)
+    _lang = "";
+  gst_element_post_message(GST_ELEMENT_CAST(demux),
+              gst_message_new_element(GST_OBJECT(demux), gst_structure_new("texttrack_add",
+                          "texttrack_id", G_TYPE_UINT,    (((1 & 0xFF) << 24)  |  (demux->subtitle_idx & 0xFF)),
+                          "kind",         G_TYPE_UINT,    KindSubtitles,
+                          "id",           G_TYPE_STRING,  _id,
+                          "pid",          G_TYPE_UINT,    pid,
+                          "label",        G_TYPE_STRING,  "",
+                          "language",     G_TYPE_STRING,  _lang,
+                          "mode",         G_TYPE_STRING,  "",
+                          "DispatchType", G_TYPE_STRING,  "",
+                          NULL)));
+}
+
+static void
+gst_ts_demux_get_audio_infos(GstTSDemux *demux, MpegTSBaseStream * bstream,MpegTSBaseProgram * program)
+{
+  media_audio_info_s *audio_info = NULL;
+  gint program_index = 0;
+  for (program_index = 0; program_index < demux->audio_info_list.programCount; program_index++) {
+    if (demux->audio_info_list.audioExtendInfos[program_index]->programNumber == program->program_number) {
+      audio_info = demux->audio_info_list.audioExtendInfos[program_index]->audioInfo;
+    }
+  }
+  if (audio_info == NULL) {
+    audio_info = (media_audio_info_s *)malloc(sizeof(media_audio_info_s));
+    if (audio_info == NULL) {
+        GST_DEBUG ("malloc demux->audio_info error");
+        return;
+    }
+    GST_DEBUG ("malloc demux->audio_info success");
+    memset (audio_info, 0, sizeof (media_audio_info_s));
+    audio_info->audioCount = 0;
+  }
+
+  int audio_count = audio_info->audioCount;
+  GST_DEBUG ("demux->audio_info->audioCount = %d.",audio_count);
+  if (audio_count >= MAX_AUDIO_TRACK_NUM) {
+    GST_WARNING("audio_count(%d) >= MAX_AUDIO_TRACK_NUM(%d), so return", audio_count, MAX_AUDIO_TRACK_NUM);
+    return;
+  }
+  media_audio_info_node_s *audio_node = (media_audio_info_node_s *)&(audio_info->audioInfoNodes[audio_count]);
+
+  if (demux->audio_info_list.programCount == 0) {
+    demux->audio_info_list.audioExtendInfos[0] = (media_audio_extend_info_s *)malloc(sizeof(media_audio_extend_info_s));
+    demux->audio_info_list.audioExtendInfos[0]->programNumber = program->program_number;
+    demux->audio_info_list.audioExtendInfos[0]->audioInfo = audio_info;
+    demux->audio_info_list.programCount++;
+  } else {
+    for (program_index = 0; program_index < demux->audio_info_list.programCount; program_index++)
+    {
+        if (demux->audio_info_list.audioExtendInfos[program_index]->programNumber == program->program_number) {
+            break;
+        } else if (program_index == demux->audio_info_list.programCount - 1) {
+            demux->audio_info_list.audioExtendInfos[demux->audio_info_list.programCount] = (media_audio_extend_info_s *)malloc(sizeof(media_audio_extend_info_s));
+            demux->audio_info_list.audioExtendInfos[demux->audio_info_list.programCount]->programNumber = program->program_number;
+            demux->audio_info_list.audioExtendInfos[demux->audio_info_list.programCount]->audioInfo = audio_info;
+            demux->audio_info_list.programCount++;
+            break;
+        }
+    }
+  }
+
+  audio_node->pid = (int32_t)bstream->pid;
+
+  const GstMpegtsDescriptor *desc_id = NULL;
+  desc_id = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_DVB_STREAM_IDENTIFIER);
+  if (desc_id) {
+    guint8 tag;
+    if (gst_mpegts_descriptor_parse_dvb_stream_identifier (desc_id, &tag)) {
+      GST_DEBUG ("Audio track Component Tag : 0x%02x\n", tag);
+      audio_node->componentTag= (int32_t)tag;
+    }
+  }
+
+  /*ISO_639_LANGUAGE descriptor */
+  const GstMpegtsDescriptor *desc = NULL;
+  int i, nb;
+  desc = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_ISO_639_LANGUAGE);
+  if(desc) {
+    gchar *lang_code;
+    GstMpegtsIso639AudioType audio_type;
+    nb = gst_mpegts_descriptor_parse_iso_639_language_nb (desc);
+    GST_INFO("Found ISO 639 descriptor (%d entries)", nb);
+    for (i = 0; i < nb; i++) {
+      if (gst_mpegts_descriptor_parse_iso_639_language_idx (desc, i, &lang_code,&audio_type)) {
+        strcpy((gchar *)(audio_node->language), lang_code);
+        //add_iso639_language_to_tags (stream, lang_code);
+        g_free (lang_code);
+
+        /*the audio elementary stream has an ISO_639_language_descriptor in the PMT with the audio_type field set to
+        0x03 then the kind property is "description",Added Yakov,for org.hbbtv_HTML50410*/
+        GST_INFO("audio_type=%d\n",audio_type);
+        if(audio_type == GST_MPEGTS_AUDIO_TYPE_VISUAL_IMPAIRED_COMMENTARY) {
+          audio_node->audioDescription = 2;
+        }
+        GST_DEBUG ("Just get the first language currently.");
+        break;
+      }
+    }
+  }
+
+  GST_INFO_OBJECT (demux, "n_audio_streams is:%d, trackID: %d,lang_code:%s",audio_count+1,
+                           audio_node->pid,audio_node->language);
+  audio_info->audioCount++;
+
+  /*get the audio "description" of ts,
+  supplementary_audio_descriptor in the PMT with the editorial_classification field set to 0x01 then the kind property is "description",
+  [HbbTV2.0.1]org.hbbtv_HTML50420*/
+  const GstMpegtsDescriptor *desc_extension = NULL;
+  desc_extension = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_DVB_EXTENSION);
+  //GST_INFO("tag_extension=%d\n",desc_extension->tag_extension);
+  if ((desc_extension != NULL) && (desc_extension->tag_extension == 0x06) && (desc_extension->length >= 1)) {
+    guint8 supplementary_audio_descriptor_code;
+    guint8 editorial_classification_code;
+    gboolean language_code_present = FALSE;
+    GstByteReader br;
+
+    /* skip tag, length and tag_extension */
+    gst_byte_reader_init (&br, desc_extension->data + 3, desc_extension->length - 1);
+    supplementary_audio_descriptor_code = gst_byte_reader_get_uint8_unchecked (&br);
+    editorial_classification_code = (supplementary_audio_descriptor_code & 0x7C) >> 2;
+    if (editorial_classification_code == 0x01) {
+      audio_node->audioDescription = 2;
+    }
+
+    /*When an application requests an MPEG-2 transport stream be presented by an HTML5 video element and then obtains the AudioTrack
+      corresponding to an Audio elementary stream in that transport stream and the ES loop of the PMT contains a supplementary_audio_descriptor
+      and an ISO_639_language_descriptor for that ES then the language property shall be the contents of the ISO_639_language_code field in the
+      supplementary_audio_descriptor in the ES loop of the PMT for that ES.
+      Added Yakov,for org.hbbtv_HTML50450*/
+    language_code_present = (supplementary_audio_descriptor_code & 0x01);
+    //GST_INFO("language_code_present=%d\n",language_code_present);
+    if (language_code_present) {
+      guint8 *p = desc_extension->data;
+      gchar lang_code[4] = {0};
+      memcpy(lang_code, (p + 4), 3);
+      strcpy((gchar *)(audio_node->language), lang_code);
+    //GST_INFO("lang_code=%s\n",lang_code);
+    }
+
+    //GST_INFO("[%s:%d] desc->tag = 0x%02x, desc->tag_extension = 0x%02x , supplementary_audio_descriptor_code = 0x%02x,
+    // editorial_classification_code = 0x%02x, audio_info->audioDescription = 0x%02x\n", __FUNCTION__, __LINE__,desc_extension->tag
+    // , desc_extension->tag_extension, supplementary_audio_descriptor_code, editorial_classification_code, audio_node->audioDescription);
+  }
+
+  /*get the audio "description" of ts,
+  enhanced_ac-3_descriptor in the PMT with a component_type field with the service_type flags set to Visually Impaired then the kind property is "description",
+  [HbbTV2.0.1]org.hbbtv_HTML50430*/
+  const GstMpegtsDescriptor *enhanced_ac3_descriptor = NULL;
+  enhanced_ac3_descriptor = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_DVB_ENHANCED_AC3);
+
+  if ((enhanced_ac3_descriptor != NULL) && (enhanced_ac3_descriptor->length >= 1)) {
+    guint8 enhanced_ac3_descriptor_code;
+    guint8 component_type_flag_code;
+    guint8 component_type_code;
+    guint8 service_type_code;
+    GstByteReader br;
+
+    /* skip tag, length */
+    gst_byte_reader_init (&br, enhanced_ac3_descriptor->data + 2, enhanced_ac3_descriptor->length - 1);
+    enhanced_ac3_descriptor_code = gst_byte_reader_get_uint8_unchecked (&br);
+    component_type_flag_code = (enhanced_ac3_descriptor_code & 0x80) >> 7;
+
+    if (component_type_flag_code == 1) {
+      /* skip tag, length and flags */
+      gst_byte_reader_init (&br, enhanced_ac3_descriptor->data + 3, enhanced_ac3_descriptor->length - 1);
+      component_type_code = gst_byte_reader_get_uint8_unchecked (&br);
+      service_type_code = (component_type_code & 0x38);
+      if (service_type_code == 0x10) {
+        audio_node->audioDescription = 2;
+      }
+    }
+    //GST_INFO("[%s:%d] enhanced_ac3_descriptor_code = 0x%02x, component_type_flag_code = 0x%02x , component_type_code = 0x%02x,
+    // service_type_code = 0x%02x, audio_info->audioDescription = 0x%02x\n", __FUNCTION__, __LINE__,enhanced_ac3_descriptor_code, component_type_flag_code, component_type_code,
+    //  service_type_code, audio_node->audioDescription);
+  }
+}
+
+static void
+gst_ts_demux_gst_video_infos(GstTSDemux *demux, MpegTSBaseStream * bstream,MpegTSBaseProgram * program)
+{
+  if (demux->video_info == NULL) {
+    demux->video_info = (media_video_info_s *)malloc(sizeof(media_video_info_s));
+
+    if(demux->video_info == NULL) {
+      GST_DEBUG ("malloc demux->video_info error");
+      return;
+    }
+
+    GST_DEBUG ("malloc demux->video_info success");
+    memset (demux->video_info, 0, sizeof (media_video_info_s));
+    demux->video_info->videoCount = 0;
+  }
+
+  int video_count = demux->video_info->videoCount;
+  GST_DEBUG ("demux->video_info->videoCount = %d.",video_count);
+  if (video_count >= MAX_VIDEO_TRACK_NUM) {
+    GST_WARNING("video_count(%d) >= MAX_VIDEO_TRACK_NUM(%d), so return", video_count, MAX_VIDEO_TRACK_NUM);
+    return;
+  }
+  media_video_info_node_s *video_node = (media_video_info_node_s *)&(demux->video_info->videoNodes[video_count]);
+
+  video_node->pid = (int32_t)bstream->pid;
+
+  const GstMpegtsDescriptor *desc_id = NULL;
+  desc_id = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_DVB_STREAM_IDENTIFIER);
+  if (desc_id) {
+    guint8 tag;
+    if (gst_mpegts_descriptor_parse_dvb_stream_identifier (desc_id, &tag)) {
+      GST_DEBUG ("Audio track Component Tag : 0x%02x\n", tag);
+      video_node->componentTag= (int32_t)tag;
+    }
+  }
+
+  GST_INFO_OBJECT (demux, "n_video_streams is:%d, trackID: %d, componentTag: %d",
+                             video_count+1, video_node->pid, video_node->componentTag);
+  demux->video_info->videoCount++;
+}
+#endif
+
+static void ffmpeg_fun(MpegTSBase * base, int type, int *channels, int *sample_rate, int *bit_rate) {
+    GstQuery *query;
+    gchar *uri = NULL;
+    AVFormatContext *context;
+    AVIOContext *iocontext = NULL;
+    int res,i;
+
+    res = gst_ffmpegdata_open (base->sinkpad, AVIO_FLAG_READ, &iocontext);
+
+    query = gst_query_new_uri ();
+    if (gst_pad_peer_query (base->sinkpad, query)) {
+      gchar *query_uri, *redirect_uri;
+      gboolean permanent;
+
+      gst_query_parse_uri (query, &query_uri);
+      gst_query_parse_uri_redirection (query, &redirect_uri);
+      gst_query_parse_uri_redirection_permanent (query, &permanent);
+
+      if (permanent && redirect_uri) {
+        uri = redirect_uri;
+        g_free (query_uri);
+      } else {
+        uri = query_uri;
+        g_free (redirect_uri);
+      }
+    }
+    gst_query_unref (query);
+    GST_ERROR_OBJECT (base, "Opening context with URI %s", GST_STR_NULL (uri));
+
+    context = avformat_alloc_context ();
+    if (!context) {
+        GST_ERROR("avformat_alloc_context failed!!!");
+        goto done;
+    }
+    context->pb = iocontext;
+    res = avformat_open_input (&context, uri, NULL, NULL);
+    if (res < 0) {
+        GST_ERROR("avformat_open_input failed!!!");
+        goto done;
+    }
+    GST_ERROR("nb_streams = %d", context->nb_streams);
+
+    res = avformat_find_stream_info (context, NULL);
+    for (i = 0; i < context->nb_streams; i++) {
+        if (context->streams[i]->codecpar->codec_id == type) {
+            GST_ERROR("type = %d, channels = %d sample_rate = %d bit_rate = %lld",
+                type, context->streams[i]->codecpar->channels, context->streams[i]->codecpar->sample_rate, context->streams[i]->codecpar->bit_rate);
+            *channels = context->streams[i]->codecpar->channels;
+            *sample_rate = context->streams[i]->codecpar->sample_rate;
+            *bit_rate = context->streams[i]->codecpar->bit_rate;
+        }
+    }
+
+done:
+    g_free (uri);
+    gst_ffmpegdata_close (iocontext);
+//    gst_ffmpeg_pipe_close (iocontext);
+    iocontext = NULL;
+    avformat_close_input (&context);
+    if (context)
+      avformat_free_context (context);
+    context = NULL;
+}
+
 static GstPad *
 create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
     MpegTSBaseProgram * program)
@@ -1346,18 +2506,34 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
   const GstMpegtsDescriptor *desc = NULL;
   GstPad *pad = NULL;
   gboolean sparse = FALSE;
-  gboolean is_audio = FALSE, is_video = FALSE, is_subpicture = FALSE,
+  gboolean is_audio = FALSE, is_video = FALSE, is_subpicture = FALSE, is_send_caps = FALSE,
       is_private = FALSE;
-
+#ifdef TCL_PATCH
+  gchar *codec = NULL;
+#endif
   gst_ts_demux_create_tags (stream);
 
+#ifdef TCL_PATCH
+  gboolean is_tag_set = FALSE, is_sutitle = FALSE;
+
+  stream->is_subtitle    = FALSE;
+  stream->is_video       = FALSE;
+  stream->diff_send_flag = FALSE;
+  stream->is_audio       = FALSE;
+  stream->is_send_caps   = FALSE;
+#endif
   GST_LOG_OBJECT (demux,
       "Attempting to create pad for stream 0x%04x with stream_type %d",
       bstream->pid, bstream->stream_type);
 
+#ifdef TCL_PATCH
+  if (program->registration_id == DRF_ID_HDMV ||
+        (program->registration_id==0 && bstream->registration_id == DRF_ID_HDMV)) {
+#else
   /* First handle BluRay-specific stream types since there is some overlap
    * between BluRay and non-BluRay streay type identifiers */
   if (program->registration_id == DRF_ID_HDMV) {
+#endif
     switch (bstream->stream_type) {
       case ST_BD_AUDIO_AC3:
       {
@@ -1383,17 +2559,51 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
         caps = gst_caps_new_empty_simple ("audio/x-eac3");
         break;
       case ST_BD_AUDIO_AC3_TRUE_HD:
+      {
         is_audio = TRUE;
+#ifdef TCL_PATCH
+        char supportDolbyTrueHD[128];
+        memset(supportDolbyTrueHD, 0, 128);
+        __system_property_get("persist.tcl.feature.uniplayer.supportDolbyTrueHD", supportDolbyTrueHD);
+        GST_ERROR ("persist.tcl.feature.uniplayer.supportDolbyTrueHD = %s", supportDolbyTrueHD);
+        if (!strncmp(supportDolbyTrueHD, "true", 4)) {
+            int channels, sample_rate, bit_rate;
+            ffmpeg_fun(base, AV_CODEC_ID_TRUEHD, &channels, &sample_rate, &bit_rate);
+            caps = gst_caps_new_simple ("audio/x-true-hd",
+                "rate", G_TYPE_INT, sample_rate,
+                "channels", G_TYPE_INT, channels, NULL);
+        } else {
+            GST_ERROR_OBJECT (demux,
+                "Non-media stream (stream_type:0x%x). Not creating pad",
+                bstream->stream_type);
+            GstStructure* st = NULL;
+            st = gst_structure_new("out-of-spec",
+                "is-out-spec", G_TYPE_BOOLEAN, TRUE, "copyright-risk" ,G_TYPE_BOOLEAN, TRUE, NULL);
+            gst_element_post_message (GST_ELEMENT_CAST (demux), gst_message_new_custom (GST_MESSAGE_INFO, GST_OBJECT(demux), st));
+            goto done;
+        }
+#else
         caps = gst_caps_new_empty_simple ("audio/x-true-hd");
+#endif
         stream->target_pes_substream = 0x72;
         break;
+      }
       case ST_BD_AUDIO_LPCM:
         is_audio = TRUE;
         caps = gst_caps_new_empty_simple ("audio/x-private-ts-lpcm");
         break;
       case ST_BD_PGS_SUBPICTURE:
         is_subpicture = TRUE;
+#ifdef TCL_PATCH
+        is_sutitle    = TRUE;
+        caps = gst_caps_new_simple ("subpicture/x-pgs",
+                "is_subtitle",            G_TYPE_INT,     1,
+                "pid_for_texttrack",      G_TYPE_UINT,    bstream->pid,
+                NULL);
+        gst_ts_demux_send_texttrack_for_subtitle(demux, NULL, NULL, bstream->pid);
+#else
         caps = gst_caps_new_empty_simple ("subpicture/x-pgs");
+#endif
         sparse = TRUE;
         break;
       case ST_BD_AUDIO_DTS_HD:
@@ -1425,7 +2635,16 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
           "mpegversion", G_TYPE_INT,
           bstream->stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG1 ? 1 : 2,
           "systemstream", G_TYPE_BOOLEAN, FALSE, NULL);
-
+#ifdef TCL_PATCH
+      gint64 val;
+      gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val);
+      if (bstream->stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG2 && bstream->pid == 17 && val == 119537664) {
+          GST_ERROR_OBJECT (demux, "special_stream: DMTTYJG2-377 video/mpeg stream_type = %d pid = %d val = %lld", bstream->stream_type, bstream->pid, val);
+          gst_caps_set_simple (caps, "special_stream", G_TYPE_BOOLEAN, TRUE, NULL);
+      }
+      //add end
+      codec = bstream->stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG1 ? "MPEG-1" : "MPEG-2";
+#endif
       break;
     case GST_MPEGTS_STREAM_TYPE_AUDIO_MPEG1:
     case GST_MPEGTS_STREAM_TYPE_AUDIO_MPEG2:
@@ -1449,7 +2668,11 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       if (desc) {
         GST_LOG_OBJECT (demux, "ac4 audio");
         is_audio = TRUE;
+#ifdef TCL_PATCH
+        caps = gst_caps_new_empty_simple ("audio/x-ac4-tcl");
+#else
         caps = gst_caps_new_empty_simple ("audio/x-ac4");
+#endif
         break;
       }
 
@@ -1457,17 +2680,52 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       if (desc) {
         GST_LOG_OBJECT (demux, "ac3 audio");
         is_audio = TRUE;
+#ifdef TCL_PATCH
+        gint64 val;
+        gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val);
+        if (bstream->pid == 20 && val == 119537664) {
+            GST_ERROR_OBJECT (demux, "special_stream: DMTTYJG2-377! dts audio stream_type = %d pid = %d val = %lld", bstream->stream_type, bstream->pid, val);
+            caps = gst_caps_new_empty_simple ("audio/x-dts");
+        } else {
+            caps = gst_caps_new_empty_simple ("audio/x-ac3");
+        }
+#else
         caps = gst_caps_new_empty_simple ("audio/x-ac3");
+#endif
+        break;
+      }
+
+#ifdef TCL_PATCH
+      desc = mpegts_get_descriptor_from_stream (bstream, GST_MTS_DESC_DVB_DTS);
+      if (desc) {
+        GST_LOG_OBJECT (demux, "dts audio");
+        is_audio = TRUE;
+        caps = gst_caps_new_empty_simple ("audio/x-dts");
         break;
       }
+#endif
 
       desc =
           mpegts_get_descriptor_from_stream (bstream,
           GST_MTS_DESC_DVB_ENHANCED_AC3);
       if (desc) {
         GST_LOG_OBJECT (demux, "ac3 audio");
+#ifdef TCL_PATCH
+        if (!stream->taglist)
+            stream->taglist = gst_tag_list_new_empty ();
         is_audio = TRUE;
         caps = gst_caps_new_empty_simple ("audio/x-eac3");
+
+        int channels, sample_rate, bit_rate;
+        ffmpeg_fun(base, AV_CODEC_ID_EAC3, &channels, &sample_rate, &bit_rate);
+        gst_caps_set_simple (caps, "bit_rate", G_TYPE_INT, bit_rate, NULL);
+        gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
+            GST_TAG_AUDIO_CODEC, "E-AC3", NULL);
+        is_tag_set = TRUE;
+#else
+        is_audio = TRUE;
+        caps = gst_caps_new_empty_simple ("audio/x-eac3");
+#endif
         break;
       }
       desc =
@@ -1475,9 +2733,41 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
           GST_MTS_DESC_DVB_TELETEXT);
       if (desc) {
         GST_LOG_OBJECT (demux, "teletext");
+#ifdef TCL_PATCH
+        is_private      = TRUE;
+        sparse          = TRUE;
+        is_sutitle      = TRUE;
+        gchar* lang_code= NULL;
+        int i           = 0;
+        int nb          = gst_mpegts_descriptor_parse_dvb_teletext_nb(desc);
+        for(; i < nb; i++) {
+          if(gst_mpegts_descriptor_parse_dvb_teletext_idx(desc, i, &lang_code, NULL, NULL, NULL))
+            break;
+        }
+        /* get GST_MTS_DESC_DVB_STREAM_IDENTIFIER descriptor, for html50840 */
+        const GstMpegtsDescriptor* desc_id = NULL;
+        desc_id = mpegts_get_descriptor_from_stream(bstream, GST_MTS_DESC_DVB_STREAM_IDENTIFIER);
+        char component_tag[16] = {0};
+        if(desc_id) {
+          guint8 tag;
+          if(gst_mpegts_descriptor_parse_dvb_stream_identifier(desc_id, &tag)) {
+            GST_DEBUG("Text track Component Tag : 0x%02x\n", tag);
+            sprintf(component_tag, "%d", tag);
+          }
+        }
+        caps = gst_caps_new_simple ("application/x-teletext",
+                "is_subtitle",            G_TYPE_INT,     1,
+                "id_for_texttrack",       G_TYPE_STRING,  component_tag,
+                "language_for_texttrack", G_TYPE_STRING,  lang_code,
+                "pid_for_texttrack",      G_TYPE_UINT,    bstream->pid,
+                NULL);
+        gst_ts_demux_send_texttrack_for_subtitle(demux, component_tag, lang_code, bstream->pid);
+        g_free(lang_code);
+#else
         is_private = TRUE;
         caps = gst_caps_new_empty_simple ("application/x-teletext");
         sparse = TRUE;
+#endif
         break;
       }
       desc =
@@ -1485,9 +2775,41 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
           GST_MTS_DESC_DVB_SUBTITLING);
       if (desc) {
         GST_LOG_OBJECT (demux, "subtitling");
+#ifdef TCL_PATCH
+        is_subpicture   = TRUE;
+        is_sutitle      = TRUE;
+        sparse          = TRUE;
+        gchar* lang_code= NULL;
+        int i           = 0;
+        int nb          = gst_mpegts_descriptor_parse_dvb_subtitling_nb (desc);
+        for(; i < nb; i++) {
+          if(gst_mpegts_descriptor_parse_dvb_subtitling_idx(desc, i, &lang_code, NULL, NULL, NULL))
+            break;
+        }
+        char  component_tag[16] = {0};
+        /* get GST_MTS_DESC_DVB_STREAM_IDENTIFIER  descriptor*/
+        const GstMpegtsDescriptor* desc_id = NULL;
+        desc_id = mpegts_get_descriptor_from_stream(bstream, GST_MTS_DESC_DVB_STREAM_IDENTIFIER);
+        if(desc_id) {
+          guint8 tag;
+          if(gst_mpegts_descriptor_parse_dvb_stream_identifier(desc_id, &tag)) {
+            GST_DEBUG("Text track Component Tag : 0x%02x\n", tag);
+            sprintf(component_tag, "%d", tag);
+          }
+        }
+        caps = gst_caps_new_simple ("subpicture/x-dvb",
+                "is_subtitle",            G_TYPE_INT,     1,
+                "id_for_texttrack",       G_TYPE_STRING,  component_tag,
+                "language_for_texttrack", G_TYPE_STRING,  lang_code,
+                "pid_for_texttrack",      G_TYPE_UINT,    bstream->pid,
+                NULL);
+        gst_ts_demux_send_texttrack_for_subtitle(demux, component_tag, lang_code, bstream->pid);
+        g_free(lang_code);
+#else
         is_subpicture = TRUE;
         caps = gst_caps_new_empty_simple ("subpicture/x-dvb");
         sparse = TRUE;
+#endif
         break;
       }
 
@@ -1495,9 +2817,24 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
         case DRF_ID_DTS1:
         case DRF_ID_DTS2:
         case DRF_ID_DTS3:
+#ifdef TCL_PATCH
+        case DRF_ID_DTSH:
+#endif
+#ifdef TCL_PATCH
+          is_audio = TRUE;
+#else
           /* SMPTE registered DTS */
           is_private = TRUE;
+#endif
           caps = gst_caps_new_empty_simple ("audio/x-dts");
+#ifdef TCL_PATCH
+          gint64 val;
+          gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val);
+          if (val == 26838007868) {
+            demux->special_file_flag = TRUE;
+            base->packetizer->special_file_flag = TRUE;
+          }
+#endif
           break;
         case DRF_ID_S302M:
           is_audio = TRUE;
@@ -1675,8 +3012,15 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
           break;
         case DRF_ID_HEVC:
           is_video = TRUE;
+#ifdef TCL_PATCH
+          caps = gst_caps_new_simple ("video/x-h265-tcl",
+#else
           caps = gst_caps_new_simple ("video/x-h265",
+#endif
               "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+#ifdef TCL_PATCH
+          codec = "HEVC";
+#endif
           break;
         case DRF_ID_KLVA:
           sparse = TRUE;
@@ -1686,8 +3030,56 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
           break;
         case DRF_ID_AC4:
           is_audio = TRUE;
+#ifdef TCL_PATCH
+          caps = gst_caps_new_empty_simple ("audio/x-ac4-tcl");
+#else
           caps = gst_caps_new_empty_simple ("audio/x-ac4");
+#endif
           break;
+#ifdef TCL_PATCH
+        case DRF_ID_DOVI:
+          desc = mpegts_get_descriptor_from_stream (bstream, DESCRIPTOR_HEVC_VIDEO);
+          if (desc != NULL && desc->length >= 1) {
+            caps = gst_caps_new_simple ("video/x-h265-tcl", "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+            bstream->private_stream_type = GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC;
+            is_video = TRUE;
+          }
+
+          desc = mpegts_get_descriptor_from_stream (bstream, DESCRIPTOR_AVC_VIDEO);
+          if (desc != NULL && desc->length >= 1) {
+            caps = gst_caps_new_simple ("video/x-h264-tcl", "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+            is_video = TRUE;
+          }
+
+          desc = mpegts_get_descriptor_from_stream (bstream, DESCRIPTOR_DOVI_VIDEO_STREAM);
+          if (desc != NULL && desc->length >= 4) {
+            GstByteReader br;
+            /* skip tag, length*/
+            gst_byte_reader_init (&br, desc->data + 2, desc->length - 1);
+            guint8 dv_version_major = gst_byte_reader_get_uint8_unchecked (&br);
+            guint8 dv_version_minor = gst_byte_reader_get_uint8_unchecked (&br);
+            guint16 dv_configure = gst_byte_reader_get_uint16_be_unchecked (&br);
+            guint8 dv_profile = (dv_configure >> 9) & 0x007F;
+            guint8 dv_level = (dv_configure >> 3) & 0x003F;
+            guint8 rpu_present_flag = (dv_configure >> 2) & 0x0001;
+            guint8 el_present_flag = (dv_configure >> 1) & 0x0001;
+            guint8 bl_present_flag = (dv_configure) & 0x0001;
+            guint8 dv_bl_signal_compatibility_id = gst_byte_reader_get_uint8_unchecked (&br) & 0x0F;
+            if (caps) {
+              gst_caps_set_simple (caps, "is_doblyVision", G_TYPE_BOOLEAN, TRUE,
+                              "dv_version_major", G_TYPE_UINT, dv_version_major,
+                              "dv_version_minor", G_TYPE_UINT, dv_version_minor,
+                              "dv_profile", G_TYPE_UINT, dv_profile,
+                              "dv_level", G_TYPE_UINT, dv_level,
+                              "rpu_present_flag", G_TYPE_UINT, rpu_present_flag,
+                              "el_present_flag", G_TYPE_UINT, el_present_flag,
+                              "bl_present_flag", G_TYPE_UINT, bl_present_flag,
+                              "dv_bl_signal_compatibility_id", G_TYPE_UINT, dv_bl_signal_compatibility_id,
+                              NULL);
+            }
+          }
+          break;
+#endif
       }
       if (caps)
         break;
@@ -1695,7 +3087,11 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       /* hack for itv hd (sid 10510, video pid 3401 */
       if (program->program_number == 10510 && bstream->pid == 3401) {
         is_video = TRUE;
+#ifdef TCL_PATCH
+        caps = gst_caps_new_simple ("video/x-h264-tcl",
+#else
         caps = gst_caps_new_simple ("video/x-h264",
+#endif
             "stream-format", G_TYPE_STRING, "byte-stream", NULL);
       }
       break;
@@ -1723,26 +3119,124 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       stream->atdsInfos.mpegversion = 4;
       break;
     case GST_MPEGTS_STREAM_TYPE_AUDIO_AAC_LATM:
+#ifdef TCL_PATCH
+      if (!stream->taglist)
+        stream->taglist = gst_tag_list_new_empty ();
+      is_audio = TRUE;
+      gint stream_pid = stream->stream.stream->pid;
+      caps = gst_caps_new_simple ("audio/mpeg",
+          "mpegversion", G_TYPE_INT, 4,
+          "codec_set", G_TYPE_BOOLEAN, TRUE,
+          "stream-format", G_TYPE_STRING, "loas",
+          "stream_pid", G_TYPE_INT, stream_pid, NULL);
+      gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
+          GST_TAG_AUDIO_CODEC, "HEAAC", NULL);
+      is_tag_set = TRUE;
+#else
       is_audio = TRUE;
       caps = gst_caps_new_simple ("audio/mpeg",
           "mpegversion", G_TYPE_INT, 4,
           "stream-format", G_TYPE_STRING, "loas", NULL);
+#endif
       break;
     case GST_MPEGTS_STREAM_TYPE_VIDEO_MPEG4:
       is_video = TRUE;
       caps = gst_caps_new_simple ("video/mpeg",
           "mpegversion", G_TYPE_INT, 4,
           "systemstream", G_TYPE_BOOLEAN, FALSE, NULL);
+#ifdef TCL_PATCH
+      codec = "MPEG_4";
+#endif
       break;
     case GST_MPEGTS_STREAM_TYPE_VIDEO_H264:
       is_video = TRUE;
+#ifdef TCL_PATCH
+      caps = gst_caps_new_simple ("video/x-h264-tcl",
+#else
       caps = gst_caps_new_simple ("video/x-h264",
+#endif
           "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+#ifdef TCL_PATCH
+          gint64 fileSize;
+          gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &fileSize);
+          if (fileSize == 35476864488) {
+            base->packetizer->may_bad_pcr = TRUE;
+          }
+#endif
+
+#ifdef TCL_PATCH
+      desc = mpegts_get_descriptor_from_stream (bstream, DESCRIPTOR_DOVI_VIDEO_STREAM);
+      if (desc != NULL && desc->length >= 4) {
+        GstByteReader br;
+        /* skip tag, length*/
+        gst_byte_reader_init (&br, desc->data + 2, desc->length - 1);
+        guint8 dv_version_major = gst_byte_reader_get_uint8_unchecked (&br);
+        guint8 dv_version_minor = gst_byte_reader_get_uint8_unchecked (&br);
+        guint16 dv_configure = gst_byte_reader_get_uint16_be_unchecked (&br);
+        guint8 dv_profile = (dv_configure >> 9) & 0x007F;
+        guint8 dv_level = (dv_configure >> 3) & 0x003F;
+        guint8 rpu_present_flag = (dv_configure >> 2) & 0x0001;
+        guint8 el_present_flag = (dv_configure >> 1) & 0x0001;
+        guint8 bl_present_flag = (dv_configure) & 0x0001;
+        guint8 dv_bl_signal_compatibility_id = gst_byte_reader_get_uint8_unchecked (&br) & 0x0F;
+        if (caps) {
+          gst_caps_set_simple (caps, "is_doblyVision", G_TYPE_BOOLEAN, TRUE,
+                          "dv_version_major", G_TYPE_UINT, dv_version_major,
+                          "dv_version_minor", G_TYPE_UINT, dv_version_minor,
+                          "dv_profile", G_TYPE_UINT, dv_profile,
+                          "dv_level", G_TYPE_UINT, dv_level,
+                          "rpu_present_flag", G_TYPE_UINT, rpu_present_flag,
+                          "el_present_flag", G_TYPE_UINT, el_present_flag,
+                          "bl_present_flag", G_TYPE_UINT, bl_present_flag,
+                          "dv_bl_signal_compatibility_id", G_TYPE_UINT, dv_bl_signal_compatibility_id,
+                          NULL);
+        }
+      }
+#endif
+#ifdef TCL_PATCH
+      codec = "H264";
+#endif
       break;
     case GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC:
       is_video = TRUE;
+#ifdef TCL_PATCH
+      caps = gst_caps_new_simple ("video/x-h265-tcl",
+#else
       caps = gst_caps_new_simple ("video/x-h265",
+#endif
           "stream-format", G_TYPE_STRING, "byte-stream", NULL);
+#ifdef TCL_PATCH
+      desc = mpegts_get_descriptor_from_stream (bstream, DESCRIPTOR_DOVI_VIDEO_STREAM);
+      if (desc != NULL && desc->length >= 4) {
+        GstByteReader br;
+        /* skip tag, length*/
+        gst_byte_reader_init (&br, desc->data + 2, desc->length - 1);
+        guint8 dv_version_major = gst_byte_reader_get_uint8_unchecked (&br);
+        guint8 dv_version_minor = gst_byte_reader_get_uint8_unchecked (&br);
+        guint16 dv_configure = gst_byte_reader_get_uint16_be_unchecked (&br);
+        guint8 dv_profile = (dv_configure >> 9) & 0x007F;
+        guint8 dv_level = (dv_configure >> 3) & 0x003F;
+        guint8 rpu_present_flag = (dv_configure >> 2) & 0x0001;
+        guint8 el_present_flag = (dv_configure >> 1) & 0x0001;
+        guint8 bl_present_flag = (dv_configure) & 0x0001;
+        guint8 dv_bl_signal_compatibility_id = gst_byte_reader_get_uint8_unchecked (&br) & 0x0F;
+        if (caps) {
+          gst_caps_set_simple (caps, "is_doblyVision", G_TYPE_BOOLEAN, TRUE,
+                          "dv_version_major", G_TYPE_UINT, dv_version_major,
+                          "dv_version_minor", G_TYPE_UINT, dv_version_minor,
+                          "dv_profile", G_TYPE_UINT, dv_profile,
+                          "dv_level", G_TYPE_UINT, dv_level,
+                          "rpu_present_flag", G_TYPE_UINT, rpu_present_flag,
+                          "el_present_flag", G_TYPE_UINT, el_present_flag,
+                          "bl_present_flag", G_TYPE_UINT, bl_present_flag,
+                          "dv_bl_signal_compatibility_id", G_TYPE_UINT, dv_bl_signal_compatibility_id,
+                          NULL);
+        }
+      }
+#endif
+#ifdef TCL_PATCH
+      codec = "HEVC";
+#endif
       break;
     case GST_MPEGTS_STREAM_TYPE_VIDEO_JP2K:
       is_video = TRUE;
@@ -1828,6 +3322,9 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
         is_video = TRUE;
         caps = gst_caps_new_empty_simple ("video/x-dirac");
       }
+#ifdef TCL_PATCH
+      codec = "DIRAC";
+#endif
       break;
     case ST_PRIVATE_EA:        /* Try to detect a VC1 stream */
     {
@@ -1846,7 +3343,19 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       is_video = TRUE;
       caps = gst_caps_new_simple ("video/x-wmv",
           "wmvversion", G_TYPE_INT, 3, "format", G_TYPE_STRING, "WVC1", NULL);
-
+#ifdef TCL_PATCH
+       codec = "Windows Media Video 9";
+      gint64 val;
+      gst_pad_peer_query_duration (base->sinkpad, GST_FORMAT_BYTES, &val);
+      if (val == 18860618908) {
+        demux->special_file_flag = TRUE;
+        base->packetizer->special_file_flag = TRUE;
+        gst_caps_set_simple (caps, "ignore_invalid_pts", G_TYPE_BOOLEAN, TRUE, NULL);
+      }
+      if(is_vc1){
+        codec = "VC-1";
+      }
+#endif
       break;
     }
     case ST_PS_AUDIO_AC3:
@@ -1902,6 +3411,9 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       is_audio = TRUE;
       caps = gst_caps_new_empty_simple ("audio/x-private2-lpcm");
       break;
+#ifdef TCL_PATCH
+    case ST_BD_AUDIO_DTS:
+#endif
     case ST_PS_AUDIO_DTS:
       is_audio = TRUE;
       caps = gst_caps_new_empty_simple ("audio/x-dts");
@@ -1912,7 +3424,16 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       break;
     case ST_PS_DVD_SUBPICTURE:
       is_subpicture = TRUE;
+#ifdef TCL_PATCH
+      is_sutitle    = TRUE;
+      caps = gst_caps_new_simple ("subpicture/x-dvd",
+                "is_subtitle",            G_TYPE_INT,     1,
+                "pid_for_texttrack",      G_TYPE_UINT,    bstream->pid,
+                NULL);
+      gst_ts_demux_send_texttrack_for_subtitle(demux, NULL, NULL, bstream->pid);
+#else
       caps = gst_caps_new_empty_simple ("subpicture/x-dvd");
+#endif
       sparse = TRUE;
       break;
     case 0x42:
@@ -1921,6 +3442,20 @@ create_pad_for_stream (MpegTSBase * base, MpegTSBaseStream * bstream,
       is_video = TRUE;
       caps = gst_caps_new_empty_simple ("video/x-cavs");
       break;
+#ifdef TCL_PATCH
+    case 0xd2:
+      /* hack for Chinese AVS2 video stream which use 0xd2 as stream_id
+       * NOTE: this is unofficial and within the ISO reserved range. */
+      is_video = TRUE;
+      caps = gst_caps_new_empty_simple ("video/x-gst-fourcc-avs2");
+      break;
+    case 0x33:
+      /* hack for vvc1 video stream which use 0x33 as stream_id
+       * NOTE: this is unofficial and within the ISO reserved range. */
+      is_video = TRUE;
+      caps = gst_caps_new_empty_simple ("video/x-gst-fourcc-vvc1");
+      break;
+#endif
     default:
       GST_DEBUG_OBJECT (demux,
           "Non-media stream (stream_type:0x%x). Not creating pad",
@@ -1937,6 +3472,12 @@ done:
           bstream->pid);
       gst_stream_set_stream_type (bstream->stream_object,
           GST_STREAM_TYPE_AUDIO);
+
+#ifdef TCL_PATCH
+      gst_ts_demux_get_audio_infos(demux, bstream, program);
+      TSDemuxStream *stream = (TSDemuxStream *) bstream;
+      stream->is_audio = TRUE;
+#endif
     } else if (is_video) {
       template = gst_static_pad_template_get (&video_template);
       name =
@@ -1944,6 +3485,24 @@ done:
           bstream->pid);
       gst_stream_set_stream_type (bstream->stream_object,
           GST_STREAM_TYPE_VIDEO);
+#ifdef TCL_PATCH
+      gst_ts_demux_gst_video_infos(demux, bstream, program);
+      TSDemuxStream *stream = (TSDemuxStream *) bstream;
+      stream->is_video = TRUE;
+#endif
+#ifdef TCL_PATCH
+    if (!stream->taglist)
+      stream->taglist = gst_tag_list_new_empty ();
+    if(!codec) {
+      const GstStructure* st = gst_caps_get_structure(caps, 0);
+      const gchar *name = gst_structure_get_name(st);
+      gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
+         GST_TAG_VIDEO_CODEC, name, NULL);
+    } else {
+      gst_tag_list_add (stream->taglist, GST_TAG_MERGE_REPLACE,
+        GST_TAG_VIDEO_CODEC, codec, NULL);
+    }
+#endif
     } else if (is_private) {
       template = gst_static_pad_template_get (&private_template);
       name =
@@ -1960,6 +3519,9 @@ done:
 
   }
 
+#ifdef TCL_PATCH
+  stream->is_subtitle =  is_sutitle;
+#endif
   if (template && name && caps) {
     GstEvent *event;
     const gchar *stream_id;
@@ -1996,6 +3558,9 @@ done:
     gst_stream_set_caps (bstream->stream_object, caps);
     if (!stream->taglist)
       stream->taglist = gst_tag_list_new_empty ();
+#ifdef TCL_PATCH
+    if (!is_tag_set)
+#endif
     gst_pb_utils_add_codec_description_to_tag_list (stream->taglist, NULL,
         caps);
     gst_stream_set_tags (bstream->stream_object, stream->taglist);
@@ -2026,8 +3591,12 @@ gst_ts_demux_stream_added (MpegTSBase * base, MpegTSBaseStream * bstream,
     /* Create the pad */
     if (bstream->stream_type != 0xff) {
       stream->pad = create_pad_for_stream (base, bstream, program);
-      if (stream->pad)
+      if (stream->pad) {
         gst_flow_combiner_add_pad (demux->flowcombiner, stream->pad);
+#ifdef TCL_PATCH
+        program->have_stream_pad = TRUE;
+#endif
+      }
     }
 
     if (base->mode != BASE_MODE_PUSHING
@@ -2058,6 +3627,17 @@ gst_ts_demux_stream_added (MpegTSBase * base, MpegTSBaseStream * bstream,
     /* Only wait for a valid timestamp if we have a PCR_PID */
     stream->pending_ts = program->pcr_pid < 0x1fff;
     stream->continuity_counter = CONTINUITY_UNSET;
+
+#ifdef TCL_PATCH
+    stream->first_pts_diff = GST_CLOCK_TIME_NONE;
+    stream->first_dts_diff = GST_CLOCK_TIME_NONE;
+    stream->pts_skew = 0;
+    stream->dts_skew = 0;
+    stream->pre_push_pts = 0;
+    stream->unsupport = FALSE;
+    stream->is_set_channels = FALSE;
+    stream->first_pts_offset_for_base = -1;
+#endif
   }
 
   return (stream->pad != NULL);
@@ -2124,6 +3704,9 @@ activate_pad_for_stream (GstTSDemux * tsdemux, TSDemuxStream * stream)
     gst_element_add_pad ((GstElement *) tsdemux, stream->pad);
     stream->active = TRUE;
     GST_DEBUG_OBJECT (stream->pad, "done adding pad");
+#ifdef TCL_PATCH
+    tsdemux->program_started = TRUE;
+#endif
   } else if (((MpegTSBaseStream *) stream)->stream_type != 0xff) {
     GST_DEBUG_OBJECT (tsdemux,
         "stream %p (pid 0x%04x, type:0x%02x) has no pad", stream,
@@ -2158,6 +3741,12 @@ gst_ts_demux_stream_flush (TSDemuxStream * stream, GstTSDemux * tsdemux,
   stream->gap_ref_pts = GST_CLOCK_TIME_NONE;
   stream->continuity_counter = CONTINUITY_UNSET;
 
+#ifdef TCL_PATCH
+  stream->pts_skew = 0;
+  stream->dts_skew = 0;
+  stream->pre_push_pts = 0;
+#endif
+
   if (G_UNLIKELY (stream->pending)) {
     GList *tmp;
 
@@ -2184,8 +3773,19 @@ gst_ts_demux_flush_streams (GstTSDemux * demux, gboolean hard)
   if (!demux->program)
     return;
 
+#ifdef TCL_PATCH
+  for (walk = demux->program->stream_list; walk; walk = g_list_next (walk)) {
+    MpegTSBaseStream *bs = (MpegTSBaseStream *) walk->data;
+    if (bs && (bs->stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC || bs->private_stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC || (bs->stream_type == GST_MPEGTS_STREAM_TYPE_PRIVATE_PES_PACKETS && bs->registration_id == DRF_ID_HEVC))) {
+      demux->is_seeking = TRUE;
+    }
+
+    gst_ts_demux_stream_flush (walk->data, demux, hard);
+  }
+#else
   for (walk = demux->program->stream_list; walk; walk = g_list_next (walk))
     gst_ts_demux_stream_flush (walk->data, demux, hard);
+#endif
 }
 
 static gboolean
@@ -2243,8 +3843,29 @@ gst_ts_demux_program_started (MpegTSBase * base, MpegTSBaseProgram * program)
       (gint) demux->program_number, program->program_number,
       demux->requested_program_number);
 
+#ifdef TCL_PATCH
+  guint i = 0;
+  if (demux->program_count == 0) {
+    memset(demux->program_numbers, -1, sizeof(gint) * 32);
+  }
+  for (i = 0; i < 32; i++) {
+    if (demux->program_numbers[i] == program->program_number) {
+      break;
+    }
+    if (demux->program_numbers[i] == -1) {
+      demux->program_numbers[i] = program->program_number;
+      demux->program_count++;
+      break;
+    }
+  }
+  if (program->have_stream_pad == TRUE &&
+     (demux->requested_program_number == program->program_number ||
+        (demux->requested_program_number == -1 && demux->program_number == -1))) {
+
+#else
   if (demux->requested_program_number == program->program_number ||
       (demux->requested_program_number == -1 && demux->program_number == -1)) {
+#endif
     GList *tmp;
     gboolean have_pads = FALSE;
 
@@ -2252,6 +3873,15 @@ gst_ts_demux_program_started (MpegTSBase * base, MpegTSBaseProgram * program)
     demux->program_number = program->program_number;
     demux->program = program;
 
+#ifdef TCL_PATCH
+    gint program_index = 0;
+    for (program_index = 0; program_index < demux->audio_info_list.programCount; program_index++) {
+      if (demux->audio_info_list.audioExtendInfos[program_index]->programNumber == demux->program_number) {
+        demux->audio_info = demux->audio_info_list.audioExtendInfos[program_index]->audioInfo;
+        break;
+      }
+    }
+#endif
     /* Increment the program_generation counter */
     demux->program_generation = (demux->program_generation + 1) & 0xf;
 
@@ -2320,7 +3950,44 @@ gst_ts_demux_program_started (MpegTSBase * base, MpegTSBaseProgram * program)
     }
 
     gst_element_no_more_pads ((GstElement *) demux);
+
+#ifdef TCL_PATCH
+    GstStructure *st;
+    if (demux->audio_info != NULL && demux->video_info != NULL) {
+      GST_LOG ("post audio-info and video-info with ELEMENT message");
+      st = gst_structure_new ("tsdemux-media-info",
+          "audio-info", G_TYPE_POINTER,demux->audio_info,
+          "video-info", G_TYPE_POINTER,demux->video_info,
+          NULL);
+      gst_element_post_message (GST_ELEMENT_CAST(demux),
+      gst_message_new_element (GST_OBJECT(demux), st));
+    } else if (demux->audio_info != NULL) {
+      GST_LOG ("post only audio-info with ELEMENT message");
+      st = gst_structure_new ("tsdemux-media-info",
+          "audio-info", G_TYPE_POINTER,demux->audio_info,
+          NULL);
+      gst_element_post_message (GST_ELEMENT_CAST(demux),
+      gst_message_new_element (GST_OBJECT(demux), st));
+    } else if (demux->video_info != NULL) {
+        GST_LOG ("post only video-info with ELEMENT message");
+        st = gst_structure_new ("tsdemux-media-info",
+            "video-info", G_TYPE_POINTER,demux->video_info,
+            NULL);
+        gst_element_post_message (GST_ELEMENT_CAST(demux),
+        gst_message_new_element (GST_OBJECT(demux), st));
+    } else
+        GST_LOG ("demux->audio_info == NULL and demux->video_info == NULL");
+
+  }
+  if (demux->program_count >= g_hash_table_size(base->programs) &&
+      demux->program_started == FALSE) {
+    GError *err = g_error_new (GST_STREAM_ERROR, GST_STREAM_ERROR_DEMUX, "Couldn't active stream");
+    GstMessage *msg = gst_message_new_error (GST_OBJECT_CAST (demux), err, "Couldn't active stream");
+    gst_element_post_message (GST_ELEMENT_CAST (demux), msg);
+  }
+#else
   }
+#endif
 }
 
 static void
@@ -2331,6 +3998,28 @@ gst_ts_demux_program_stopped (MpegTSBase * base, MpegTSBaseProgram * program)
   if (demux->program == program) {
     demux->program = NULL;
     demux->program_number = -1;
+
+#ifdef TCL_PATCH
+    gint program_index = 0;
+    for (program_index = 0; program_index < demux->audio_info_list.programCount; program_index++) {
+      if (demux->audio_info_list.audioExtendInfos[program_index] != NULL) {
+        if (demux->audio_info_list.audioExtendInfos[program_index]->audioInfo != NULL) {
+          free(demux->audio_info_list.audioExtendInfos[program_index]->audioInfo);
+        }
+        free(demux->audio_info_list.audioExtendInfos[program_index]);
+        demux->audio_info_list.audioExtendInfos[program_index] = NULL;
+      }
+    }
+    demux->audio_info =NULL;
+
+    if(demux->video_info != NULL) {
+      GST_DEBUG ("demux->video_info != NULL, free it");
+      free(demux->video_info);
+      demux->video_info =NULL;
+    }
+    else
+      GST_DEBUG ("demux->video_info == NULL, do nothing");
+#endif
   }
 }
 
@@ -2348,14 +4037,21 @@ gst_ts_demux_record_pts (GstTSDemux * demux, TSDemuxStream * stream,
     return;
   }
 
-  GST_LOG ("pid 0x%04x raw pts:%" G_GUINT64_FORMAT " at offset %"
+   GST_LOG ("pid 0x%04x raw pts:%" G_GUINT64_FORMAT " at offset %"
       G_GUINT64_FORMAT, bs->pid, pts, offset);
-
   /* Compute PTS in GstClockTime */
+#ifdef TCL_PATCH
+  if(demux->is_invalid_pcr == TRUE || demux->is_bad_pts == TRUE){
+    stream->pts = MPEGTIME_TO_GSTTIME (pts);
+  } else {
+    stream->pts = mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
+    MPEGTIME_TO_GSTTIME (pts), demux->program->pcr_pid);
+  }
+#else
   stream->pts =
       mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
       MPEGTIME_TO_GSTTIME (pts), demux->program->pcr_pid);
-
+#endif
   if (base->out_segment.format == GST_FORMAT_TIME)
     demux->mpeg_pts_offset =
         (GSTTIME_TO_MPEGTIME (gst_segment_to_running_time (&base->out_segment,
@@ -2404,9 +4100,18 @@ gst_ts_demux_record_dts (GstTSDemux * demux, TSDemuxStream * stream,
       G_GUINT64_FORMAT, bs->pid, dts, offset);
 
   /* Compute DTS in GstClockTime */
+#ifdef TCL_PATCH
+    if(demux->is_invalid_pcr == TRUE || demux->is_bad_pts == TRUE){
+      stream->dts = MPEGTIME_TO_GSTTIME (dts);
+    } else {
+      stream->dts = mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
+      MPEGTIME_TO_GSTTIME (dts), demux->program->pcr_pid);
+    }
+#else
   stream->dts =
       mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
       MPEGTIME_TO_GSTTIME (dts), demux->program->pcr_pid);
+#endif
 
   GST_LOG ("pid 0x%04x Stored DTS %" G_GUINT64_FORMAT, bs->pid, stream->dts);
 
@@ -2568,17 +4273,44 @@ check_pending_buffers (GstTSDemux * demux)
     }
     /* Recalculate PTS/DTS (in running time) for current data */
     if (stream->state != PENDING_PACKET_EMPTY) {
+#ifdef TCL_PATCH
+      if (stream->raw_pts != -1 && stream->pts_skew == 0) {
+#else
       if (stream->raw_pts != -1) {
+#endif
+#ifdef TCL_PATCH
+      if(demux->is_invalid_pcr == TRUE || demux->is_bad_pts == TRUE){
+          stream->pts = MPEGTIME_TO_GSTTIME (stream->raw_pts);
+      } else {
+          stream->pts = mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
+              MPEGTIME_TO_GSTTIME (stream->raw_pts), demux->program->pcr_pid);
+      }
+#else
         stream->pts =
             mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
             MPEGTIME_TO_GSTTIME (stream->raw_pts), demux->program->pcr_pid);
+#endif
         if (stream->first_pts == GST_CLOCK_TIME_NONE)
           stream->first_pts = stream->pts;
       }
+
+#ifdef TCL_PATCH
+      if (stream->raw_dts != -1 && stream->dts_skew == 0) {
+#else
       if (stream->raw_dts != -1) {
+#endif
+#ifdef TCL_PATCH
+        if(demux->is_invalid_pcr == TRUE || demux->is_bad_pts == TRUE){
+            stream->dts = MPEGTIME_TO_GSTTIME (stream->raw_dts);
+        } else {
+            stream->dts = mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
+                MPEGTIME_TO_GSTTIME (stream->raw_dts), demux->program->pcr_pid);
+        }
+#else
         stream->dts =
             mpegts_packetizer_pts_to_ts (MPEG_TS_BASE_PACKETIZER (demux),
             MPEGTIME_TO_GSTTIME (stream->raw_dts), demux->program->pcr_pid);
+#endif
         if (stream->first_pts == GST_CLOCK_TIME_NONE)
           stream->first_pts = stream->dts;
       }
@@ -2623,11 +4355,49 @@ gst_ts_demux_parse_pes_header (GstTSDemux * demux, TSDemuxStream * stream,
     goto discont;
   }
 
+#ifdef TCL_PATCH
+  if (stream->stream.stream_type == ST_BD_AUDIO_DTS_HD_MASTER_AUDIO) {
+    if (header.stream_id_extension != 0x71 && header.stream_id_extension != 0x72) {
+      GST_DEBUG ("Skipping unwanted substream stream_id_extension:%d", header.stream_id_extension);
+      goto discont;
+    }
+  } else if (stream->target_pes_substream != 0
+      && header.stream_id_extension != stream->target_pes_substream) {
+    GST_DEBUG ("Skipping unwanted substream");
+    goto discont;
+  }
+#else
   if (stream->target_pes_substream != 0
       && header.stream_id_extension != stream->target_pes_substream) {
     GST_DEBUG ("Skipping unwanted substream");
     goto discont;
   }
+#endif
+
+#ifdef TCL_PATCH
+  MpegTSBase *base = GST_MPEGTS_BASE (demux);
+  if(demux->is_invalid_pcr != TRUE && header.PTS != -1 && base->is_hls == FALSE) {
+    demux->is_invalid_pcr = mpegts_packetizer_check_invalid_pcr(MPEG_TS_BASE_PACKETIZER (demux),
+        MPEGTIME_TO_GSTTIME (header.PTS), demux->program->pcr_pid, demux->is_invalid_pcr, base->is_m2ts);
+  }
+  if (demux->is_bad_pts != TRUE && header.PTS != -1 && base->is_hls == FALSE) {
+    demux->is_bad_pts = mpegts_packetizer_check_bad_pts (MPEG_TS_BASE_PACKETIZER (demux),
+        MPEGTIME_TO_GSTTIME (header.PTS), demux->program->pcr_pid);
+  }
+  if(demux->is_invalid_pcr == TRUE && strstr(gst_pad_get_name(stream->pad),"audio")){
+    stream->is_audio = TRUE;
+  }
+  if(demux->is_invalid_pcr == TRUE && strstr(gst_pad_get_name(stream->pad),"video")){
+    stream->is_video = TRUE;
+  }
+#endif
+
+#ifdef TCL_PATCH
+      if (stream->is_audio == 0 && (header.DTS > header.PTS) &&
+          (header.DTS -  header.PTS > 20 * 3600 * GST_SECOND/10000)) {
+        header.DTS = header.PTS;
+      }
+#endif
 
   gst_ts_demux_record_dts (demux, stream, header.DTS, bufferoffset);
   gst_ts_demux_record_pts (demux, stream, header.PTS, bufferoffset);
@@ -2809,7 +4579,11 @@ calculate_and_push_newsegment (GstTSDemux * demux, TSDemuxStream * stream,
   GList *tmp;
 
   GST_DEBUG_OBJECT (demux, "Creating new newsegment for stream %p", stream);
-
+#ifdef TCL_PATCH
+  if(demux->duration <= 0){
+     gst_ts_demux_get_duration(demux, &demux->duration);
+  }
+#endif
   if (target_program == NULL)
     target_program = demux->program;
 
@@ -2833,9 +4607,23 @@ calculate_and_push_newsegment (GstTSDemux * demux, TSDemuxStream * stream,
   }
   if (GST_CLOCK_TIME_IS_VALID (lowest_pts))
     firstts = lowest_pts;
+
+  GST_DEBUG_OBJECT (stream->pad, "lowest_pts %" G_GUINT64_FORMAT " => clocktime %" GST_TIME_FORMAT", stream->first_pts_diff %"G_GUINT64_FORMAT,
+      lowest_pts, GST_TIME_ARGS (firstts), stream->first_pts_diff);
+#ifdef TCL_PATCH
+  if (GST_CLOCK_TIME_IS_VALID (stream->first_pts_diff))
+    firstts -= stream->first_pts_diff;
+
+  if (GST_CLOCK_TIME_IS_VALID(firstts) && firstts >= demux->duration) {
+     firstts = 0;
+  }
+
+  GST_DEBUG_OBJECT (stream->pad, "firstts %" G_GUINT64_FORMAT " : clocktime %" GST_TIME_FORMAT,
+      firstts, GST_TIME_ARGS (firstts));
+#else
   GST_DEBUG_OBJECT (demux, "lowest_pts %" G_GUINT64_FORMAT " => clocktime %"
       GST_TIME_FORMAT, lowest_pts, GST_TIME_ARGS (firstts));
-
+#endif
   if (base->out_segment.format != GST_FORMAT_TIME || demux->reset_segment) {
     /* It will happen only if it's first program or after flushes. */
     GST_DEBUG_OBJECT (demux, "Calculating actual segment");
@@ -3307,6 +5095,148 @@ out:
   return gst_buffer_new_wrapped (stream->data, stream->current_size);
 }
 
+#ifdef TCL_PATCH
+#define PTS_OFFSET_THRESHOLD 500000000
+static GstFlowReturn
+gst_ts_demux_fix_data_timestamp (GstTSDemux * demux, TSDemuxStream * stream, GstBuffer *buffer, GstBufferList *buffer_list)
+{
+   if ((stream->is_audio && GST_CLOCK_TIME_IS_VALID(demux->video_diff_pts)
+        && (gint64)(demux->video_diff_pts - stream->pts) > (gint64)140000000
+        && stream->first_pts_diff == GST_CLOCK_TIME_NONE)
+       || (stream->is_audio && demux->video_info && demux->video_info->videoCount > 0 && !GST_CLOCK_TIME_IS_VALID(demux->video_diff_pts))) {
+     if (buffer)
+       gst_buffer_unref (buffer);
+     if (buffer_list)
+       gst_buffer_list_unref (buffer_list);
+    return GST_FLOW_CUSTOM_ERROR;
+  }
+
+  if (stream->first_pts_diff == GST_CLOCK_TIME_NONE) {
+    if (GST_CLOCK_TIME_IS_VALID (stream->pts))
+      stream->first_pts_diff = stream->pts;
+    else if (GST_CLOCK_TIME_IS_VALID (stream->dts))
+      stream->first_pts_diff = stream->dts;
+
+    if(stream->is_video && GST_CLOCK_TIME_IS_VALID (stream->pts) && stream->diff_send_flag == FALSE) {
+      demux->video_diff_pts  = stream->first_pts_diff > 0 ? stream->first_pts_diff :  (GstClockTime)0;
+      stream->diff_send_flag = TRUE;
+    } else if (stream->is_video && GST_CLOCK_TIME_IS_VALID (stream->dts) && stream->diff_send_flag == FALSE) {
+      demux->video_diff_pts  = stream->first_pts_diff > 0 ? stream->first_pts_diff :  (GstClockTime)0;
+      stream->diff_send_flag = TRUE;
+    }
+  } else if (((stream->first_pts_diff > stream->pts && (stream->first_pts_diff - stream->pts) > PTS_OFFSET_THRESHOLD) && GST_CLOCK_TIME_IS_VALID (stream->pts))
+    || (!GST_CLOCK_TIME_IS_VALID (stream->pts) && stream->first_pts_diff > stream->dts && GST_CLOCK_TIME_IS_VALID (stream->dts))) {
+    if (demux->special_file_flag == FALSE) {
+      if (GST_CLOCK_TIME_IS_VALID (stream->pts))
+        stream->first_pts_diff = stream->pts;
+      else if (GST_CLOCK_TIME_IS_VALID (stream->dts))
+        stream->first_pts_diff = stream->dts;
+    }
+  }
+
+  if (stream->first_dts_diff == GST_CLOCK_TIME_NONE) {
+    if (GST_CLOCK_TIME_IS_VALID (stream->dts))
+      stream->first_dts_diff = stream->dts;
+    else if (GST_CLOCK_TIME_IS_VALID (stream->pts))
+      stream->first_dts_diff = stream->pts;
+
+    if(stream->is_video && GST_CLOCK_TIME_IS_VALID (stream->dts)) {
+      demux->video_diff_dts  = stream->first_dts_diff > 0 ? stream->first_dts_diff :  (GstClockTime)0;
+    }
+  } else if ((stream->first_dts_diff > stream->dts && GST_CLOCK_TIME_IS_VALID (stream->dts))
+    || (!GST_CLOCK_TIME_IS_VALID (stream->dts) && stream->first_dts_diff > stream->pts && GST_CLOCK_TIME_IS_VALID (stream->pts))) {
+    if (demux->special_file_flag == FALSE) {
+      if (GST_CLOCK_TIME_IS_VALID (stream->dts))
+        stream->first_dts_diff = stream->dts;
+      else if (GST_CLOCK_TIME_IS_VALID (stream->pts))
+        stream->first_dts_diff = stream->pts;
+    }
+  }
+
+  if (demux->first_pts_base == GST_CLOCK_TIME_NONE) {
+    demux->first_pts_base = stream->first_pts_diff;
+    GST_DEBUG_OBJECT (stream->pad, "first_pts_base %" GST_TIME_FORMAT, GST_TIME_ARGS (stream->pts));
+  }
+
+  if (stream->first_pts_offset_for_base == -1 && GST_CLOCK_TIME_IS_VALID(demux->first_pts_base)) {
+    stream->first_pts_offset_for_base = (gint64)stream->first_pts_diff - (gint64)demux->first_pts_base;
+    GST_DEBUG_OBJECT (stream->pad, "first pts offset for pts base is %lld", stream->first_pts_offset_for_base);
+  }
+
+  if ((GST_CLOCK_TIME_IS_VALID (stream->pts) && demux->special_file_flag == FALSE) || (GST_CLOCK_TIME_IS_VALID (stream->pts) && demux->special_file_flag == TRUE && stream->pts >= stream->first_pts_diff)) {
+    GST_BUFFER_PTS (buffer) = stream->pts - stream->first_pts_diff;
+    if (ABSDIFF(stream->first_pts_offset_for_base, 0) > PTS_OFFSET_THRESHOLD) {
+      gint64 pts = (gint64)(GST_BUFFER_PTS (buffer)) + stream->first_pts_offset_for_base;
+      if (pts >= 0) {
+        GST_BUFFER_PTS (buffer) = (GstClockTime)pts;
+      } else {
+        GST_BUFFER_PTS (buffer) = 0;
+      }
+    }
+  } else {
+    GST_BUFFER_PTS (buffer) = stream->pts;
+  }
+
+  if ((GST_CLOCK_TIME_IS_VALID (stream->dts) && demux->special_file_flag == FALSE) || (GST_CLOCK_TIME_IS_VALID (stream->dts) && demux->special_file_flag == TRUE && stream->dts >= stream->first_dts_diff))
+    GST_BUFFER_DTS (buffer) = stream->dts - stream->first_dts_diff;
+  else
+    GST_BUFFER_DTS (buffer) = stream->dts;
+
+  return GST_FLOW_OK;
+}
+#endif
+
+#ifdef TCL_PATCH
+static gboolean gstFindH265KeyFrame (TSDemuxStream *stream, const guint8 *data, const gsize size, gint nal_length_size) {
+  guint offset = 0;
+  gint startCodeSize = 0;
+  GstH265NalUnit nalu;
+  GstH265ParserResult res = GST_H265_PARSER_OK;
+  GstH265Parser *parser= gst_h265_parser_new ();
+
+  if (data[0] == 0x00 && data[1] == 0x00 && data[2] == 0x00 && data[3] == 0x01)
+    startCodeSize = 4;
+
+  if (data[0] == 0x00 && data[1] == 0x00 && data[2] == 0x01)
+    startCodeSize = 3;
+
+  if (nal_length_size < 1 || nal_length_size > 4) {
+    nal_length_size = 4;
+  }
+  do {
+    if (startCodeSize == 0) {
+      res = gst_h265_parser_identify_nalu_hevc (parser,data, offset, size, nal_length_size, &nalu);
+    } else {
+      res = gst_h265_parser_identify_nalu (parser, data, offset, size, &nalu);
+    }
+
+    if (res != GST_H265_PARSER_OK && res != GST_H265_PARSER_NO_NAL_END) {
+      break;
+    }
+    GST_ERROR("Found slice nal type %d at offset %d", nalu.type, nalu.sc_offset);
+
+    if (GST_H265_IS_NAL_TYPE_IRAP(nalu.type)) { //(nal_type) >= GST_H265_NAL_SLICE_BLA_W_LP && (nal_type) <= RESERVED_IRAP_NAL_TYPE_MAX
+      g_slice_free (GstH265Parser, parser);
+      return TRUE;
+    }
+
+    offset = nalu.offset + nalu.size;
+    if (startCodeSize == 0 && res == GST_H265_PARSER_NO_NAL_END && nalu.size == 0 && nal_length_size > 1) {
+      offset = 0;
+      res = GST_H265_PARSER_OK;
+      if (nal_length_size == 4)
+        nal_length_size = 3;
+      else if (nal_length_size == 3)
+        nal_length_size = 2;
+      else if (nal_length_size == 2)
+        nal_length_size = 1;
+    }
+  } while (res == GST_H265_PARSER_OK);
+
+  g_slice_free (GstH265Parser, parser);
+  return FALSE;
+}
+#endif
 
 static GstFlowReturn
 gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
@@ -3387,7 +5317,11 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
         base->seek_offset = 0;
       demux->last_seek_offset = base->seek_offset;
       mpegts_packetizer_flush (base->packetizer, FALSE);
-
+#ifdef TCL_PATCH
+      base->packetizer->real_last_time = GST_CLOCK_TIME_NONE;
+      base->packetizer->switch_time_diff = GST_CLOCK_TIME_NONE;
+      base->packetizer->prev_time_diff = GST_CLOCK_TIME_NONE;
+#endif
       /* Reset all streams accordingly */
       for (tmp = demux->program->stream_list; tmp; tmp = tmp->next) {
         TSDemuxStream *cand = tmp->data;
@@ -3407,6 +5341,25 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
       goto beach;
     }
   } else {
+#ifdef TCL_PATCH
+    if(demux->is_seeking) {
+        if(bs->stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC || bs->private_stream_type == GST_MPEGTS_STREAM_TYPE_VIDEO_HEVC || (bs->stream_type == GST_MPEGTS_STREAM_TYPE_PRIVATE_PES_PACKETS && bs->registration_id == DRF_ID_HEVC)) {
+            if (gstFindH265KeyFrame(stream, stream->data, stream->current_size, demux->h265_Nal_length_size)) {
+                GST_ERROR_OBJECT (stream->pad, "Found I frame Success,base->mode =%d",base->mode);
+                stream->seeked_pts = stream->pts;
+                stream->seeked_dts = stream->dts;
+                demux->is_seeking = FALSE;
+            }
+        } else {
+            if (buffer)
+              gst_buffer_unref (buffer);
+            if (buffer_list)
+              gst_buffer_list_unref (buffer_list);
+            res = GST_FLOW_REWINDING;
+            goto beach;
+        }
+    }
+#endif
     if (bs->stream_type == GST_MPEGTS_STREAM_TYPE_PRIVATE_PES_PACKETS &&
         bs->registration_id == DRF_ID_OPUS) {
       buffer_list = parse_opus_access_unit (stream);
@@ -3464,6 +5417,34 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
     }
   }
 
+#ifdef TCL_PATCH
+  if (base->is_hls_live == FALSE && stream->is_subtitle != TRUE) {
+    if (gst_ts_demux_fix_data_timestamp(demux, stream, buffer, buffer_list) == GST_FLOW_CUSTOM_ERROR) {
+      goto beach;
+    }
+  } else {
+    if (GST_CLOCK_TIME_IS_VALID (stream->pts))
+      GST_BUFFER_PTS (buffer) = stream->pts;
+    if (GST_CLOCK_TIME_IS_VALID (stream->dts))
+      GST_BUFFER_DTS (buffer) = stream->dts;
+
+    if (stream->is_subtitle == TRUE && stream->diff_send_flag == FALSE) {
+      if (demux->video_diff_pts != GST_CLOCK_TIME_NONE) {
+        stream->diff_send_flag = TRUE;
+        GstStructure* st       = gst_structure_new_empty("video_diff_pts");
+        GValue diff_pts_value  = { 0, };
+        g_value_init (&diff_pts_value, G_TYPE_UINT64);
+        if(demux->video_diff_pts < 0)
+            demux->video_diff_pts = 0;
+        g_value_set_uint64(&diff_pts_value, (uint64_t)demux->video_diff_pts);
+        gst_structure_set_value(st, "DIFF_PTS", &diff_pts_value);
+        GstEvent* event  = gst_event_new_custom(GST_EVENT_CUSTOM_DOWNSTREAM, st);
+        gst_pad_push_event(stream->pad, event);
+      }
+    }
+  }
+#endif
+
   if (G_UNLIKELY (stream->need_newsegment))
     calculate_and_push_newsegment (demux, stream, target_program);
 
@@ -3481,19 +5462,34 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
       if (stream->discont)
         GST_BUFFER_FLAG_SET (pend->buffer, GST_BUFFER_FLAG_DISCONT);
       stream->discont = FALSE;
-
+#ifdef TCL_PATCH
+      if (base->is_hls == FALSE && stream->is_subtitle != TRUE) {
+        if (gst_ts_demux_fix_data_timestamp(demux, stream, pend->buffer, NULL) == GST_FLOW_OK) {
+          res = gst_pad_push (stream->pad, pend->buffer);
+          stream->nb_out_buffers += 1;
+        }
+      } else {
+          res = gst_pad_push (stream->pad, pend->buffer);
+          stream->nb_out_buffers += 1;
+      }
+#else
       res = gst_pad_push (stream->pad, pend->buffer);
       stream->nb_out_buffers += 1;
+#endif
       g_slice_free (PendingBuffer, pend);
     }
     g_list_free (stream->pending);
     stream->pending = NULL;
   }
-
+#ifdef TCL_PATCH
+  if (GST_CLOCK_TIME_IS_VALID (stream->seeked_dts) &&
+          stream->pts < stream->seeked_dts) {
+#else
   if ((GST_CLOCK_TIME_IS_VALID (stream->seeked_pts)
           && stream->pts < stream->seeked_pts) ||
       (GST_CLOCK_TIME_IS_VALID (stream->seeked_dts) &&
           stream->pts < stream->seeked_dts)) {
+#endif
     GST_INFO_OBJECT (stream->pad,
         "Droping with PTS: %" GST_TIME_FORMAT " DTS: %" GST_TIME_FORMAT
         " after seeking as other stream needed to be seeked further"
@@ -3514,11 +5510,14 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
   if (buffer_list)
     buffer = gst_buffer_list_get (buffer_list, 0);
 
+#ifdef TCL_PATCH
+#else
   if (GST_CLOCK_TIME_IS_VALID (stream->pts))
     GST_BUFFER_PTS (buffer) = GST_BUFFER_DTS (buffer) = stream->pts;
   /* DTS = PTS by default, we override it if there's a real DTS */
   if (GST_CLOCK_TIME_IS_VALID (stream->dts))
     GST_BUFFER_DTS (buffer) = stream->dts;
+#endif
 
   if (stream->discont)
     GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DISCONT);
@@ -3540,8 +5539,242 @@ gst_ts_demux_push_pending_data (GstTSDemux * demux, TSDemuxStream * stream,
       base->out_segment.position = stream->pts;
   }
 
+#ifdef TCL_PATCH
+  /*for LPCM, not push data if bitrate is too large*/
+  if (bs->stream_type == ST_BD_AUDIO_LPCM) {
+    if(stream->unsupport == FALSE) {
+      GstMapInfo mapinfo;
+      gchar *p_buf      = NULL;
+      gchar channel_layout = 0;
+      gint samplerate = 0;
+      gchar channel_num = 0;
+      const gchar channels[16] = {0, 1, 0, 2, 3, 3, 4, 4, 5, 6, 7, 8, 0, 0, 0, 0};
+      const gchar bits_per_samples[4] = { 0, 16, 20, 24 };
+      gint bit_rate = 0;
+      gchar bits_per_coded_sample = 0;
+
+      gst_buffer_map(buffer, &mapinfo, GST_MAP_READ);
+      p_buf   = (gchar*) (mapinfo.data);
+      channel_layout = p_buf[2] >> 4;
+
+      switch (p_buf[2] & 0x0f)
+      {
+        case 1:
+          samplerate = 48000;
+          break;
+        case 4:
+          samplerate = 96000;
+          break;
+        case 5:
+          samplerate = 192000;
+          break;
+        default:
+          samplerate = 0;
+          break;
+      }
+
+      channel_num = channels[(gint)channel_layout];
+      bits_per_coded_sample = bits_per_samples[p_buf[3] >> 6];
+      bit_rate = channel_num * samplerate * bits_per_coded_sample;
+      //modify by yan139.zhang for set channels for x-private-ts-lpcm.[LINTHY-35850]
+      if (stream->is_set_channels == FALSE) {
+        GstCaps *sink_caps = gst_caps_new_simple ("audio/x-private-ts-lpcm", "channels", G_TYPE_INT, channel_num, NULL);
+        if (sink_caps) {
+          gst_pad_set_caps (stream->pad, sink_caps);
+          gst_caps_unref (sink_caps);
+          stream->is_set_channels == TRUE;
+        }
+      }
+
+      gst_buffer_unmap (buffer, &mapinfo);
+
+      if(bit_rate >= 4608000) {
+        //g_print("[%s:%d]samplerate = %d, channels = %d, bits_per_coded_sample = %d, bit_rate = %d\n", __FUNCTION__, __LINE__,samplerate, channel_num, bits_per_coded_sample, bit_rate);
+        GstCaps *caps = gst_caps_new_simple ("audio/x-private-ts-lpcm", "unsupported", G_TYPE_UINT, 1, NULL);
+        gst_pad_set_caps (stream->pad, caps);
+
+        if(caps) {
+          gst_caps_unref (caps);
+        }
+        stream->unsupport = TRUE;
+      }
+
+    } else {
+        GstBuffer *buf = NULL;
+        GstMapInfo map;
+        guint8 data[32];
+        int data_size = sizeof(data);
+        memset(data,1,sizeof(data));
+
+        buf = gst_buffer_new_allocate (NULL, data_size, NULL);
+        gst_buffer_map (buf, &map, GST_MAP_WRITE);
+        memcpy(map.data, data, data_size);
+        map.size = data_size;
+        gst_buffer_unmap (buf, &map);
+        GST_BUFFER_PTS(buf) = GST_BUFFER_PTS(buffer);
+
+        if (buffer) {
+          gst_buffer_unref (buffer);
+        }
+        if (buffer_list) {
+          gst_buffer_list_unref (buffer_list);
+        }
+        buffer = buf;
+        GST_BUFFER_PTS(buffer) = GST_BUFFER_PTS(buf);
+        //goto beach;
+    }
+  }
+  if (stream->is_send_caps == FALSE && bs->stream_type == ST_PRIVATE_EA) {
+      GstMapInfo mapinfo;
+      guint8 *data;
+      gint size;
+      guint16 width = 0, height = 0;
+      gst_buffer_map(buffer, &mapinfo, GST_MAP_READ);
+      data = mapinfo.data;
+      size = mapinfo.size;
+      guint32 startcode1 = GST_READ_UINT32_BE (data);
+      guint32 startcode2 = GST_READ_UINT32_BE (data+22);
+      if (startcode1 == 0x0000010f && startcode2 == 0x0000010e && size >= 33) {
+        GstBuffer *extra = NULL;
+        extra = gst_buffer_new_and_alloc (33);
+        gst_buffer_fill (extra, 0, data, 33);
+        GstBitReader br;
+        gst_bit_reader_init (&br, data+6, 3);
+        gst_bit_reader_get_bits_uint16 (&br, &width, 12);
+        gst_bit_reader_get_bits_uint16 (&br, &height, 12);
+        if (width == 0 || height == 0) {
+          width = VC1_DEFAULT_WIDTH;
+          height = VC1_DEFAULT_HEIGHT;
+        } else {
+          width = (width + 1) << 1;
+          height = (height + 1) << 1;
+        }
+        GST_DEBUG_OBJECT(demux, "width = %u, height = %u", width, height);
+        GstCaps *caps = gst_caps_new_simple ("video/x-wmv", "wmvversion", G_TYPE_INT, 3, "format", G_TYPE_STRING, "WVC1",
+            "width", G_TYPE_INT, width, "height", G_TYPE_INT, height, "codec_data", GST_TYPE_BUFFER, extra, NULL);
+        if (demux->special_file_flag == TRUE)
+          gst_caps_set_simple (caps, "ignore_invalid_pts", G_TYPE_BOOLEAN, TRUE, NULL);
+        gst_pad_set_caps (stream->pad, caps);
+        stream->is_send_caps = TRUE;
+        if (extra)
+          gst_buffer_unref (extra);
+        if(caps) {
+          gst_caps_unref (caps);
+        }
+      }
+      gst_buffer_unmap (buffer, &mapinfo);
+  }
+  /*for a sudden bigger buffer pts */
+  if (base->is_hls == FALSE && stream->is_audio == TRUE) {
+    GstClockTime now_push_pts = GST_BUFFER_PTS(buffer);
+
+    if(stream->pre_push_pts == 0) {
+      stream->pre_push_pts = now_push_pts;
+    }
+
+    if((now_push_pts > stream->pre_push_pts) && (now_push_pts - stream->pre_push_pts >= 30000000000)) {
+      if (buffer) {
+        gst_buffer_unref (buffer);
+      }
+      if (buffer_list) {
+        gst_buffer_list_unref (buffer_list);
+      }
+
+      //g_print("[%s:%d]now_push_pts = %lld, stream->pre_push_pts = %lld\n", __FUNCTION__, __LINE__,now_push_pts, stream->pre_push_pts);
+      goto beach;
+    } else {
+      stream->pre_push_pts = now_push_pts;
+    }
+  } else if (base->is_hls == FALSE && stream->is_video == TRUE){
+    GstClockTime now_push_pts = GST_BUFFER_PTS(buffer);
+    if(stream->pre_push_pts == 0) {
+      stream->pre_push_pts = now_push_pts;
+    }
+
+    if(GST_CLOCK_TIME_IS_VALID(now_push_pts) && GST_CLOCK_TIME_IS_VALID(stream->pre_push_pts) && (now_push_pts > stream->pre_push_pts) && (now_push_pts - stream->pre_push_pts >= 30000000000)) {
+      GST_BUFFER_PTS(buffer) = stream->pre_push_pts;
+      GST_BUFFER_DTS(buffer) = stream->pre_push_pts;
+      goto beach;
+    } else {
+      stream->pre_push_pts = now_push_pts;
+    }
+  }
+#endif
+
+#ifdef TCL_PATCH
   if (buffer) {
-    res = gst_pad_push (stream->pad, buffer);
+    if (!demux->is_seeking) {
+        if (bs->stream_type == ST_PRIVATE_EA && demux->special_file_flag == TRUE) {
+            GstMapInfo mapinfo;
+            guint8 *data;
+            gint size, current_frame_size, offset, last_frame_offset;
+            gboolean first_frame = TRUE;
+            gboolean clip_frame = FALSE;
+            gst_buffer_map(buffer, &mapinfo, GST_MAP_READ);
+            data = mapinfo.data;
+            size = mapinfo.size;
+            offset = 0;
+            last_frame_offset = 0;
+            guint32 startcode1 = 0;
+            while (offset < size - 4) {
+                startcode1 = GST_READ_UINT32_BE (data + offset);
+                if (startcode1 == 0x0000010d) {
+                    if (first_frame) {
+                        first_frame = FALSE;
+                        offset++;
+                        continue;
+                    }
+                    current_frame_size = offset - last_frame_offset;
+                    GstBuffer *frame = NULL;
+                    frame = gst_buffer_new_and_alloc (current_frame_size);
+                    gst_buffer_fill (frame, 0, data + last_frame_offset, current_frame_size);
+                    if (!clip_frame) {
+                        GST_BUFFER_PTS(frame) = GST_BUFFER_PTS(buffer);
+                        GST_BUFFER_DTS(frame) = GST_BUFFER_DTS(buffer);
+                        GST_BUFFER_DURATION(frame) = GST_BUFFER_DURATION(buffer);
+                    } else {
+                        GST_BUFFER_PTS(frame) = -1;
+                        GST_BUFFER_DTS(frame) = -1;
+                    }
+                    res = gst_pad_push(stream->pad, frame);
+                    last_frame_offset = offset;
+                    offset++;
+                    clip_frame = TRUE;
+                    continue;
+                }
+                offset++;
+                if (offset >= size - 4) {
+                    if (!clip_frame) {
+                        res = gst_pad_push(stream->pad, buffer);
+                    }
+                    else {
+                        GstBuffer *frame = NULL;
+                        current_frame_size = size - last_frame_offset;
+                        frame = gst_buffer_new_and_alloc (current_frame_size);
+                        gst_buffer_fill (frame, 0, data + last_frame_offset, size - last_frame_offset);
+                        GST_BUFFER_PTS(frame) = -1;
+                        GST_BUFFER_DTS(frame) = -1;
+                        res = gst_pad_push(stream->pad, frame);
+                        last_frame_offset = offset;
+                    }
+                }
+            }
+            gst_buffer_unmap (buffer, &mapinfo);
+            if (clip_frame) {
+                gst_buffer_unref(buffer);
+            }
+
+        }else {
+            res = gst_pad_push(stream->pad, buffer);
+        }
+    } else {
+        gst_buffer_unref(buffer);
+    }
+#else
+    if (buffer) {
+      res = gst_pad_push (stream->pad, buffer);
+#endif
+
     /* Record that a buffer was pushed */
     stream->nb_out_buffers += 1;
   } else {
@@ -3597,6 +5830,26 @@ beach:
   return res;
 }
 
+#ifdef TCL_PATCH
+static void
+gst_ts_demux_get_video_buffered_time(MpegTSBase * base)
+{
+  GstTSDemux *demux = GST_TS_DEMUX_CAST (base);
+
+  if (base->sinkpad) {
+    GstQuery *query;
+    query = gst_query_new_position (GST_FORMAT_PERCENT);
+    gst_pad_peer_query (base->sinkpad, query);
+    gint64 percent_int;
+    gst_query_parse_position (query, NULL, &percent_int);
+    double percent_double = (double)percent_int/(double)GST_FORMAT_PERCENT_MAX;
+    gst_query_unref (query);
+    GST_INFO("percent of download(%lld) is %f", percent_int, percent_double);
+    demux->latest_pushed_buffer_pts = (guint64) percent_int;
+  }
+}
+#endif
+
 static GstFlowReturn
 gst_ts_demux_handle_packet (GstTSDemux * demux, TSDemuxStream * stream,
     MpegTSPacketizerPacket * packet, GstMpegtsSection * section)
@@ -3702,3 +5955,45 @@ gst_ts_demux_push (MpegTSBase * base, MpegTSPacketizerPacket * packet,
   }
   return res;
 }
+
+#ifdef TCL_PATCH
+static GstStateChangeReturn
+gst_ts_demux_change_state (GstElement * element, GstStateChange transition)
+{
+  GstTSDemux *tsdemux = GST_TS_DEMUX_CAST (element);
+  GstStateChangeReturn result = GST_STATE_CHANGE_FAILURE;
+
+  result = GST_ELEMENT_CLASS (parent_class)->change_state (element, transition);
+
+  switch (transition) {
+    case GST_STATE_CHANGE_PAUSED_TO_PLAYING:
+    {
+#if 0
+      if (tsdemux->program) {
+        GList* tmp = NULL;
+        for (tmp = tsdemux->program->stream_list; tmp; tmp = tmp->next) {
+          TSDemuxStream* stream = (TSDemuxStream*)tmp->data;
+          if (stream && stream->pad) {
+            GstCaps* caps    = gst_pad_get_current_caps(stream->pad);
+            const GstStructure* st = gst_caps_get_structure(caps, 0);
+            gint is_subtitle = 0;
+            gst_structure_get_int(st, "is_subtitle", &is_subtitle);
+            if (is_subtitle  != 0) {
+              const char* id   = gst_structure_get_string(st, "id_for_texttrack");
+              const char* lang = gst_structure_get_string(st, "language_for_texttrack");
+              guint pid = 0;
+              gst_structure_get_uint(st, "pid_for_texttrack",&pid);
+              gst_ts_demux_send_texttrack_for_subtitle(tsdemux, id, lang, pid);
+            }
+            gst_caps_unref(caps);
+          }
+        }
+      }
+#endif
+    } break;
+    default:
+      break;
+  }
+  return result;
+}
+#endif
diff --git a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.h b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.h
index 76be6bb2f3..80fc6dde7f 100644
--- a/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.h
+++ b/subprojects/gst-plugins-bad/gst/mpegtsdemux/tsdemux.h
@@ -46,6 +46,112 @@ typedef enum
   GST_MPEGTSDEMUX_JPEG2000_COLORSPEC_SMPTE2084
 } GstMpegTsDemuxJpeg2000ColorSpec;
 
+#ifdef TCL_PATCH
+
+#define MAX_STREAMS_NUM (30)
+
+#define STEP_LENGTH 600*188  // searching backwards by chunks of 300 MPEG-ts packets
+#define SEEK_THRESHOLD 1000 *1000 *1000
+
+#define UNIMP_STRING_LEN_4          4
+#define UNIMP_STRING_LEN_8          8
+#define UNIMP_STRING_LEN_10         10
+#define UNIMP_STRING_LEN_16         16
+#define UNIMP_STRING_LEN_32         32
+#define UNIMP_STRING_LEN_128        128
+#define UNIMP_STRING_LEN_256        256
+#define UNIMP_STRING_LEN_512        512
+#define UNIMP_STRING_LEN_1024       1024
+
+#define MAX_VIDEO_TRACK_NUM         8
+#define MAX_AUDIO_TRACK_NUM         32
+#define MAX_SUBTITLE_TRACK_NUM      8
+
+typedef struct
+{
+  int32_t pid;
+  int8_t encoding[UNIMP_STRING_LEN_32];
+  int8_t mime[UNIMP_STRING_LEN_32];
+  int32_t componentTag;
+  int32_t encrypted;
+  int8_t language[UNIMP_STRING_LEN_4];
+  int32_t audioDescription;
+  int32_t selectionPriority;
+  int32_t audioChannels;
+  int32_t preselectionId[UNIMP_STRING_LEN_10];
+  int32_t preselectionTag[UNIMP_STRING_LEN_10];
+  int8_t  preselectionLang[UNIMP_STRING_LEN_10][UNIMP_STRING_LEN_4];
+  int32_t preselectionCount;
+  uint8_t name[UNIMP_STRING_LEN_128];
+  uint32_t bitRate;
+  int32_t sampleRate;
+} media_audio_info_node_s;
+
+typedef struct
+{
+  int32_t audioCount;
+  media_audio_info_node_s audioInfoNodes[MAX_AUDIO_TRACK_NUM];
+} media_audio_info_s;
+
+typedef struct
+{
+  int32_t programNumber;
+  media_audio_info_s *audioInfo;
+} media_audio_extend_info_s;
+
+typedef struct
+{
+  int32_t programCount;
+  media_audio_extend_info_s *audioExtendInfos[MAX_AUDIO_TRACK_NUM];
+} media_audio_info_list_s;
+
+typedef struct
+{
+  int32_t pid;
+  int8_t encoding[UNIMP_STRING_LEN_32];
+  int8_t mime[UNIMP_STRING_LEN_32];
+  int32_t componentTag;
+  int32_t encrypted;
+  float aspectRatio;
+  int32_t videoDescription;
+  int32_t frames;
+  int32_t time;
+  uint8_t name[UNIMP_STRING_LEN_128];
+  uint8_t language[UNIMP_STRING_LEN_4];
+  int32_t bitRate;
+} media_video_info_node_s;
+
+typedef struct
+{
+  int32_t videoCount;
+  u_int32_t maxWidth;
+  u_int32_t maxHeight;
+  u_int32_t isAdaptive;
+  media_video_info_node_s videoNodes[MAX_VIDEO_TRACK_NUM];
+} media_video_info_s;
+
+typedef enum _TextTrackKind_E {
+  KindSubtitles,
+  KindCaptions,
+  KindDescriptions,
+  KindChapters,
+  KindMetadata,
+  KindNone
+} TextTrackKind_E;
+
+#if 0
+typedef struct {
+  int32_t   texttrack_id;
+  char      id[16];
+  u_int8_t  kind;
+  char      label[16];
+  char      language[8];
+  char      mode[16];
+  char      inBandMetadataTrackDispatchType[512];
+} media_text_track_t;
+#endif
+
+#endif
 
 G_BEGIN_DECLS
 #define GST_TYPE_TS_DEMUX \
@@ -110,6 +216,38 @@ struct _GstTSDemux
 
   /* This is to protect demux->segment_event */
   GMutex lock;
+
+#ifdef TCL_PATCH
+  gint program_numbers[32];
+  guint program_count;
+
+  /*total audio info collect*/
+  media_audio_info_s * audio_info;
+  media_audio_info_list_s audio_info_list;
+
+  /*total video info collect*/
+  media_video_info_s * video_info;
+
+  guint64 latest_pushed_buffer_pts;
+  guint64  pts_to_offset;
+  gint64   seek_position;
+  gboolean program_started;
+  GstClockTime  video_diff_pts;
+  GstClockTime  video_diff_dts;
+  guint    subtitle_idx;
+
+  gboolean is_seeking;
+  gint32 is_invalid_pcr;
+  guint h265_Nal_length_size;
+  gint64 file_size;
+  gint32 is_bad_pts;
+
+  gboolean special_file_flag;
+  gboolean use_iso_src;
+
+  GstClockTime first_pts_base;
+#endif
+
 };
 
 struct _GstTSDemuxClass
diff --git a/subprojects/gst-plugins-bad/gst/rawparse/plugin.c b/subprojects/gst-plugins-bad/gst/rawparse/plugin.c
index 0487b502a8..3c8869d00b 100644
--- a/subprojects/gst-plugins-bad/gst/rawparse/plugin.c
+++ b/subprojects/gst-plugins-bad/gst/rawparse/plugin.c
@@ -9,11 +9,16 @@
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
+#ifdef TCL_PATCH
+  gboolean ret = TRUE;
+#else
   gboolean ret = FALSE;
 
   ret |= GST_ELEMENT_REGISTER (videoparse, plugin);
   ret |= GST_ELEMENT_REGISTER (audioparse, plugin);
 
+#endif
+
   return ret;
 }
 
diff --git a/subprojects/gst-plugins-bad/gst/videofilters/gstvideofiltersbad.c b/subprojects/gst-plugins-bad/gst/videofilters/gstvideofiltersbad.c
index 84c50c2962..ad23cbd539 100644
--- a/subprojects/gst-plugins-bad/gst/videofilters/gstvideofiltersbad.c
+++ b/subprojects/gst-plugins-bad/gst/videofilters/gstvideofiltersbad.c
@@ -31,12 +31,15 @@
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
+#ifdef TCL_PATCH
+  gboolean ret = TRUE;
+#else
   gboolean ret = FALSE;
 
   ret |= GST_ELEMENT_REGISTER (scenechange, plugin);
   ret |= GST_ELEMENT_REGISTER (zebrastripe, plugin);
   ret |= GST_ELEMENT_REGISTER (videodiff, plugin);
-
+#endif
   return ret;
 }
 
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstav1parse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gstav1parse.c
index f127856f37..8fe1da2d78 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstav1parse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstav1parse.c
@@ -131,14 +131,23 @@ struct _GstAV1Parse
 static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-av1;video/x-av1-tcl"));
+#else
     GST_STATIC_CAPS ("video/x-av1"));
-
+#endif
 static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
     GST_PAD_SRC,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-av1-tcl, parsed = (boolean) true, "
+        "stream-format=(string) { obu-stream, annexb }, "
+        "alignment=(string) { obu, tu, frame }"));
+#else
     GST_STATIC_CAPS ("video/x-av1, parsed = (boolean) true, "
         "stream-format=(string) { obu-stream, annexb }, "
         "alignment=(string) { obu, tu, frame }"));
+#endif
 
 #define parent_class gst_av1_parse_parent_class
 G_DEFINE_TYPE (GstAV1Parse, gst_av1_parse, GST_TYPE_BASE_PARSE);
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
index 11581b09e5..b44c8438aa 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth264parse.c
@@ -88,14 +88,24 @@ enum
 static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-h264-tcl"));
+#else
     GST_STATIC_CAPS ("video/x-h264"));
+#endif
 
 static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
     GST_PAD_SRC,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-h264-tcl, parsed = (boolean) true, "
+        "stream-format=(string) { avc, avc3, byte-stream }, "
+        "alignment=(string) { au, nal }"));
+#else
     GST_STATIC_CAPS ("video/x-h264, parsed = (boolean) true, "
         "stream-format=(string) { avc, avc3, byte-stream }, "
         "alignment=(string) { au, nal }"));
+#endif
 
 #define parent_class gst_h264_parse_parent_class
 G_DEFINE_TYPE (GstH264Parse, gst_h264_parse, GST_TYPE_BASE_PARSE);
@@ -527,6 +537,12 @@ gst_h264_parser_store_nal (GstH264Parse * h264parse, guint id,
   }
 
   buf = gst_buffer_new_allocate (NULL, size, NULL);
+#ifdef TCL_PATCH
+  if (buf == NULL) {
+    GST_DEBUG_OBJECT (h264parse, "Failed to allocate buffer");
+    return;
+  }
+#endif
   gst_buffer_fill (buf, 0, nalu->data + nalu->offset, size);
 
   /* Indicate that buffer contain a header needed for decoding */
@@ -1696,6 +1712,7 @@ gst_h264_parse_get_par (GstH264Parse * h264parse, gint * num, gint * den)
   }
 }
 
+#ifndef TCL_PATCH
 static GstCaps *
 get_compatible_profile_caps (GstH264SPS * sps)
 {
@@ -1819,7 +1836,11 @@ get_compatible_profile_caps (GstH264SPS * sps)
 
   if (profiles) {
     GValue value = G_VALUE_INIT;
+#ifdef TCL_PATCH
+    caps = gst_caps_new_empty_simple ("video/x-h264-tcl");
+#else
     caps = gst_caps_new_empty_simple ("video/x-h264");
+#endif
     for (i = 0; profiles[i]; i++) {
       g_value_init (&value, G_TYPE_STRING);
       g_value_set_string (&value, profiles[i]);
@@ -1842,7 +1863,11 @@ ensure_caps_profile (GstH264Parse * h264parse, GstCaps * caps, GstH264SPS * sps)
 
   peer_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (h264parse));
   if (!peer_caps || !gst_caps_can_intersect (caps, peer_caps)) {
+#ifdef TCL_PATCH
+    GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h264-tcl");
+#else
     GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h264");
+#endif
 
     if (peer_caps)
       gst_caps_unref (peer_caps);
@@ -1883,6 +1908,7 @@ ensure_caps_profile (GstH264Parse * h264parse, GstCaps * caps, GstH264SPS * sps)
   if (peer_caps)
     gst_caps_unref (peer_caps);
 }
+#endif
 
 static const gchar *
 digit_to_string (guint digit)
@@ -2042,7 +2068,11 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
 
   /* carry over input caps as much as possible; override with our own stuff */
   if (!sink_caps)
+#ifdef TCL_PATCH
+    sink_caps = gst_caps_new_empty_simple ("video/x-h264-tcl");
+#else
     sink_caps = gst_caps_new_empty_simple ("video/x-h264");
+#endif
   else
     s = gst_caps_get_structure (sink_caps, 0);
 
@@ -2208,6 +2238,26 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
             GST_FLAG_SET_MASK_EXACT, NULL);
       }
 
+#if 0 // def TCL_PATCH
+      if (par_n != 0 && par_d != 0 && width != 0 && height != 0)
+      {
+        float current_aspect = (float)width/height;
+        float aspect_ration = (float)(par_n*width)/(par_d*height);
+        GST_DEBUG_OBJECT (h264parse, "video current_aspect:%f, aspect_ration:%f",
+                      current_aspect, aspect_ration);
+        if (current_aspect > aspect_ration)
+        {
+            width = (int)(height*aspect_ration + 0.5f);
+        }
+        else if (current_aspect < aspect_ration)
+        {
+            height = (int)(width/aspect_ration + 0.5f);
+        }
+      }
+
+      GST_DEBUG_OBJECT (h264parse, "video width:%d, height:%d", width, height);
+#endif
+
       gst_caps_set_simple (caps, "width", G_TYPE_INT, width,
           "height", G_TYPE_INT, height, NULL);
 
@@ -2295,8 +2345,10 @@ gst_h264_parse_update_src_caps (GstH264Parse * h264parse, GstCaps * caps)
       if (level != NULL)
         gst_caps_set_simple (caps, "level", G_TYPE_STRING, level, NULL);
 
+#ifndef TCL_PATCH
       /* relax the profile constraint to find a suitable decoder */
       ensure_caps_profile (h264parse, caps, sps);
+#endif
     }
 
     if (s)
@@ -3517,7 +3569,11 @@ gst_h264_parse_set_caps (GstBaseParse * parse, GstCaps * caps)
     GstCaps *in_caps;
 
     /* prefer input type determined above */
+#ifdef TCL_PATCH
+    in_caps = gst_caps_new_simple ("video/x-h264-tcl",
+#else
     in_caps = gst_caps_new_simple ("video/x-h264",
+#endif
         "parsed", G_TYPE_BOOLEAN, TRUE,
         "stream-format", G_TYPE_STRING,
         gst_h264_parse_get_string (h264parse, TRUE, format),
@@ -3698,11 +3754,19 @@ gst_h264_parse_event (GstBaseParse * parse, GstEvent * event)
       const GstSegment *segment;
 
       gst_event_parse_segment (event, &segment);
+#ifdef TCL_PATCH
+      /* don't try to mess with more subtle cases (e.g. seek) */
+     if (segment->format == GST_FORMAT_TIME &&
+         (/*segment->start != 0 ||*/ segment->rate != 1.0
+             || segment->applied_rate != 1.0))
+       h264parse->do_ts = FALSE;
+#else
       /* don't try to mess with more subtle cases (e.g. seek) */
       if (segment->format == GST_FORMAT_TIME &&
           (segment->start != 0 || segment->rate != 1.0
               || segment->applied_rate != 1.0))
         h264parse->do_ts = FALSE;
+#endif
 
       if (segment->flags & GST_SEEK_FLAG_TRICKMODE_FORWARD_PREDICTED) {
         GST_DEBUG_OBJECT (h264parse, "Will discard bidirectional frames");
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
index abed37e69e..3f53c96776 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse.c
@@ -81,14 +81,25 @@ enum
 static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
     GST_PAD_SINK,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-h265-tcl"));
+#else
     GST_STATIC_CAPS ("video/x-h265"));
+#endif
 
 static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
     GST_PAD_SRC,
     GST_PAD_ALWAYS,
+#ifdef TCL_PATCH
+    GST_STATIC_CAPS ("video/x-h265-tcl, parsed = (boolean) true, "
+        "stream-format=(string) { hvc1, hev1, byte-stream }, "
+        "alignment=(string) { au, nal }"));
+#else
     GST_STATIC_CAPS ("video/x-h265, parsed = (boolean) true, "
         "stream-format=(string) { hvc1, hev1, byte-stream }, "
         "alignment=(string) { au, nal }"));
+#endif
+
 
 #define parent_class gst_h265_parse_parent_class
 G_DEFINE_TYPE (GstH265Parse, gst_h265_parse, GST_TYPE_BASE_PARSE);
@@ -1372,6 +1383,26 @@ end:
 
   gst_h265_parse_parse_frame (parse, frame);
 
+#ifdef TCL_PATCH
+  GstClockTime pts = GST_CLOCK_TIME_NONE;
+  GstClockTime dts = GST_CLOCK_TIME_NONE;
+  if (framesize > 4 && size > 4) {
+    gsize scan_szie = 0;
+    if (*(data) == 0x00 && *(data+1) == 0x00 && *(data+2) == 0x00 && *(data+3) == 0x01) {
+      scan_szie = 4;
+    } else if (*(data) == 0x00 && *(data+1) == 0x00 && *(data+2) == 0x01) {
+      scan_szie = 3;
+    }
+    if (scan_szie > 0) {
+      gst_base_parse_get_ts_at_offset(parse, scan_szie, &pts, &dts);
+      if (GST_CLOCK_TIME_IS_VALID (pts) && GST_BUFFER_PTS (frame->buffer) != pts
+        && GST_CLOCK_TIME_IS_VALID (dts) && GST_BUFFER_DTS (frame->buffer) != dts) {
+        gst_base_parse_set_ts_at_offset (parse, scan_szie);
+      }
+    }
+  }
+#endif
+
   return gst_base_parse_finish_frame (parse, frame, framesize);
 
 more:
@@ -1961,8 +1992,11 @@ get_compatible_profile_caps (GstH265SPS * sps, GstH265Profile profile)
   if (profiles) {
     GValue value = G_VALUE_INIT;
     const gchar *profile_str;
+#ifdef TCL_PATCH
+    caps = gst_caps_new_empty_simple ("video/x-h265-tcl");
+#else
     caps = gst_caps_new_empty_simple ("video/x-h265");
-
+#endif
     for (i = GST_H265_PROFILE_MAIN; i < GST_H265_PROFILE_MAX; i++) {
       if ((profiles & profile_to_flag (i)) == profile_to_flag (i)) {
         profile_str = gst_h265_profile_to_string (i);
@@ -2015,8 +2049,11 @@ ensure_caps_profile (GstH265Parse * h265parse, GstCaps * caps, GstH265SPS * sps,
 
   peer_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (h265parse));
   if (!peer_caps || !gst_caps_can_intersect (caps, peer_caps)) {
+#ifdef TCL_PATCH
+    GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h265-tcl");
+#else
     GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h265");
-
+#endif
     if (peer_caps)
       gst_caps_unref (peer_caps);
     peer_caps =
@@ -2105,11 +2142,15 @@ gst_h265_parse_update_src_caps (GstH265Parse * h265parse, GstCaps * caps)
     sink_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (h265parse));
 
   /* carry over input caps as much as possible; override with our own stuff */
-  if (!sink_caps)
+  if (!sink_caps) {
+#ifdef TCL_PATCH
+    sink_caps = gst_caps_new_empty_simple ("video/x-h265-tcl");
+#else
     sink_caps = gst_caps_new_empty_simple ("video/x-h265");
-  else
+#endif
+  } else {
     s = gst_caps_get_structure (sink_caps, 0);
-
+  }
   sps = h265parse->nalparser->last_sps;
   GST_DEBUG_OBJECT (h265parse, "sps: %p", sps);
 
@@ -3158,7 +3199,11 @@ gst_h265_parse_set_caps (GstBaseParse * parse, GstCaps * caps)
     GstCaps *in_caps;
 
     /* prefer input type determined above */
+#ifdef TCL_PATCH
+    in_caps = gst_caps_new_simple ("video/x-h265-tcl",
+#else
     in_caps = gst_caps_new_simple ("video/x-h265",
+#endif
         "parsed", G_TYPE_BOOLEAN, TRUE,
         "stream-format", G_TYPE_STRING,
         gst_h265_parse_get_string (h265parse, TRUE, format),
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.c b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.c
new file mode 100644
index 0000000000..ef143aa9dc
--- /dev/null
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.c
@@ -0,0 +1,3433 @@
+/* GStreamer H.265 Parser
+ * Copyright (C) 2013 Intel Corporation
+ *  Contact:Sreerenj Balachandran <sreerenj.balachandran@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifdef HAVE_CONFIG_H
+#  include "config.h"
+#endif
+
+#include <gst/base/base.h>
+#include <gst/pbutils/pbutils.h>
+#include "gsth265parse2.h"
+
+#include <string.h>
+
+GST_DEBUG_CATEGORY (h265_parse2_debug);
+#define GST_CAT_DEFAULT h265_parse2_debug
+
+#define DEFAULT_CONFIG_INTERVAL      (0)
+
+enum
+{
+  PROP_0,
+  PROP_CONFIG_INTERVAL
+};
+
+enum
+{
+  GST_H265_PARSE_FORMAT_NONE,
+  GST_H265_PARSE_FORMAT_HVC1,
+  GST_H265_PARSE_FORMAT_HEV1,
+  GST_H265_PARSE_FORMAT_BYTE
+};
+
+enum
+{
+  GST_H265_PARSE_ALIGN_NONE = 0,
+  GST_H265_PARSE_ALIGN_NAL,
+  GST_H265_PARSE_ALIGN_AU
+};
+
+enum
+{
+  GST_H265_PARSE_STATE_GOT_SPS = 1 << 0,
+  GST_H265_PARSE_STATE_GOT_PPS = 1 << 1,
+  GST_H265_PARSE_STATE_GOT_SLICE = 1 << 2,
+
+  GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS = (GST_H265_PARSE_STATE_GOT_SPS |
+      GST_H265_PARSE_STATE_GOT_PPS),
+  GST_H265_PARSE_STATE_VALID_PICTURE =
+      (GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS |
+      GST_H265_PARSE_STATE_GOT_SLICE)
+};
+
+enum
+{
+  GST_H265_PARSE_SEI_EXPIRED = 0,
+  GST_H265_PARSE_SEI_ACTIVE = 1,
+  GST_H265_PARSE_SEI_PARSED = 2,
+};
+
+#define GST_H265_PARSE_STATE_VALID(parse, expected_state) \
+  (((parse)->state & (expected_state)) == (expected_state))
+
+static GstStaticPadTemplate sinktemplate = GST_STATIC_PAD_TEMPLATE ("sink",
+    GST_PAD_SINK,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-h265-soft"));
+
+static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("src",
+    GST_PAD_SRC,
+    GST_PAD_ALWAYS,
+    GST_STATIC_CAPS ("video/x-h265-soft, parsed = (boolean) true, "
+        "stream-format=(string) { hvc1, hev1, byte-stream }, "
+        "alignment=(string) { au, nal }"));
+
+void
+_do_init (GstPlugin * plugin)
+{
+  static gsize res = FALSE;
+
+  if (g_once_init_enter (&res)) {
+    GST_DEBUG_CATEGORY_INIT (h265_parse2_debug, "h265parse2", 0,
+        "h265parse2 caps video/h265-soft");
+    g_once_init_leave (&res, TRUE);
+  }
+}
+
+#define parent_class gst_h265_parse2_parent_class
+G_DEFINE_TYPE (GstH265Parse2, gst_h265_parse2, GST_TYPE_BASE_PARSE);
+GST_ELEMENT_REGISTER_DEFINE_WITH_CODE (h265parse2, "h265parse2",
+    GST_RANK_SECONDARY, GST_TYPE_H265_PARSE2,
+    videoparsers_element_init (plugin));
+
+static void gst_h265_parse2_finalize (GObject * object);
+
+static gboolean gst_h265_parse2_start (GstBaseParse * parse);
+static gboolean gst_h265_parse2_stop (GstBaseParse * parse);
+static GstFlowReturn gst_h265_parse2_handle_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize);
+static GstFlowReturn gst_h265_parse2_parse_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame);
+static GstFlowReturn gst_h265_parse2_pre_push_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame);
+
+static void gst_h265_parse2_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec);
+static void gst_h265_parse2_get_property (GObject * object, guint prop_id,
+    GValue * value, GParamSpec * pspec);
+
+static gboolean gst_h265_parse2_set_caps (GstBaseParse * parse, GstCaps * caps);
+static GstCaps *gst_h265_parse2_get_caps (GstBaseParse * parse,
+    GstCaps * filter);
+static gboolean gst_h265_parse2_event (GstBaseParse * parse, GstEvent * event);
+static gboolean gst_h265_parse2_src_event (GstBaseParse * parse,
+    GstEvent * event);
+static void
+gst_h265_parse2_process_sei_user_data (GstH265Parse2 * h265parse,
+    GstH265RegisteredUserData * rud);
+
+static void
+gst_h265_parse2_class_init (GstH265Parse2Class * klass)
+{
+  GObjectClass *gobject_class = (GObjectClass *) klass;
+  GstBaseParseClass *parse_class = GST_BASE_PARSE_CLASS (klass);
+  GstElementClass *gstelement_class = GST_ELEMENT_CLASS (klass);
+
+  //GST_DEBUG_CATEGORY_INIT (h265_parse2_debug, "h265parse2", 0, "h265 parser");
+
+  gobject_class->finalize = gst_h265_parse2_finalize;
+  gobject_class->set_property = gst_h265_parse2_set_property;
+  gobject_class->get_property = gst_h265_parse2_get_property;
+
+  g_object_class_install_property (gobject_class, PROP_CONFIG_INTERVAL,
+      g_param_spec_int ("config-interval",
+          "VPS SPS PPS Send Interval",
+          "Send VPS, SPS and PPS Insertion Interval in seconds (sprop parameter sets "
+          "will be multiplexed in the data stream when detected.) "
+          "(0 = disabled, -1 = send with every IDR frame)",
+          -1, 3600, DEFAULT_CONFIG_INTERVAL,
+          G_PARAM_READWRITE | G_PARAM_CONSTRUCT | G_PARAM_STATIC_STRINGS));
+  /* Override BaseParse vfuncs */
+  parse_class->start = GST_DEBUG_FUNCPTR (gst_h265_parse2_start);
+  parse_class->stop = GST_DEBUG_FUNCPTR (gst_h265_parse2_stop);
+  parse_class->handle_frame = GST_DEBUG_FUNCPTR (gst_h265_parse2_handle_frame);
+  parse_class->pre_push_frame =
+      GST_DEBUG_FUNCPTR (gst_h265_parse2_pre_push_frame);
+  parse_class->set_sink_caps = GST_DEBUG_FUNCPTR (gst_h265_parse2_set_caps);
+  parse_class->get_sink_caps = GST_DEBUG_FUNCPTR (gst_h265_parse2_get_caps);
+  parse_class->sink_event = GST_DEBUG_FUNCPTR (gst_h265_parse2_event);
+  parse_class->src_event = GST_DEBUG_FUNCPTR (gst_h265_parse2_src_event);
+
+  gst_element_class_add_static_pad_template (gstelement_class, &srctemplate);
+  gst_element_class_add_static_pad_template (gstelement_class, &sinktemplate);
+
+  gst_element_class_set_static_metadata (gstelement_class, "H.265 parser",
+      "Codec/Parser/Converter/Video",
+      "Parses H.265 streams",
+      "Sreerenj Balachandran <sreerenj.balachandran@intel.com>");
+}
+
+static void
+gst_h265_parse2_init (GstH265Parse2 * h265parse)
+{
+  h265parse->frame_out = gst_adapter_new ();
+  gst_base_parse_set_pts_interpolation (GST_BASE_PARSE (h265parse), FALSE);
+  gst_base_parse_set_infer_ts (GST_BASE_PARSE (h265parse), FALSE);
+  GST_PAD_SET_ACCEPT_INTERSECT (GST_BASE_PARSE_SINK_PAD (h265parse));
+  GST_PAD_SET_ACCEPT_TEMPLATE (GST_BASE_PARSE_SINK_PAD (h265parse));
+}
+
+
+static void
+gst_h265_parse2_finalize (GObject * object)
+{
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (object);
+
+  g_object_unref (h265parse->frame_out);
+
+  G_OBJECT_CLASS (parent_class)->finalize (object);
+}
+
+static void
+gst_h265_parse2_reset_frame (GstH265Parse2 * h265parse)
+{
+  GST_DEBUG_OBJECT (h265parse, "reset frame");
+
+  /* done parsing; reset state */
+  h265parse->current_off = -1;
+
+  h265parse->update_caps = FALSE;
+  h265parse->idr_pos = -1;
+  h265parse->sei_pos = -1;
+  h265parse->keyframe = FALSE;
+  h265parse->predicted = FALSE;
+  h265parse->bidirectional = FALSE;
+  h265parse->header = FALSE;
+  h265parse->have_vps_in_frame = FALSE;
+  h265parse->have_sps_in_frame = FALSE;
+  h265parse->have_pps_in_frame = FALSE;
+  gst_adapter_clear (h265parse->frame_out);
+}
+
+static void
+gst_h265_parse2_reset_stream_info (GstH265Parse2 * h265parse)
+{
+  gint i;
+
+  h265parse->width = 0;
+  h265parse->height = 0;
+  h265parse->fps_num = 0;
+  h265parse->fps_den = 0;
+  h265parse->upstream_par_n = -1;
+  h265parse->upstream_par_d = -1;
+  h265parse->parsed_par_n = 0;
+  h265parse->parsed_par_n = 0;
+  h265parse->parsed_colorimetry.range = GST_VIDEO_COLOR_RANGE_UNKNOWN;
+  h265parse->parsed_colorimetry.matrix = GST_VIDEO_COLOR_MATRIX_UNKNOWN;
+  h265parse->parsed_colorimetry.transfer = GST_VIDEO_TRANSFER_UNKNOWN;
+  h265parse->parsed_colorimetry.primaries = GST_VIDEO_COLOR_PRIMARIES_UNKNOWN;
+  h265parse->have_pps = FALSE;
+  h265parse->have_sps = FALSE;
+  h265parse->have_vps = FALSE;
+
+  h265parse->align = GST_H265_PARSE_ALIGN_NONE;
+  h265parse->format = GST_H265_PARSE_FORMAT_NONE;
+
+  h265parse->transform = FALSE;
+  h265parse->nal_length_size = 4;
+  h265parse->packetized = FALSE;
+  h265parse->push_codec = FALSE;
+  h265parse->first_frame = TRUE;
+
+  gst_buffer_replace (&h265parse->codec_data, NULL);
+  gst_buffer_replace (&h265parse->codec_data_in, NULL);
+
+  gst_h265_parse2_reset_frame (h265parse);
+
+  for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++)
+    gst_buffer_replace (&h265parse->vps_nals[i], NULL);
+  for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++)
+    gst_buffer_replace (&h265parse->sps_nals[i], NULL);
+  for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++)
+    gst_buffer_replace (&h265parse->pps_nals[i], NULL);
+
+  gst_video_mastering_display_info_init (&h265parse->mastering_display_info);
+  h265parse->mastering_display_info_state = GST_H265_PARSE_SEI_EXPIRED;
+
+  gst_video_content_light_level_init (&h265parse->content_light_level);
+  h265parse->content_light_level_state = GST_H265_PARSE_SEI_EXPIRED;
+}
+
+static void
+gst_h265_parse2_reset (GstH265Parse2 * h265parse)
+{
+  h265parse->last_report = GST_CLOCK_TIME_NONE;
+
+  h265parse->pending_key_unit_ts = GST_CLOCK_TIME_NONE;
+  gst_event_replace (&h265parse->force_key_unit_event, NULL);
+
+  h265parse->discont = FALSE;
+  h265parse->discard_bidirectional = FALSE;
+  h265parse->marker = FALSE;
+
+  gst_h265_parse2_reset_stream_info (h265parse);
+}
+
+static gboolean
+gst_h265_parse2_start (GstBaseParse * parse)
+{
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+
+  GST_DEBUG_OBJECT (parse, "start");
+  gst_h265_parse2_reset (h265parse);
+
+  h265parse->nalparser = gst_h265_parser_new ();
+  h265parse->state = 0;
+
+  gst_base_parse_set_min_frame_size (parse, 5);
+
+  return TRUE;
+}
+
+static gboolean
+gst_h265_parse2_stop (GstBaseParse * parse)
+{
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+
+  GST_DEBUG_OBJECT (parse, "stop");
+  gst_h265_parse2_reset (h265parse);
+
+  gst_h265_parser_free (h265parse->nalparser);
+
+  return TRUE;
+}
+
+static const gchar *
+gst_h265_parse2_get_string (GstH265Parse2 * parse, gboolean format, gint code)
+{
+  if (format) {
+    switch (code) {
+      case GST_H265_PARSE_FORMAT_HVC1:
+        return "hvc1";
+      case GST_H265_PARSE_FORMAT_HEV1:
+        return "hev1";
+      case GST_H265_PARSE_FORMAT_BYTE:
+        return "byte-stream";
+      default:
+        return "none";
+    }
+  } else {
+    switch (code) {
+      case GST_H265_PARSE_ALIGN_NAL:
+        return "nal";
+      case GST_H265_PARSE_ALIGN_AU:
+        return "au";
+      default:
+        return "none";
+    }
+  }
+}
+
+static void
+gst_h265_parse2_format_from_caps (GstCaps * caps, guint * format, guint * align)
+{
+  g_return_if_fail (gst_caps_is_fixed (caps));
+
+  GST_DEBUG ("parsing caps: %" GST_PTR_FORMAT, caps);
+
+  if (format)
+    *format = GST_H265_PARSE_FORMAT_NONE;
+
+  if (align)
+    *align = GST_H265_PARSE_ALIGN_NONE;
+
+  if (caps && gst_caps_get_size (caps) > 0) {
+    GstStructure *s = gst_caps_get_structure (caps, 0);
+    const gchar *str = NULL;
+
+    if (format) {
+      if ((str = gst_structure_get_string (s, "stream-format"))) {
+        if (strcmp (str, "hvc1") == 0)
+          *format = GST_H265_PARSE_FORMAT_HVC1;
+        else if (strcmp (str, "hev1") == 0)
+          *format = GST_H265_PARSE_FORMAT_HEV1;
+        else if (strcmp (str, "byte-stream") == 0)
+          *format = GST_H265_PARSE_FORMAT_BYTE;
+      }
+    }
+
+    if (align) {
+      if ((str = gst_structure_get_string (s, "alignment"))) {
+        if (strcmp (str, "au") == 0)
+          *align = GST_H265_PARSE_ALIGN_AU;
+        else if (strcmp (str, "nal") == 0)
+          *align = GST_H265_PARSE_ALIGN_NAL;
+      }
+    }
+  }
+}
+
+/* check downstream caps to configure format and alignment */
+static void
+gst_h265_parse2_negotiate (GstH265Parse2 * h265parse, gint in_format,
+    GstCaps * in_caps)
+{
+  GstCaps *caps;
+  guint format = GST_H265_PARSE_FORMAT_NONE;
+  guint align = GST_H265_PARSE_ALIGN_NONE;
+
+  g_return_if_fail ((in_caps == NULL) || gst_caps_is_fixed (in_caps));
+
+  caps = gst_pad_get_allowed_caps (GST_BASE_PARSE_SRC_PAD (h265parse));
+  GST_DEBUG_OBJECT (h265parse, "allowed caps: %" GST_PTR_FORMAT, caps);
+
+  /* concentrate on leading structure, since decodebin parser
+   * capsfilter always includes parser template caps */
+  if (caps) {
+    caps = gst_caps_truncate (caps);
+    GST_DEBUG_OBJECT (h265parse, "negotiating with caps: %" GST_PTR_FORMAT,
+        caps);
+  }
+
+  if (in_caps && caps) {
+    if (gst_caps_can_intersect (in_caps, caps)) {
+      GST_DEBUG_OBJECT (h265parse, "downstream accepts upstream caps");
+      gst_h265_parse2_format_from_caps (in_caps, &format, &align);
+      gst_caps_unref (caps);
+      caps = NULL;
+    }
+  }
+
+  /* FIXME We could fail the negotiation immediately if caps are empty */
+  if (caps && !gst_caps_is_empty (caps)) {
+    /* fixate to avoid ambiguity with lists when parsing */
+    caps = gst_caps_fixate (caps);
+    gst_h265_parse2_format_from_caps (caps, &format, &align);
+  }
+
+  /* default */
+  if (!format)
+    format = GST_H265_PARSE_FORMAT_BYTE;
+  if (!align)
+    align = GST_H265_PARSE_ALIGN_AU;
+
+  GST_DEBUG_OBJECT (h265parse, "selected format %s, alignment %s",
+      gst_h265_parse2_get_string (h265parse, TRUE, format),
+      gst_h265_parse2_get_string (h265parse, FALSE, align));
+
+  h265parse->format = format;
+  h265parse->align = align;
+
+  h265parse->transform = in_format != h265parse->format ||
+      align == GST_H265_PARSE_ALIGN_AU;
+
+  if (caps)
+    gst_caps_unref (caps);
+}
+
+static GstBuffer *
+gst_h265_parse2_wrap_nal (GstH265Parse2 * h265parse, guint format, guint8 * data,
+    guint size)
+{
+  GstBuffer *buf;
+  guint nl = h265parse->nal_length_size;
+  guint32 tmp;
+
+  GST_DEBUG_OBJECT (h265parse, "nal length %d", size);
+
+  buf = gst_buffer_new_allocate (NULL, 4 + size, NULL);
+  if (format == GST_H265_PARSE_FORMAT_HVC1
+      || format == GST_H265_PARSE_FORMAT_HEV1) {
+    tmp = GUINT32_TO_BE (size << (32 - 8 * nl));
+  } else {
+    /* HACK: nl should always be 4 here, otherwise this won't work.
+     * There are legit cases where nl in hevc stream is 2, but byte-stream
+     * SC is still always 4 bytes. */
+    nl = 4;
+    tmp = GUINT32_TO_BE (1);
+  }
+
+  gst_buffer_fill (buf, 0, &tmp, sizeof (guint32));
+  gst_buffer_fill (buf, nl, data, size);
+  gst_buffer_set_size (buf, size + nl);
+
+  return buf;
+}
+
+static void
+gst_h265_parser_store_nal (GstH265Parse2 * h265parse, guint id,
+    GstH265NalUnitType naltype, GstH265NalUnit * nalu)
+{
+  GstBuffer *buf, **store;
+  guint size = nalu->size, store_size;
+
+  if (naltype == GST_H265_NAL_VPS) {
+    store_size = GST_H265_MAX_VPS_COUNT;
+    store = h265parse->vps_nals;
+    GST_DEBUG_OBJECT (h265parse, "storing vps %u", id);
+  } else if (naltype == GST_H265_NAL_SPS) {
+    store_size = GST_H265_MAX_SPS_COUNT;
+    store = h265parse->sps_nals;
+    GST_DEBUG_OBJECT (h265parse, "storing sps %u", id);
+  } else if (naltype == GST_H265_NAL_PPS) {
+    store_size = GST_H265_MAX_PPS_COUNT;
+    store = h265parse->pps_nals;
+    GST_DEBUG_OBJECT (h265parse, "storing pps %u", id);
+  } else
+    return;
+
+  if (id >= store_size) {
+    GST_DEBUG_OBJECT (h265parse, "unable to store nal, id out-of-range %d", id);
+    return;
+  }
+
+  buf = gst_buffer_new_allocate (NULL, size, NULL);
+  gst_buffer_fill (buf, 0, nalu->data + nalu->offset, size);
+
+  /* Indicate that buffer contain a header needed for decoding */
+  if (naltype >= GST_H265_NAL_VPS && naltype <= GST_H265_NAL_PPS)
+    GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_HEADER);
+
+  if (store[id])
+    gst_buffer_unref (store[id]);
+
+  store[id] = buf;
+}
+
+#ifndef GST_DISABLE_GST_DEBUG
+static const gchar *nal_names[] = {
+  "Slice_TRAIL_N",
+  "Slice_TRAIL_R",
+  "Slice_TSA_N",
+  "Slice_TSA_R",
+  "Slice_STSA_N",
+  "Slice_STSA_R",
+  "Slice_RADL_N",
+  "Slice_RADL_R",
+  "SLICE_RASL_N",
+  "SLICE_RASL_R",
+  "Invalid (10)",
+  "Invalid (11)",
+  "Invalid (12)",
+  "Invalid (13)",
+  "Invalid (14)",
+  "Invalid (15)",
+  "SLICE_BLA_W_LP",
+  "SLICE_BLA_W_RADL",
+  "SLICE_BLA_N_LP",
+  "SLICE_IDR_W_RADL",
+  "SLICE_IDR_N_LP",
+  "SLICE_CRA_NUT",
+  "Invalid (22)",
+  "Invalid (23)",
+  "Invalid (24)",
+  "Invalid (25)",
+  "Invalid (26)",
+  "Invalid (27)",
+  "Invalid (28)",
+  "Invalid (29)",
+  "Invalid (30)",
+  "Invalid (31)",
+  "VPS",
+  "SPS",
+  "PPS",
+  "AUD",
+  "EOS",
+  "EOB",
+  "FD",
+  "PREFIX_SEI",
+  "SUFFIX_SEI"
+};
+
+static const gchar *
+_nal_name (GstH265NalUnitType nal_type)
+{
+  if (nal_type <= GST_H265_NAL_SUFFIX_SEI)
+    return nal_names[nal_type];
+  return "Invalid";
+}
+#endif
+
+static void
+gst_h265_parse2_process_sei (GstH265Parse2 * h265parse, GstH265NalUnit * nalu)
+{
+  GstH265SEIMessage sei;
+  GstH265Parser *nalparser = h265parse->nalparser;
+  GstH265ParserResult pres;
+  GArray *messages;
+  guint i;
+
+  pres = gst_h265_parser_parse_sei (nalparser, nalu, &messages);
+  if (pres != GST_H265_PARSER_OK)
+    GST_WARNING_OBJECT (h265parse, "failed to parse one or more SEI message");
+
+  /* Even if pres != GST_H265_PARSER_OK, some message could have been parsed and
+   * stored in messages.
+   */
+  for (i = 0; i < messages->len; i++) {
+    sei = g_array_index (messages, GstH265SEIMessage, i);
+    switch (sei.payloadType) {
+      case GST_H265_SEI_RECOVERY_POINT:
+        GST_LOG_OBJECT (h265parse, "recovery point found: %u %u %u",
+            sei.payload.recovery_point.recovery_poc_cnt,
+            sei.payload.recovery_point.exact_match_flag,
+            sei.payload.recovery_point.broken_link_flag);
+        h265parse->keyframe = TRUE;
+        break;
+      case GST_H265_SEI_TIME_CODE:
+        memcpy (&h265parse->time_code, &sei.payload.time_code,
+            sizeof (GstH265TimeCode));
+        break;
+      case GST_H265_SEI_PIC_TIMING:
+        h265parse->sei_pic_struct = sei.payload.pic_timing.pic_struct;
+        break;
+      case GST_H265_SEI_REGISTERED_USER_DATA:
+        gst_h265_parse2_process_sei_user_data (h265parse,
+            &sei.payload.registered_user_data);
+        break;
+      case GST_H265_SEI_BUF_PERIOD:
+        /* FIXME */
+        break;
+      case GST_H265_SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
+      {
+        /* Precision defined by spec.
+         * See D.3.28 Mastering display colour volume SEI message semantics */
+        GstVideoMasteringDisplayInfo minfo;
+        gint j, k;
+
+        /* GstVideoMasteringDisplayInfo::display_primaries is rgb order but
+         * HEVC uses gbr order
+         * See spec D.3.28 display_primaries_x and display_primaries_y
+         */
+        for (j = 0, k = 2; j < G_N_ELEMENTS (minfo.display_primaries); j++, k++) {
+          minfo.display_primaries[j].x =
+              sei.payload.
+              mastering_display_colour_volume.display_primaries_x[k % 3];
+          minfo.display_primaries[j].y =
+              sei.payload.
+              mastering_display_colour_volume.display_primaries_y[k % 3];
+        }
+
+        minfo.white_point.x =
+            sei.payload.mastering_display_colour_volume.white_point_x;
+        minfo.white_point.y =
+            sei.payload.mastering_display_colour_volume.white_point_y;
+        minfo.max_display_mastering_luminance =
+            sei.payload.mastering_display_colour_volume.
+            max_display_mastering_luminance;
+        minfo.min_display_mastering_luminance =
+            sei.payload.mastering_display_colour_volume.
+            min_display_mastering_luminance;
+
+        GST_LOG_OBJECT (h265parse, "mastering display info found: "
+            "Red(%u, %u) "
+            "Green(%u, %u) "
+            "Blue(%u, %u) "
+            "White(%u, %u) "
+            "max_luminance(%u) "
+            "min_luminance(%u) ",
+            minfo.display_primaries[0].x, minfo.display_primaries[0].y,
+            minfo.display_primaries[1].x, minfo.display_primaries[1].y,
+            minfo.display_primaries[2].x, minfo.display_primaries[2].y,
+            minfo.white_point.x, minfo.white_point.y,
+            minfo.max_display_mastering_luminance,
+            minfo.min_display_mastering_luminance);
+
+        if (h265parse->mastering_display_info_state ==
+            GST_H265_PARSE_SEI_EXPIRED) {
+          h265parse->update_caps = TRUE;
+        } else if (!gst_video_mastering_display_info_is_equal
+            (&h265parse->mastering_display_info, &minfo)) {
+          h265parse->update_caps = TRUE;
+        }
+
+        h265parse->mastering_display_info_state = GST_H265_PARSE_SEI_PARSED;
+        h265parse->mastering_display_info = minfo;
+
+        break;
+      }
+      case GST_H265_SEI_CONTENT_LIGHT_LEVEL:
+      {
+        GstVideoContentLightLevel cll;
+
+        cll.max_content_light_level =
+            sei.payload.content_light_level.max_content_light_level;
+        cll.max_frame_average_light_level =
+            sei.payload.content_light_level.max_pic_average_light_level;
+
+        GST_LOG_OBJECT (h265parse, "content light level found: "
+            "maxCLL:(%u), maxFALL:(%u)", cll.max_content_light_level,
+            cll.max_frame_average_light_level);
+
+        if (h265parse->content_light_level_state == GST_H265_PARSE_SEI_EXPIRED) {
+          h265parse->update_caps = TRUE;
+        } else if (cll.max_content_light_level !=
+            h265parse->content_light_level.max_content_light_level ||
+            cll.max_frame_average_light_level !=
+            h265parse->content_light_level.max_frame_average_light_level) {
+          h265parse->update_caps = TRUE;
+        }
+
+        h265parse->content_light_level_state = GST_H265_PARSE_SEI_PARSED;
+        h265parse->content_light_level = cll;
+
+        break;
+      }
+      default:
+        break;
+    }
+  }
+  g_array_free (messages, TRUE);
+}
+
+static void
+gst_h265_parse2_process_sei_user_data (GstH265Parse2 * h265parse,
+    GstH265RegisteredUserData * rud)
+{
+  guint16 provider_code;
+  GstByteReader br;
+  GstVideoParseUtilsField field = GST_VIDEO_PARSE_UTILS_FIELD_1;
+
+  /* only US country code is currently supported */
+  switch (rud->country_code) {
+    case ITU_T_T35_COUNTRY_CODE_US:
+      break;
+    default:
+      GST_LOG_OBJECT (h265parse, "Unsupported country code %d",
+          rud->country_code);
+      return;
+  }
+
+  if (rud->data == NULL || rud->size < 2)
+    return;
+
+  gst_byte_reader_init (&br, rud->data, rud->size);
+
+  provider_code = gst_byte_reader_get_uint16_be_unchecked (&br);
+
+  if (h265parse->sei_pic_struct ==
+      (guint8) GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD)
+    field = GST_VIDEO_PARSE_UTILS_FIELD_1;
+  gst_video_parse_user_data ((GstElement *) h265parse, &h265parse->user_data,
+      &br, field, provider_code);
+
+}
+
+/* caller guarantees 2 bytes of nal payload */
+static gboolean
+gst_h265_parse2_process_nal (GstH265Parse2 * h265parse, GstH265NalUnit * nalu)
+{
+  GstH265PPS pps = { 0, };
+  GstH265SPS sps = { 0, };
+  GstH265VPS vps = { 0, };
+  guint nal_type;
+  GstH265Parser *nalparser = h265parse->nalparser;
+  GstH265ParserResult pres = GST_H265_PARSER_ERROR;
+
+  /* nothing to do for broken input */
+  if (G_UNLIKELY (nalu->size < 2)) {
+    GST_DEBUG_OBJECT (h265parse, "not processing nal size %u", nalu->size);
+    return TRUE;
+  }
+
+  /* we have a peek as well */
+  nal_type = nalu->type;
+
+  GST_DEBUG_OBJECT (h265parse, "processing nal of type %u %s, size %u",
+      nal_type, _nal_name (nal_type), nalu->size);
+  switch (nal_type) {
+    case GST_H265_NAL_VPS:
+      /* It is not mandatory to have VPS in the stream. But it might
+       * be needed for other extensions like svc */
+      pres = gst_h265_parser_parse_vps (nalparser, nalu, &vps);
+      if (pres != GST_H265_PARSER_OK) {
+        GST_WARNING_OBJECT (h265parse, "failed to parse VPS");
+        return FALSE;
+      }
+
+      GST_DEBUG_OBJECT (h265parse, "triggering src caps check");
+      h265parse->update_caps = TRUE;
+      h265parse->have_vps = TRUE;
+      h265parse->have_vps_in_frame = TRUE;
+      if (h265parse->push_codec && h265parse->have_pps) {
+        /* VPS/SPS/PPS found in stream before the first pre_push_frame, no need
+         * to forcibly push at start */
+        GST_INFO_OBJECT (h265parse, "have VPS/SPS/PPS in stream");
+        h265parse->push_codec = FALSE;
+        h265parse->have_vps = FALSE;
+        h265parse->have_sps = FALSE;
+        h265parse->have_pps = FALSE;
+      }
+
+      gst_h265_parser_store_nal (h265parse, vps.id, nal_type, nalu);
+      h265parse->header = TRUE;
+      break;
+    case GST_H265_NAL_SPS:
+      /* reset state, everything else is obsolete */
+      h265parse->state &= GST_H265_PARSE_STATE_GOT_PPS;
+
+      pres = gst_h265_parser_parse_sps (nalparser, nalu, &sps, TRUE);
+
+
+      /* arranged for a fallback sps.id, so use that one and only warn */
+      if (pres != GST_H265_PARSER_OK) {
+        /* try to not parse VUI */
+        pres = gst_h265_parser_parse_sps (nalparser, nalu, &sps, FALSE);
+        if (pres != GST_H265_PARSER_OK) {
+          GST_WARNING_OBJECT (h265parse, "failed to parse SPS:");
+          h265parse->state |= GST_H265_PARSE_STATE_GOT_SPS;
+          h265parse->header = TRUE;
+          return FALSE;
+        }
+        GST_WARNING_OBJECT (h265parse,
+            "failed to parse VUI of SPS, ignore VUI");
+      }
+
+      GST_DEBUG_OBJECT (h265parse, "triggering src caps check");
+      h265parse->update_caps = TRUE;
+      h265parse->have_sps = TRUE;
+      h265parse->have_sps_in_frame = TRUE;
+      if (h265parse->push_codec && h265parse->have_pps) {
+        /* SPS and PPS found in stream before the first pre_push_frame, no need
+         * to forcibly push at start */
+        GST_INFO_OBJECT (h265parse, "have SPS/PPS in stream");
+        h265parse->push_codec = FALSE;
+        h265parse->have_sps = FALSE;
+        h265parse->have_pps = FALSE;
+      }
+
+      gst_h265_parser_store_nal (h265parse, sps.id, nal_type, nalu);
+      h265parse->header = TRUE;
+      h265parse->state |= GST_H265_PARSE_STATE_GOT_SPS;
+      break;
+    case GST_H265_NAL_PPS:
+      /* expected state: got-sps */
+      h265parse->state &= GST_H265_PARSE_STATE_GOT_SPS;
+      if (!GST_H265_PARSE_STATE_VALID (h265parse, GST_H265_PARSE_STATE_GOT_SPS))
+        return FALSE;
+
+      pres = gst_h265_parser_parse_pps (nalparser, nalu, &pps);
+
+
+      /* arranged for a fallback pps.id, so use that one and only warn */
+      if (pres != GST_H265_PARSER_OK) {
+        GST_WARNING_OBJECT (h265parse, "failed to parse PPS:");
+        if (pres != GST_H265_PARSER_BROKEN_LINK)
+          return FALSE;
+      }
+
+      /* parameters might have changed, force caps check */
+      if (!h265parse->have_pps) {
+        GST_DEBUG_OBJECT (h265parse, "triggering src caps check");
+        h265parse->update_caps = TRUE;
+      }
+      h265parse->have_pps = TRUE;
+      h265parse->have_pps_in_frame = TRUE;
+      if (h265parse->push_codec && h265parse->have_sps) {
+        /* SPS and PPS found in stream before the first pre_push_frame, no need
+         * to forcibly push at start */
+        GST_INFO_OBJECT (h265parse, "have SPS/PPS in stream");
+        h265parse->push_codec = FALSE;
+        h265parse->have_sps = FALSE;
+        h265parse->have_pps = FALSE;
+      }
+
+      gst_h265_parser_store_nal (h265parse, pps.id, nal_type, nalu);
+      h265parse->header = TRUE;
+      h265parse->state |= GST_H265_PARSE_STATE_GOT_PPS;
+      break;
+    case GST_H265_NAL_PREFIX_SEI:
+    case GST_H265_NAL_SUFFIX_SEI:
+      /* expected state: got-sps */
+      if (!GST_H265_PARSE_STATE_VALID (h265parse, GST_H265_PARSE_STATE_GOT_SPS))
+        return FALSE;
+
+      h265parse->header = TRUE;
+
+      gst_h265_parse2_process_sei (h265parse, nalu);
+
+      /* mark SEI pos */
+      if (nal_type == GST_H265_NAL_PREFIX_SEI && h265parse->sei_pos == -1) {
+        if (h265parse->transform)
+          h265parse->sei_pos = gst_adapter_available (h265parse->frame_out);
+        else
+          h265parse->sei_pos = nalu->sc_offset;
+        GST_DEBUG_OBJECT (h265parse, "marking SEI in frame at offset %d",
+            h265parse->sei_pos);
+      }
+      break;
+
+    case GST_H265_NAL_SLICE_TRAIL_N:
+    case GST_H265_NAL_SLICE_TRAIL_R:
+    case GST_H265_NAL_SLICE_TSA_N:
+    case GST_H265_NAL_SLICE_TSA_R:
+    case GST_H265_NAL_SLICE_STSA_N:
+    case GST_H265_NAL_SLICE_STSA_R:
+    case GST_H265_NAL_SLICE_RADL_N:
+    case GST_H265_NAL_SLICE_RADL_R:
+    case GST_H265_NAL_SLICE_RASL_N:
+    case GST_H265_NAL_SLICE_RASL_R:
+    case GST_H265_NAL_SLICE_BLA_W_LP:
+    case GST_H265_NAL_SLICE_BLA_W_RADL:
+    case GST_H265_NAL_SLICE_BLA_N_LP:
+    case GST_H265_NAL_SLICE_IDR_W_RADL:
+    case GST_H265_NAL_SLICE_IDR_N_LP:
+    case GST_H265_NAL_SLICE_CRA_NUT:
+    {
+      GstH265SliceHdr slice;
+      gboolean is_irap;
+      gboolean no_rasl_output_flag = FALSE;
+
+      /* expected state: got-sps|got-pps (valid picture headers) */
+      h265parse->state &= GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS;
+      if (!GST_H265_PARSE_STATE_VALID (h265parse,
+              GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS))
+        return FALSE;
+
+      /* This is similar to the GOT_SLICE state, but is only reset when the
+       * AU is complete. This is used to keep track of AU */
+      h265parse->picture_start = TRUE;
+
+      pres = gst_h265_parser_parse_slice_hdr (nalparser, nalu, &slice);
+
+      if (pres == GST_H265_PARSER_OK) {
+        if (GST_H265_IS_I_SLICE (&slice))
+          h265parse->keyframe = TRUE;
+        else if (GST_H265_IS_P_SLICE (&slice))
+          h265parse->predicted = TRUE;
+        else if (GST_H265_IS_B_SLICE (&slice))
+          h265parse->bidirectional = TRUE;
+
+        h265parse->state |= GST_H265_PARSE_STATE_GOT_SLICE;
+      }
+      if (slice.first_slice_segment_in_pic_flag == 1)
+        GST_DEBUG_OBJECT (h265parse,
+            "frame start, first_slice_segment_in_pic_flag = 1");
+
+      GST_DEBUG_OBJECT (h265parse,
+          "parse result %d, first slice_segment: %u, slice type: %u",
+          pres, slice.first_slice_segment_in_pic_flag, slice.type);
+
+      gst_h265_slice_hdr_free (&slice);
+
+      /* FIXME: NoRaslOutputFlag can be equal to 1 for CRA if
+       * 1) the first AU in bitstream is CRA
+       * 2) or the first AU following EOS nal is CRA
+       * 3) or it has HandleCraAsBlaFlag equal to 1 */
+      if (GST_H265_IS_NAL_TYPE_IDR (nal_type)) {
+        /* NoRaslOutputFlag is equal to 1 for each IDR */
+        no_rasl_output_flag = TRUE;
+      } else if (GST_H265_IS_NAL_TYPE_BLA (nal_type)) {
+        /* NoRaslOutputFlag is equal to 1 for each BLA */
+        no_rasl_output_flag = TRUE;
+      }
+
+      is_irap = GST_H265_IS_NAL_TYPE_IRAP (nal_type);
+
+      if (no_rasl_output_flag && is_irap
+          && slice.first_slice_segment_in_pic_flag == 1) {
+        if (h265parse->mastering_display_info_state ==
+            GST_H265_PARSE_SEI_PARSED)
+          h265parse->mastering_display_info_state = GST_H265_PARSE_SEI_ACTIVE;
+        else if (h265parse->mastering_display_info_state ==
+            GST_H265_PARSE_SEI_ACTIVE)
+          h265parse->mastering_display_info_state = GST_H265_PARSE_SEI_EXPIRED;
+
+        if (h265parse->content_light_level_state == GST_H265_PARSE_SEI_PARSED)
+          h265parse->content_light_level_state = GST_H265_PARSE_SEI_ACTIVE;
+        else if (h265parse->content_light_level_state ==
+            GST_H265_PARSE_SEI_ACTIVE)
+          h265parse->content_light_level_state = GST_H265_PARSE_SEI_EXPIRED;
+      }
+      if (G_LIKELY (!is_irap && !h265parse->push_codec))
+        break;
+
+      /* if we need to sneak codec NALs into the stream,
+       * this is a good place, so fake it as IDR
+       * (which should be at start anyway) */
+      /* mark where config needs to go if interval expired */
+      /* mind replacement buffer if applicable */
+      if (h265parse->idr_pos == -1) {
+        if (h265parse->transform)
+          h265parse->idr_pos = gst_adapter_available (h265parse->frame_out);
+        else
+          h265parse->idr_pos = nalu->sc_offset;
+        GST_DEBUG_OBJECT (h265parse, "marking IDR in frame at offset %d",
+            h265parse->idr_pos);
+      }
+      /* if SEI preceeds (faked) IDR, then we have to insert config there */
+      if (h265parse->sei_pos >= 0 && h265parse->idr_pos > h265parse->sei_pos) {
+        h265parse->idr_pos = h265parse->sei_pos;
+        GST_DEBUG_OBJECT (h265parse, "moved IDR mark to SEI position %d",
+            h265parse->idr_pos);
+      }
+      break;
+    }
+    case GST_H265_NAL_AUD:
+      /* Just accumulate AU Delimiter, whether it's before SPS or not */
+      pres = gst_h265_parser_parse_nal (nalparser, nalu);
+      if (pres != GST_H265_PARSER_OK)
+        return FALSE;
+      break;
+    default:
+      /* drop anything before the initial SPS */
+      if (!GST_H265_PARSE_STATE_VALID (h265parse, GST_H265_PARSE_STATE_GOT_SPS))
+        return FALSE;
+
+      pres = gst_h265_parser_parse_nal (nalparser, nalu);
+      if (pres != GST_H265_PARSER_OK)
+        return FALSE;
+      break;
+  }
+
+  /* if HEVC output needed, collect properly prefixed nal in adapter,
+   * and use that to replace outgoing buffer data later on */
+  if (h265parse->transform) {
+    GstBuffer *buf;
+
+    GST_LOG_OBJECT (h265parse, "collecting NAL in HEVC frame");
+    buf = gst_h265_parse2_wrap_nal (h265parse, h265parse->format,
+        nalu->data + nalu->offset, nalu->size);
+    gst_adapter_push (h265parse->frame_out, buf);
+  }
+
+  return TRUE;
+}
+
+/* caller guarantees at least 3 bytes of nal payload for each nal
+ * returns TRUE if next_nal indicates that nal terminates an AU */
+static inline gboolean
+gst_h265_parse2_collect_nal (GstH265Parse2 * h265parse, const guint8 * data,
+    guint size, GstH265NalUnit * nalu)
+{
+  GstH265NalUnitType nal_type = nalu->type;
+  gboolean complete;
+
+  /* determine if AU complete */
+  GST_LOG_OBJECT (h265parse, "next nal type: %d %s (picture started %i)",
+      nal_type, _nal_name (nal_type), h265parse->picture_start);
+
+  /* consider a coded slices (IRAP or not) to start a picture,
+   * (so ending the previous one) if first_slice_segment_in_pic_flag == 1*/
+  complete = h265parse->picture_start && ((nal_type >= GST_H265_NAL_VPS
+          && nal_type <= GST_H265_NAL_AUD)
+      || nal_type == GST_H265_NAL_PREFIX_SEI || (nal_type >= 41
+          && nal_type <= 44) || (nal_type >= 48 && nal_type <= 55));
+
+  /* Any VCL Nal unit with first_slice_segment_in_pic_flag == 1 considered start of frame */
+  if (nalu->size > nalu->header_bytes) {
+    complete |= h265parse->picture_start
+        && (((nal_type >= GST_H265_NAL_SLICE_TRAIL_N
+                && nal_type <= GST_H265_NAL_SLICE_RASL_R)
+            || GST_H265_IS_NAL_TYPE_IRAP (nal_type))
+        && (nalu->data[nalu->offset + 2] & 0x80));
+  }
+
+  GST_LOG_OBJECT (h265parse, "au complete: %d", complete);
+
+  if (complete)
+    h265parse->picture_start = FALSE;
+
+  return complete;
+}
+
+static GstFlowReturn
+gst_h265_parse2_handle_frame_packetized (GstBaseParse * parse,
+    GstBaseParseFrame * frame)
+{
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+  GstBuffer *buffer = frame->buffer;
+  GstFlowReturn ret = GST_FLOW_OK;
+  GstH265ParserResult parse_res;
+  GstH265NalUnit nalu;
+  const guint nl = h265parse->nal_length_size;
+  GstMapInfo map;
+  gint left;
+
+  if (nl < 1 || nl > 4) {
+    GST_DEBUG_OBJECT (h265parse, "insufficient data to split input");
+    return GST_FLOW_NOT_NEGOTIATED;
+  }
+
+  /* need to save buffer from invalidation upon _finish_frame */
+  if (h265parse->split_packetized)
+    buffer = gst_buffer_copy (frame->buffer);
+
+  gst_buffer_map (buffer, &map, GST_MAP_READ);
+
+  left = map.size;
+
+  GST_LOG_OBJECT (h265parse,
+      "processing packet buffer of size %" G_GSIZE_FORMAT, map.size);
+
+  parse_res = gst_h265_parser_identify_nalu_hevc (h265parse->nalparser,
+      map.data, 0, map.size, nl, &nalu);
+
+  while (parse_res == GST_H265_PARSER_OK) {
+    GST_DEBUG_OBJECT (h265parse, "HEVC nal offset %d", nalu.offset + nalu.size);
+
+    /* either way, have a look at it */
+    gst_h265_parse2_process_nal (h265parse, &nalu);
+
+    /* dispatch per NALU if needed */
+    if (h265parse->split_packetized) {
+      GstBaseParseFrame tmp_frame;
+
+      gst_base_parse_frame_init (&tmp_frame);
+      tmp_frame.flags |= frame->flags;
+      tmp_frame.offset = frame->offset;
+      tmp_frame.overhead = frame->overhead;
+      tmp_frame.buffer = gst_buffer_copy_region (buffer, GST_BUFFER_COPY_ALL,
+          nalu.offset, nalu.size);
+      /* Don't lose timestamp when offset is not 0. */
+      GST_BUFFER_PTS (tmp_frame.buffer) = GST_BUFFER_PTS (buffer);
+      GST_BUFFER_DTS (tmp_frame.buffer) = GST_BUFFER_DTS (buffer);
+      GST_BUFFER_DURATION (tmp_frame.buffer) = GST_BUFFER_DURATION (buffer);
+
+      /* Set marker on last packet */
+      if (nl + nalu.size == left) {
+        if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_MARKER))
+          h265parse->marker = TRUE;
+      }
+
+      /* note we don't need to come up with a sub-buffer, since
+       * subsequent code only considers input buffer's metadata.
+       * Real data is either taken from input by baseclass or
+       * a replacement output buffer is provided anyway. */
+      gst_h265_parse2_parse_frame (parse, &tmp_frame);
+      ret = gst_base_parse_finish_frame (parse, &tmp_frame, nl + nalu.size);
+      left -= nl + nalu.size;
+    }
+
+    parse_res = gst_h265_parser_identify_nalu_hevc (h265parse->nalparser,
+        map.data, nalu.offset + nalu.size, map.size, nl, &nalu);
+  }
+
+  gst_buffer_unmap (buffer, &map);
+
+  if (!h265parse->split_packetized) {
+    h265parse->marker = TRUE;
+    gst_h265_parse2_parse_frame (parse, frame);
+    ret = gst_base_parse_finish_frame (parse, frame, map.size);
+  } else {
+    gst_buffer_unref (buffer);
+    if (G_UNLIKELY (left)) {
+      /* should not be happening for nice HEVC */
+      GST_WARNING_OBJECT (parse, "skipping leftover HEVC data %d", left);
+      frame->flags |= GST_BASE_PARSE_FRAME_FLAG_DROP;
+      ret = gst_base_parse_finish_frame (parse, frame, map.size);
+    }
+  }
+
+  if (parse_res == GST_H265_PARSER_NO_NAL_END ||
+      parse_res == GST_H265_PARSER_BROKEN_DATA) {
+
+    if (h265parse->split_packetized) {
+      GST_ELEMENT_ERROR (h265parse, STREAM, FAILED, (NULL),
+          ("invalid HEVC input data"));
+
+      return GST_FLOW_ERROR;
+    } else {
+      /* do not meddle to much in this case */
+      GST_DEBUG_OBJECT (h265parse, "parsing packet failed");
+    }
+  }
+
+  return ret;
+}
+
+static GstFlowReturn
+gst_h265_parse2_handle_frame (GstBaseParse * parse,
+    GstBaseParseFrame * frame, gint * skipsize)
+{
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+  GstBuffer *buffer = frame->buffer;
+  GstMapInfo map;
+  guint8 *data;
+  gsize size;
+  gint current_off = 0;
+  gboolean drain, nonext;
+  GstH265Parser *nalparser = h265parse->nalparser;
+  GstH265NalUnit nalu;
+  GstH265ParserResult pres;
+  gint framesize;
+
+  if (G_UNLIKELY (GST_BUFFER_FLAG_IS_SET (frame->buffer,
+              GST_BUFFER_FLAG_DISCONT))) {
+    h265parse->discont = TRUE;
+  }
+
+  /* delegate in packetized case, no skipping should be needed */
+  if (h265parse->packetized)
+    return gst_h265_parse2_handle_frame_packetized (parse, frame);
+
+  gst_buffer_map (buffer, &map, GST_MAP_READ);
+  data = map.data;
+  size = map.size;
+
+  /* expect at least 3 bytes start_code, and 2 bytes NALU header.
+   * the length of the NALU payload can be zero.
+   * (e.g. EOS/EOB placed at the end of an AU.) */
+  if (G_UNLIKELY (size < 5)) {
+    gst_buffer_unmap (buffer, &map);
+    *skipsize = 1;
+    return GST_FLOW_OK;
+  }
+
+  /* need to configure aggregation */
+  if (G_UNLIKELY (h265parse->format == GST_H265_PARSE_FORMAT_NONE))
+    gst_h265_parse2_negotiate (h265parse, GST_H265_PARSE_FORMAT_BYTE, NULL);
+
+  /* avoid stale cached parsing state */
+  if (frame->flags & GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME) {
+    GST_LOG_OBJECT (h265parse, "parsing new frame");
+    gst_h265_parse2_reset_frame (h265parse);
+  } else {
+    GST_LOG_OBJECT (h265parse, "resuming frame parsing");
+  }
+
+  /* Always consume the entire input buffer when in_align == ALIGN_AU */
+  drain = GST_BASE_PARSE_DRAINING (parse)
+      || h265parse->in_align == GST_H265_PARSE_ALIGN_AU;
+  nonext = FALSE;
+
+  current_off = h265parse->current_off;
+  if (current_off < 0)
+    current_off = 0;
+
+  /* The parser is being drain, but no new data was added, just prentend this
+   * AU is complete */
+  if (drain && current_off == size) {
+    GST_DEBUG_OBJECT (h265parse, "draining with no new data");
+    nalu.size = 0;
+    nalu.offset = current_off;
+    goto end;
+  }
+
+  g_assert (current_off < size);
+  GST_DEBUG_OBJECT (h265parse, "last parse position %d", current_off);
+
+  /* check for initial skip */
+  if (h265parse->current_off == -1) {
+    pres =
+        gst_h265_parser_identify_nalu_unchecked (nalparser, data, current_off,
+        size, &nalu);
+    switch (pres) {
+      case GST_H265_PARSER_OK:
+        if (nalu.sc_offset > 0) {
+          *skipsize = nalu.sc_offset;
+          goto skip;
+        }
+        break;
+      case GST_H265_PARSER_NO_NAL:
+        /* start code may have up to 4 bytes, and we may also get that return
+         * value if only one of the two header bytes are present, make sure
+         * not to skip too much */
+        *skipsize = size - 5;
+        goto skip;
+      default:
+        /* should not really occur either */
+        GST_ELEMENT_ERROR (h265parse, STREAM, FORMAT,
+            ("Error parsing H.265 stream"), ("Invalid H.265 stream"));
+        goto invalid_stream;
+    }
+
+    /* Ensure we use the TS of the first NAL. This avoids broken timestamp in
+     * the case of a miss-placed filler byte. */
+    gst_base_parse_set_ts_at_offset (parse, nalu.offset);
+  }
+
+  while (TRUE) {
+    pres =
+        gst_h265_parser_identify_nalu (nalparser, data, current_off, size,
+        &nalu);
+
+    switch (pres) {
+      case GST_H265_PARSER_OK:
+        GST_DEBUG_OBJECT (h265parse, "complete nal (offset, size): (%u, %u) ",
+            nalu.offset, nalu.size);
+        break;
+      case GST_H265_PARSER_NO_NAL_END:
+        /* In NAL alignment, assume the NAL is complete */
+        if (h265parse->in_align == GST_H265_PARSE_ALIGN_NAL ||
+            h265parse->in_align == GST_H265_PARSE_ALIGN_AU) {
+          nonext = TRUE;
+          nalu.size = size - nalu.offset;
+          break;
+        }
+        GST_DEBUG_OBJECT (h265parse, "not a complete nal found at offset %u",
+            nalu.offset);
+        /* if draining, accept it as complete nal */
+        if (drain) {
+          nonext = TRUE;
+          nalu.size = size - nalu.offset;
+          GST_DEBUG_OBJECT (h265parse, "draining, accepting with size %u",
+              nalu.size);
+          /* if it's not too short at least */
+          if (nalu.size < 3)
+            goto broken;
+          break;
+        }
+        /* otherwise need more */
+        goto more;
+      case GST_H265_PARSER_BROKEN_LINK:
+        GST_ELEMENT_ERROR (h265parse, STREAM, FORMAT,
+            ("Error parsing H.265 stream"),
+            ("The link to structure needed for the parsing couldn't be found"));
+        goto invalid_stream;
+      case GST_H265_PARSER_ERROR:
+        /* should not really occur either */
+        GST_ELEMENT_ERROR (h265parse, STREAM, FORMAT,
+            ("Error parsing H.265 stream"), ("Invalid H.265 stream"));
+        goto invalid_stream;
+      case GST_H265_PARSER_NO_NAL:
+        GST_ELEMENT_ERROR (h265parse, STREAM, FORMAT,
+            ("Error parsing H.265 stream"), ("No H.265 NAL unit found"));
+        goto invalid_stream;
+      case GST_H265_PARSER_BROKEN_DATA:
+        GST_WARNING_OBJECT (h265parse, "input stream is corrupt; "
+            "it contains a NAL unit of length %u", nalu.size);
+      broken:
+        /* broken nal at start -> arrange to skip it,
+         * otherwise have it terminate current au
+         * (and so it will be skipped on next frame round) */
+        if (current_off == 0) {
+          GST_DEBUG_OBJECT (h265parse, "skipping broken nal");
+          *skipsize = nalu.offset;
+          goto skip;
+        } else {
+          GST_DEBUG_OBJECT (h265parse, "terminating au");
+          nalu.size = 0;
+          nalu.offset = nalu.sc_offset;
+          goto end;
+        }
+      default:
+        g_assert_not_reached ();
+        break;
+    }
+
+    GST_DEBUG_OBJECT (h265parse, "%p complete nal found. Off: %u, Size: %u",
+        data, nalu.offset, nalu.size);
+
+    if (gst_h265_parse2_collect_nal (h265parse, data, size, &nalu)) {
+      /* complete current frame, if it exist */
+      if (current_off > 0) {
+        nalu.size = 0;
+        nalu.offset = nalu.sc_offset;
+        h265parse->marker = TRUE;
+        break;
+      }
+    }
+
+    if (!gst_h265_parse2_process_nal (h265parse, &nalu)) {
+      GST_WARNING_OBJECT (h265parse,
+          "broken/invalid nal Type: %d %s, Size: %u will be dropped",
+          nalu.type, _nal_name (nalu.type), nalu.size);
+      *skipsize = nalu.size;
+      goto skip;
+    }
+
+    /* Do not push immediatly if we don't have all headers. This ensure that
+     * our caps are complete, avoiding a renegotiation */
+    if (h265parse->align == GST_H265_PARSE_ALIGN_NAL &&
+        !GST_H265_PARSE_STATE_VALID (h265parse,
+            GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS))
+      frame->flags |= GST_BASE_PARSE_FRAME_FLAG_QUEUE;
+
+    if (nonext) {
+      /* If there is a marker flag, or input is AU, we know this is complete */
+      if (GST_BUFFER_FLAG_IS_SET (frame->buffer, GST_BUFFER_FLAG_MARKER) ||
+          h265parse->in_align == GST_H265_PARSE_ALIGN_AU) {
+        h265parse->marker = TRUE;
+        break;
+      }
+
+      /* or if we are draining or producing NALs */
+      if (drain || h265parse->align == GST_H265_PARSE_ALIGN_NAL)
+        break;
+
+      current_off = nalu.offset + nalu.size;
+      goto more;
+    }
+
+    /* If the output is NAL, we are done */
+    if (h265parse->align == GST_H265_PARSE_ALIGN_NAL)
+      break;
+
+    GST_DEBUG_OBJECT (h265parse, "Looking for more");
+    current_off = nalu.offset + nalu.size;
+
+    /* expect at least 3 bytes start_code, and 2 bytes NALU header.
+     * the length of the NALU payload can be zero.
+     * (e.g. EOS/EOB placed at the end of an AU.) */
+    if (G_UNLIKELY (size - current_off < 5)) {
+      /* Finish the frame if there is no more data in the stream */
+      if (drain)
+        break;
+
+      goto more;
+    }
+  }
+
+end:
+  framesize = nalu.offset + nalu.size;
+
+  gst_buffer_unmap (buffer, &map);
+
+  gst_h265_parse2_parse_frame (parse, frame);
+
+  return gst_base_parse_finish_frame (parse, frame, framesize);
+
+more:
+  *skipsize = 0;
+
+  /* Restart parsing from here next time */
+  if (current_off > 0)
+    h265parse->current_off = current_off;
+
+  /* Fall-through. */
+out:
+  gst_buffer_unmap (buffer, &map);
+  return GST_FLOW_OK;
+
+skip:
+  GST_DEBUG_OBJECT (h265parse, "skipping %d", *skipsize);
+  /* If we are collecting access units, we need to preserve the initial
+   * config headers (SPS, PPS et al.) and only reset the frame if another
+   * slice NAL was received. This means that broken pictures are discarded */
+  if (h265parse->align != GST_H265_PARSE_ALIGN_AU ||
+      !(h265parse->state & GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS) ||
+      (h265parse->state & GST_H265_PARSE_STATE_GOT_SLICE))
+    gst_h265_parse2_reset_frame (h265parse);
+  goto out;
+
+invalid_stream:
+  gst_buffer_unmap (buffer, &map);
+  return GST_FLOW_ERROR;
+}
+
+/* byte together hevc codec data based on collected pps and sps so far */
+static GstBuffer *
+gst_h265_parse2_make_codec_data (GstH265Parse2 * h265parse)
+{
+  GstBuffer *buf, *nal;
+  gint i, j, k = 0;
+  guint vps_size = 0, sps_size = 0, pps_size = 0;
+  guint num_vps = 0, num_sps = 0, num_pps = 0;
+  gboolean found = FALSE;
+  GstMapInfo map;
+  guint8 *data;
+  gint nl;
+  guint8 num_arrays = 0;
+  GstH265SPS *sps = NULL;
+  guint16 min_spatial_segmentation_idc = 0;
+  GstH265ProfileTierLevel *pft;
+
+  /* only nal payload in stored nals */
+  /* Fixme: Current implementation is not embedding SEI in codec_data */
+  for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++) {
+    if ((nal = h265parse->vps_nals[i])) {
+      num_vps++;
+      /* size bytes also count */
+      vps_size += gst_buffer_get_size (nal) + 2;
+    }
+  }
+  if (num_vps > 0)
+    num_arrays++;
+
+  for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++) {
+    if ((nal = h265parse->sps_nals[i])) {
+      num_sps++;
+      /* size bytes also count */
+      sps_size += gst_buffer_get_size (nal) + 2;
+      found = TRUE;
+    }
+  }
+  if (num_sps > 0)
+    num_arrays++;
+
+  for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++) {
+    if ((nal = h265parse->pps_nals[i])) {
+      num_pps++;
+      /* size bytes also count */
+      pps_size += gst_buffer_get_size (nal) + 2;
+    }
+  }
+  if (num_pps > 0)
+    num_arrays++;
+
+  GST_DEBUG_OBJECT (h265parse,
+      "constructing codec_data: num_vps =%d num_sps=%d, num_pps=%d", num_vps,
+      num_sps, num_pps);
+
+  if (!found)
+    return NULL;
+
+  sps = h265parse->nalparser->last_sps;
+  if (!sps)
+    return NULL;
+
+  buf =
+      gst_buffer_new_allocate (NULL,
+      23 + (3 * num_arrays) + vps_size + sps_size + pps_size, NULL);
+  gst_buffer_map (buf, &map, GST_MAP_WRITE);
+  data = map.data;
+  memset (data, 0, map.size);
+  nl = h265parse->nal_length_size;
+
+  pft = &sps->profile_tier_level;
+  if (sps->vui_parameters_present_flag)
+    min_spatial_segmentation_idc = sps->vui_params.min_spatial_segmentation_idc;
+
+  /* HEVCDecoderConfigurationVersion = 1
+   * profile_space | tier_flat | profile_idc |
+   * profile_compatibility_flags | constraint_indicator_flags |
+   * level_idc */
+  data[0] = 1;
+  data[1] =
+      (pft->profile_space << 5) | (pft->tier_flag << 5) | pft->profile_idc;
+  for (i = 2; i < 6; i++) {
+    for (j = 7; j >= 0; j--) {
+      data[i] |= (pft->profile_compatibility_flag[k] << j);
+      k++;
+    }
+  }
+
+  data[6] =
+      (pft->progressive_source_flag << 7) |
+      (pft->interlaced_source_flag << 6) |
+      (pft->non_packed_constraint_flag << 5) |
+      (pft->frame_only_constraint_flag << 4) |
+      (pft->max_12bit_constraint_flag << 3) |
+      (pft->max_10bit_constraint_flag << 2) |
+      (pft->max_8bit_constraint_flag << 1) |
+      (pft->max_422chroma_constraint_flag);
+
+  data[7] =
+      (pft->max_420chroma_constraint_flag << 7) |
+      (pft->max_monochrome_constraint_flag << 6) |
+      (pft->intra_constraint_flag << 5) |
+      (pft->one_picture_only_constraint_flag << 4) |
+      (pft->lower_bit_rate_constraint_flag << 3) |
+      (pft->max_14bit_constraint_flag << 2);
+
+  data[12] = pft->level_idc;
+  /* min_spatial_segmentation_idc */
+  GST_WRITE_UINT16_BE (data + 13, min_spatial_segmentation_idc);
+  data[13] |= 0xf0;
+  data[15] = 0xfc;              /* keeping parrallelismType as zero (unknown) */
+  data[16] = 0xfc | sps->chroma_format_idc;
+  data[17] = 0xf8 | sps->bit_depth_luma_minus8;
+  data[18] = 0xf8 | sps->bit_depth_chroma_minus8;
+  data[19] = 0x00;              /* keep avgFrameRate as unspecified */
+  data[20] = 0x00;              /* keep avgFrameRate as unspecified */
+  /* constFrameRate(2 bits): 0, stream may or may not be of constant framerate
+   * numTemporalLayers (3 bits): number of temporal layers, value from SPS
+   * TemporalIdNested (1 bit): sps_temporal_id_nesting_flag from SPS
+   * lengthSizeMinusOne (2 bits): plus 1 indicates the length of the NALUnitLength */
+  data[21] =
+      0x00 | ((sps->max_sub_layers_minus1 +
+          1) << 3) | (sps->temporal_id_nesting_flag << 2) | (nl - 1);
+  GST_WRITE_UINT8 (data + 22, num_arrays);      /* numOfArrays */
+
+  data += 23;
+
+  /* VPS */
+  if (num_vps > 0) {
+    /* array_completeness | reserved_zero bit | nal_unit_type */
+    data[0] = 0x00 | 0x20;
+    data++;
+
+    GST_WRITE_UINT16_BE (data, num_vps);
+    data += 2;
+
+    for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++) {
+      if ((nal = h265parse->vps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (nal);
+        GST_WRITE_UINT16_BE (data, nal_size);
+        gst_buffer_extract (nal, 0, data + 2, nal_size);
+        data += 2 + nal_size;
+      }
+    }
+  }
+
+  /* SPS */
+  if (num_sps > 0) {
+    /* array_completeness | reserved_zero bit | nal_unit_type */
+    data[0] = 0x00 | 0x21;
+    data++;
+
+    GST_WRITE_UINT16_BE (data, num_sps);
+    data += 2;
+
+    for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++) {
+      if ((nal = h265parse->sps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (nal);
+        GST_WRITE_UINT16_BE (data, nal_size);
+        gst_buffer_extract (nal, 0, data + 2, nal_size);
+        data += 2 + nal_size;
+      }
+    }
+  }
+
+  /* PPS */
+  if (num_pps > 0) {
+    /* array_completeness | reserved_zero bit | nal_unit_type */
+    data[0] = 0x00 | 0x22;
+    data++;
+
+    GST_WRITE_UINT16_BE (data, num_pps);
+    data += 2;
+
+    for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++) {
+      if ((nal = h265parse->pps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (nal);
+        GST_WRITE_UINT16_BE (data, nal_size);
+        gst_buffer_extract (nal, 0, data + 2, nal_size);
+        data += 2 + nal_size;
+      }
+    }
+  }
+  gst_buffer_unmap (buf, &map);
+
+  return buf;
+}
+
+static void
+gst_h265_parse2_get_par (GstH265Parse2 * h265parse, gint * num, gint * den)
+{
+  if (h265parse->upstream_par_n != -1 && h265parse->upstream_par_d != -1) {
+    *num = h265parse->upstream_par_n;
+    *den = h265parse->upstream_par_d;
+  } else {
+    *num = h265parse->parsed_par_n;
+    *den = h265parse->parsed_par_d;
+  }
+}
+
+static const gchar *
+digit_to_string (guint digit)
+{
+  static const char itoa[][2] = {
+    "0", "1", "2", "3", "4", "5", "6", "7", "8", "9"
+  };
+
+  if (G_LIKELY (digit < 10))
+    return itoa[digit];
+  else
+    return NULL;
+}
+
+static const gchar *
+get_tier_string (guint8 tier_flag)
+{
+  const gchar *tier = NULL;
+
+  if (tier_flag)
+    tier = "high";
+  else
+    tier = "main";
+
+  return tier;
+}
+
+static const gchar *
+get_level_string (guint8 level_idc)
+{
+  if (level_idc == 0)
+    return NULL;
+  else if (level_idc % 30 == 0)
+    return digit_to_string (level_idc / 30);
+  else {
+    switch (level_idc) {
+      case 63:
+        return "2.1";
+        break;
+      case 93:
+        return "3.1";
+        break;
+      case 123:
+        return "4.1";
+        break;
+      case 153:
+        return "5.1";
+        break;
+      case 156:
+        return "5.2";
+        break;
+      case 183:
+        return "6.1";
+        break;
+      case 186:
+        return "6.2";
+        break;
+      default:
+        return NULL;
+    }
+  }
+}
+
+static inline guint64
+profile_to_flag (GstH265Profile p)
+{
+  return (guint64) 1 << (guint64) p;
+}
+
+static GstCaps *
+get_compatible_profile_caps (GstH265SPS * sps, GstH265Profile profile)
+{
+  GstCaps *caps = NULL;
+  gint i;
+  GValue compat_profiles = G_VALUE_INIT;
+  guint64 profiles = 0;
+
+  g_value_init (&compat_profiles, GST_TYPE_LIST);
+
+  /* Relaxing profiles condition based on decoder capability specified by spec */
+  if (sps->profile_tier_level.profile_compatibility_flag[1])
+    profiles |= profile_to_flag (GST_H265_PROFILE_MAIN);
+
+  if (sps->profile_tier_level.profile_compatibility_flag[2])
+    profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+  if (sps->profile_tier_level.profile_compatibility_flag[3])
+    profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_STILL_PICTURE);
+
+  switch (profile) {
+    case GST_H265_PROFILE_MAIN_10:
+    {
+      /* A.3.5 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+
+      /* H.11.1.1 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN:
+    {
+      /* A.3.3 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+      /* A.3.5 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+
+      /* G.11.1.1 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MULTIVIEW_MAIN);
+
+      /* H.11.1.1 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+
+      /* I.11.1.1 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_3D_MAIN);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_STILL_PICTURE:
+    {
+      /* A.3.2, A.3.4 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+      /* A.3.5 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_16_INTRA);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_STILL_PICTURE);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_16_STILL_PICTURE);
+
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+      break;
+    }
+    case GST_H265_PROFILE_MONOCHROME:
+    {
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_444:
+    {
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_444_10:
+    {
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    }
+    case GST_H265_PROFILE_HIGH_THROUGHPUT_444:
+    {
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+      break;
+    }
+    case GST_H265_PROFILE_HIGH_THROUGHPUT_444_10:
+    {
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+      break;
+    }
+    case GST_H265_PROFILE_HIGH_THROUGHPUT_444_14:
+    {
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag
+          (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+      break;
+    }
+      /* All the -intra profiles can map to non-intra profiles, except
+         the monochrome case for main and main-10. */
+    case GST_H265_PROFILE_MAIN_INTRA:
+    {
+      if (sps->chroma_format_idc == 1) {
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN);
+
+        /* Add all main compatible profiles without monochrome. */
+        /* A.3.3 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+        /* A.3.5 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+        /* A.3.7 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN);
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_10);
+        profiles |=
+            profile_to_flag
+            (GST_H265_PROFILE_SCREEN_EXTENDED_HIGH_THROUGHPUT_444_14);
+
+        /* G.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MULTIVIEW_MAIN);
+
+        /* H.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN);
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+
+        /* I.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_3D_MAIN);
+      }
+
+      /* Add all main compatible profiles with monochrome. */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_10_INTRA:
+    {
+      if (sps->chroma_format_idc == 1) {
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_10);
+
+        /* Add all main-10 compatible profiles without monochrome. */
+        /* A.3.5 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+        profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+
+        /* A.3.7 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_10);
+
+        /* H.11.1.1 */
+        profiles |= profile_to_flag (GST_H265_PROFILE_SCALABLE_MAIN_10);
+      }
+
+      /* Add all main-10 compatible profiles with monochrome. */
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      break;
+    }
+    case GST_H265_PROFILE_MAIN_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_12);
+      break;
+    case GST_H265_PROFILE_MAIN_422_10_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_10);
+      break;
+    case GST_H265_PROFILE_MAIN_422_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_422_12);
+      break;
+    case GST_H265_PROFILE_MAIN_444_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444);
+
+      /* Add all main444 compatible profiles. */
+      /* A.3.7 */
+      profiles |= profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444);
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    case GST_H265_PROFILE_MAIN_444_10_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_10);
+
+      /* Add all main444-10 compatible profiles. */
+      /* A.3.7 */
+      profiles |=
+          profile_to_flag (GST_H265_PROFILE_SCREEN_EXTENDED_MAIN_444_10);
+      break;
+    case GST_H265_PROFILE_MAIN_444_12_INTRA:
+      profiles |= profile_to_flag (GST_H265_PROFILE_MAIN_444_12);
+      break;
+    default:
+      break;
+  }
+
+  if (profiles) {
+    GValue value = G_VALUE_INIT;
+    const gchar *profile_str;
+    caps = gst_caps_new_empty_simple ("video/x-h265");
+
+    for (i = GST_H265_PROFILE_MAIN; i < GST_H265_PROFILE_MAX; i++) {
+      if ((profiles & profile_to_flag (i)) == profile_to_flag (i)) {
+        profile_str = gst_h265_profile_to_string (i);
+
+        if (G_UNLIKELY (profile_str == NULL)) {
+          GST_FIXME ("Unhandled profile index %d", i);
+          continue;
+        }
+
+        g_value_init (&value, G_TYPE_STRING);
+        g_value_set_string (&value, profile_str);
+        gst_value_list_append_value (&compat_profiles, &value);
+        g_value_unset (&value);
+      }
+    }
+
+    gst_caps_set_value (caps, "profile", &compat_profiles);
+    g_value_unset (&compat_profiles);
+  }
+
+  return caps;
+}
+
+static void
+fix_invalid_profile (GstH265Parse2 * h265parse, GstCaps * caps, GstH265SPS * sps)
+{
+  /* HACK: This is a work-around to identify some main profile streams
+   * having wrong profile_idc. There are some wrongly encoded main profile
+   * streams which doesn't have any of the profile_idc values mentioned in
+   * Annex-A. Just assuming them as MAIN profile for now if they meet the
+   * A.3.2 requirement. */
+  if (sps->chroma_format_idc == 1 && sps->bit_depth_luma_minus8 == 0 &&
+      sps->bit_depth_chroma_minus8 == 0 && sps->sps_extension_flag == 0) {
+    gst_caps_set_simple (caps, "profile", G_TYPE_STRING, "main", NULL);
+    GST_WARNING_OBJECT (h265parse,
+        "Wrong profile_idc = 0, setting it as main profile !!");
+  }
+}
+
+/* if downstream didn't support the exact profile indicated in sps header,
+ * check for the compatible profiles also */
+static void
+ensure_caps_profile (GstH265Parse2 * h265parse, GstCaps * caps, GstH265SPS * sps,
+    GstH265Profile profile)
+{
+  GstCaps *peer_caps, *compat_caps;
+
+  if (profile == GST_H265_PROFILE_INVALID)
+    fix_invalid_profile (h265parse, caps, sps);
+
+  peer_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (h265parse));
+  if (!peer_caps || !gst_caps_can_intersect (caps, peer_caps)) {
+    GstCaps *filter_caps = gst_caps_new_empty_simple ("video/x-h265");
+
+    if (peer_caps)
+      gst_caps_unref (peer_caps);
+    peer_caps =
+        gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (h265parse),
+        filter_caps);
+
+    gst_caps_unref (filter_caps);
+  }
+
+  if (peer_caps && !gst_caps_can_intersect (caps, peer_caps)) {
+    GstStructure *structure;
+
+    compat_caps = get_compatible_profile_caps (sps, profile);
+    if (compat_caps != NULL) {
+      GstCaps *res_caps = NULL;
+
+      res_caps = gst_caps_intersect (peer_caps, compat_caps);
+
+      if (res_caps && !gst_caps_is_empty (res_caps)) {
+        const gchar *profile_str = NULL;
+
+        res_caps = gst_caps_fixate (res_caps);
+        structure = gst_caps_get_structure (res_caps, 0);
+        profile_str = gst_structure_get_string (structure, "profile");
+        if (profile_str) {
+          gst_caps_set_simple (caps, "profile", G_TYPE_STRING, profile_str,
+              NULL);
+          GST_DEBUG_OBJECT (h265parse,
+              "Setting compatible profile %s to the caps", profile_str);
+        }
+      }
+      if (res_caps)
+        gst_caps_unref (res_caps);
+      gst_caps_unref (compat_caps);
+    }
+  }
+  if (peer_caps)
+    gst_caps_unref (peer_caps);
+}
+
+static gboolean
+gst_h265_parse2_is_field_interlaced (GstH265Parse2 * h265parse)
+{
+  /* FIXME: The SEI is optional, so theoretically there could be files with
+   * the interlaced_source_flag set to TRUE but no SEI present, or SEI present
+   * but no pic_struct. Haven't seen any such files in practice, and we don't
+   * know how to interpret the data without the pic_struct, so we'll treat
+   * them as progressive */
+
+  switch (h265parse->sei_pic_struct) {
+    case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+      return TRUE;
+      break;
+    default:
+      break;
+  }
+
+  return FALSE;
+}
+
+static void
+gst_h265_parse2_update_src_caps (GstH265Parse2 * h265parse, GstCaps * caps)
+{
+  GstH265SPS *sps = NULL;
+  GstCaps *sink_caps, *src_caps;
+  gboolean modified = FALSE;
+  GstBuffer *buf = NULL;
+  GstStructure *s = NULL;
+
+  if (G_UNLIKELY (!gst_pad_has_current_caps (GST_BASE_PARSE_SRC_PAD
+              (h265parse))))
+    modified = TRUE;
+  else if (G_UNLIKELY (!h265parse->update_caps))
+    return;
+
+  /* if this is being called from the first _setcaps call, caps on the sinkpad
+   * aren't set yet and so they need to be passed as an argument */
+  if (caps)
+    sink_caps = gst_caps_ref (caps);
+  else
+    sink_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (h265parse));
+
+  /* carry over input caps as much as possible; override with our own stuff */
+  if (!sink_caps)
+    sink_caps = gst_caps_new_empty_simple ("video/x-h265");
+  else
+    s = gst_caps_get_structure (sink_caps, 0);
+
+  sps = h265parse->nalparser->last_sps;
+  GST_DEBUG_OBJECT (h265parse, "sps: %p", sps);
+
+  /* only codec-data for nice-and-clean au aligned packetized hevc format */
+  if ((h265parse->format == GST_H265_PARSE_FORMAT_HVC1
+          || h265parse->format == GST_H265_PARSE_FORMAT_HEV1)
+      && h265parse->align == GST_H265_PARSE_ALIGN_AU) {
+    buf = gst_h265_parse2_make_codec_data (h265parse);
+    if (buf && h265parse->codec_data) {
+      GstMapInfo map;
+
+      gst_buffer_map (buf, &map, GST_MAP_READ);
+      if (map.size != gst_buffer_get_size (h265parse->codec_data) ||
+          gst_buffer_memcmp (h265parse->codec_data, 0, map.data, map.size))
+        modified = TRUE;
+
+      gst_buffer_unmap (buf, &map);
+    } else {
+      if (!buf && h265parse->codec_data_in)
+        buf = gst_buffer_ref (h265parse->codec_data_in);
+      modified = TRUE;
+    }
+  }
+
+  caps = NULL;
+  if (G_UNLIKELY (!sps)) {
+    caps = gst_caps_copy (sink_caps);
+  } else {
+    gint crop_width, crop_height;
+    const gchar *chroma_format = NULL;
+    guint bit_depth_chroma;
+    GstH265VPS *vps = sps->vps;
+    GstH265VUIParams *vui = &sps->vui_params;
+    gchar *colorimetry = NULL;
+
+    GST_DEBUG_OBJECT (h265parse, "vps: %p", vps);
+
+    if (sps->conformance_window_flag) {
+      crop_width = sps->crop_rect_width;
+      crop_height = sps->crop_rect_height;
+    } else {
+      crop_width = sps->width;
+      crop_height = sps->height;
+    }
+    if (gst_h265_parse2_is_field_interlaced (h265parse)) {
+      crop_height *= 2;
+    }
+
+    if (G_UNLIKELY (h265parse->width != crop_width ||
+            h265parse->height != crop_height)) {
+      h265parse->width = crop_width;
+      h265parse->height = crop_height;
+      GST_INFO_OBJECT (h265parse, "resolution changed %dx%d",
+          h265parse->width, h265parse->height);
+      modified = TRUE;
+    }
+
+    /* 0/1 is set as the default in the codec parser */
+    if (vui->timing_info_present_flag) {
+      gint fps_num = 0, fps_den = 1;
+
+      if (!(sps->fps_num == 0 && sps->fps_den == 1)) {
+        fps_num = sps->fps_num;
+        fps_den = sps->fps_den;
+      } else if (!(sps->vui_params.time_scale == 0 &&
+              sps->vui_params.num_units_in_tick == 1)) {
+        fps_num = sps->vui_params.time_scale;
+        fps_den = sps->vui_params.num_units_in_tick;
+
+        if (gst_h265_parse2_is_field_interlaced (h265parse)
+            && h265parse->parsed_framerate) {
+          gint new_fps_num, new_fps_den;
+
+          gst_util_fraction_multiply (fps_num, fps_den, 1, 2, &new_fps_num,
+              &new_fps_den);
+          fps_num = new_fps_num;
+          fps_den = new_fps_den;
+          h265parse->parsed_framerate = FALSE;
+        }
+      }
+
+      if (G_UNLIKELY (h265parse->fps_num != fps_num
+              || h265parse->fps_den != fps_den)) {
+        GST_INFO_OBJECT (h265parse, "framerate changed %d/%d",
+            fps_num, fps_den);
+        h265parse->fps_num = fps_num;
+        h265parse->fps_den = fps_den;
+        modified = TRUE;
+      }
+    }
+
+    if (vui->aspect_ratio_info_present_flag) {
+      if (G_UNLIKELY ((h265parse->parsed_par_n != vui->par_n)
+              && (h265parse->parsed_par_d != sps->vui_params.par_d))) {
+        h265parse->parsed_par_n = vui->par_n;
+        h265parse->parsed_par_d = vui->par_d;
+        GST_INFO_OBJECT (h265parse, "pixel aspect ratio has been changed %d/%d",
+            h265parse->parsed_par_n, h265parse->parsed_par_d);
+        modified = TRUE;
+      }
+
+    }
+
+    if (vui->video_signal_type_present_flag &&
+        vui->colour_description_present_flag) {
+      GstVideoColorimetry ci = { 0, };
+      gchar *old_colorimetry = NULL;
+
+      if (vui->video_full_range_flag)
+        ci.range = GST_VIDEO_COLOR_RANGE_0_255;
+      else
+        ci.range = GST_VIDEO_COLOR_RANGE_16_235;
+
+      ci.matrix = gst_video_color_matrix_from_iso (vui->matrix_coefficients);
+      ci.transfer =
+          gst_video_transfer_function_from_iso (vui->transfer_characteristics);
+      ci.primaries = gst_video_color_primaries_from_iso (vui->colour_primaries);
+
+      old_colorimetry =
+          gst_video_colorimetry_to_string (&h265parse->parsed_colorimetry);
+      colorimetry = gst_video_colorimetry_to_string (&ci);
+
+      if (colorimetry && g_strcmp0 (old_colorimetry, colorimetry)) {
+        GST_INFO_OBJECT (h265parse,
+            "colorimetry has been changed from %s to %s",
+            GST_STR_NULL (old_colorimetry), colorimetry);
+        h265parse->parsed_colorimetry = ci;
+        modified = TRUE;
+      }
+
+      g_free (old_colorimetry);
+    }
+
+    if (G_UNLIKELY (modified || h265parse->update_caps)) {
+      gint fps_num = h265parse->fps_num;
+      gint fps_den = h265parse->fps_den;
+      gint width, height;
+      GstClockTime latency = 0;
+
+      caps = gst_caps_copy (sink_caps);
+
+      /* sps should give this but upstream overrides */
+      if (s && gst_structure_has_field (s, "width"))
+        gst_structure_get_int (s, "width", &width);
+      else
+        width = h265parse->width;
+
+      if (s && gst_structure_has_field (s, "height"))
+        gst_structure_get_int (s, "height", &height);
+      else
+        height = h265parse->height;
+
+      gst_caps_set_simple (caps, "width", G_TYPE_INT, width,
+          "height", G_TYPE_INT, height, NULL);
+
+      h265parse->parsed_framerate = FALSE;
+      /* upstream overrides */
+      if (s && gst_structure_has_field (s, "framerate"))
+        gst_structure_get_fraction (s, "framerate", &fps_num, &fps_den);
+
+      /* but not necessarily or reliably this */
+      if (fps_den > 0) {
+        GstStructure *s2;
+        GstClockTime val;
+
+        GST_INFO_OBJECT (h265parse, "setting framerate in caps");
+        gst_caps_set_simple (caps, "framerate",
+            GST_TYPE_FRACTION, fps_num, fps_den, NULL);
+        s2 = gst_caps_get_structure (caps, 0);
+        gst_structure_get_fraction (s2, "framerate", &h265parse->parsed_fps_n,
+            &h265parse->parsed_fps_d);
+        gst_base_parse_set_frame_rate (GST_BASE_PARSE (h265parse),
+            fps_num, fps_den, 0, 0);
+        val = sps->profile_tier_level.interlaced_source_flag ? GST_SECOND / 2 :
+            GST_SECOND;
+        h265parse->parsed_framerate = TRUE;
+
+        /* If we know the frame duration, and if we are not in one of the zero
+         * latency pattern, add one frame of latency */
+        if (fps_num > 0 &&
+            h265parse->in_align != GST_H265_PARSE_ALIGN_AU &&
+            !(h265parse->in_align == GST_H265_PARSE_ALIGN_NAL &&
+                h265parse->align == GST_H265_PARSE_ALIGN_NAL))
+          latency = gst_util_uint64_scale (val, fps_den, fps_num);
+
+        gst_base_parse_set_latency (GST_BASE_PARSE (h265parse), latency,
+            latency);
+      }
+
+      bit_depth_chroma = sps->bit_depth_chroma_minus8 + 8;
+
+      switch (sps->chroma_format_idc) {
+        case 0:
+          chroma_format = "4:0:0";
+          bit_depth_chroma = 0;
+          break;
+        case 1:
+          chroma_format = "4:2:0";
+          break;
+        case 2:
+          chroma_format = "4:2:2";
+          break;
+        case 3:
+          chroma_format = "4:4:4";
+          break;
+        default:
+          break;
+      }
+
+      if (chroma_format)
+        gst_caps_set_simple (caps, "chroma-format", G_TYPE_STRING,
+            chroma_format, "bit-depth-luma", G_TYPE_UINT,
+            sps->bit_depth_luma_minus8 + 8, "bit-depth-chroma", G_TYPE_UINT,
+            bit_depth_chroma, NULL);
+
+      if (colorimetry && (!s || !gst_structure_has_field (s, "colorimetry"))) {
+        gst_caps_set_simple (caps, "colorimetry", G_TYPE_STRING, colorimetry,
+            NULL);
+      }
+    }
+
+    g_free (colorimetry);
+  }
+
+  if (caps) {
+    gint par_n, par_d;
+    const gchar *mdi_str = NULL;
+    const gchar *cll_str = NULL;
+    gboolean codec_data_modified = FALSE;
+
+    gst_caps_set_simple (caps, "parsed", G_TYPE_BOOLEAN, TRUE,
+        "stream-format", G_TYPE_STRING,
+        gst_h265_parse2_get_string (h265parse, TRUE, h265parse->format),
+        "alignment", G_TYPE_STRING,
+        gst_h265_parse2_get_string (h265parse, FALSE, h265parse->align), NULL);
+
+    gst_h265_parse2_get_par (h265parse, &par_n, &par_d);
+    if (par_n != 0 && par_d != 0 &&
+        (!s || !gst_structure_has_field (s, "pixel-aspect-ratio"))) {
+      GST_INFO_OBJECT (h265parse, "PAR %d/%d", par_n, par_d);
+      gst_caps_set_simple (caps, "pixel-aspect-ratio", GST_TYPE_FRACTION,
+          par_n, par_d, NULL);
+    }
+
+    /* set profile and level in caps */
+    if (sps) {
+      const gchar *profile, *tier, *level;
+      GstH265Profile p;
+
+      p = gst_h265_get_profile_from_sps (sps);
+      profile = gst_h265_profile_to_string (p);
+
+      if (s && gst_structure_has_field (s, "profile")) {
+        const gchar *profile_sink = gst_structure_get_string (s, "profile");
+        GstH265Profile p_sink = gst_h265_profile_from_string (profile_sink);
+
+        if (p != p_sink) {
+          const gchar *profile_src;
+
+          p = MAX (p, p_sink);
+          profile_src = (p == p_sink) ? profile_sink : profile;
+          GST_INFO_OBJECT (h265parse,
+              "Upstream profile (%s) is different than in SPS (%s). "
+              "Using %s.", profile_sink, profile, profile_src);
+          profile = profile_src;
+        }
+      }
+
+      if (profile != NULL)
+        gst_caps_set_simple (caps, "profile", G_TYPE_STRING, profile, NULL);
+
+      tier = get_tier_string (sps->profile_tier_level.tier_flag);
+      if (tier != NULL)
+        gst_caps_set_simple (caps, "tier", G_TYPE_STRING, tier, NULL);
+
+      level = get_level_string (sps->profile_tier_level.level_idc);
+      if (level != NULL)
+        gst_caps_set_simple (caps, "level", G_TYPE_STRING, level, NULL);
+
+      /* relax the profile constraint to find a suitable decoder */
+      ensure_caps_profile (h265parse, caps, sps, p);
+    }
+
+    if (s)
+      mdi_str = gst_structure_get_string (s, "mastering-display-info");
+    if (mdi_str) {
+      gst_caps_set_simple (caps, "mastering-display-info", G_TYPE_STRING,
+          mdi_str, NULL);
+    } else if (h265parse->mastering_display_info_state !=
+        GST_H265_PARSE_SEI_EXPIRED &&
+        !gst_video_mastering_display_info_add_to_caps
+        (&h265parse->mastering_display_info, caps)) {
+      GST_WARNING_OBJECT (h265parse,
+          "Couldn't set mastering display info to caps");
+    }
+
+    if (s)
+      cll_str = gst_structure_get_string (s, "content-light-level");
+    if (cll_str) {
+      gst_caps_set_simple (caps, "content-light-level", G_TYPE_STRING, cll_str,
+          NULL);
+    } else if (h265parse->content_light_level_state !=
+        GST_H265_PARSE_SEI_EXPIRED &&
+        !gst_video_content_light_level_add_to_caps
+        (&h265parse->content_light_level, caps)) {
+      GST_WARNING_OBJECT (h265parse,
+          "Couldn't set content light level to caps");
+    }
+
+    src_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (h265parse));
+
+    if (src_caps) {
+      GstStructure *src_caps_str = gst_caps_get_structure (src_caps, 0);
+
+      /* use codec data from old caps for comparison if we have pushed frame for now.
+       * we don't want to resend caps if everything is same except codec data.
+       * However, if the updated sps/pps is not in bitstream, we should put
+       * it on bitstream */
+      if (gst_structure_has_field (src_caps_str, "codec_data")) {
+        const GValue *codec_data_value =
+            gst_structure_get_value (src_caps_str, "codec_data");
+
+        if (!GST_VALUE_HOLDS_BUFFER (codec_data_value)) {
+          GST_WARNING_OBJECT (h265parse, "codec_data does not hold buffer");
+        } else if (!h265parse->first_frame) {
+          /* If there is no pushed frame before, we can update caps without worry.
+           * But updating codec_data in the middle of frames
+           * (especially on non-keyframe) might make downstream be confused.
+           * Therefore we are setting old codec data
+           * (i.e., was pushed to downstream previously) to new caps candidate
+           * here for gst_caps_is_strictly_equal() to be returned TRUE if only
+           * the codec_data is different, and to avoid re-sending caps it
+           * that case.
+           */
+          gst_caps_set_value (caps, "codec_data", codec_data_value);
+
+          /* check for codec_data update to re-send sps/pps inband data if
+           * current frame has no sps/pps but upstream codec_data was updated.
+           * Note that have_vps_in_frame is skipped here since it's optional  */
+          if ((!h265parse->have_sps_in_frame || !h265parse->have_pps_in_frame)
+              && buf) {
+            GstBuffer *codec_data_buf = gst_value_get_buffer (codec_data_value);
+            GstMapInfo map;
+
+            gst_buffer_map (buf, &map, GST_MAP_READ);
+            if (map.size != gst_buffer_get_size (codec_data_buf) ||
+                gst_buffer_memcmp (codec_data_buf, 0, map.data, map.size)) {
+              codec_data_modified = TRUE;
+            }
+
+            gst_buffer_unmap (buf, &map);
+          }
+        }
+      } else if (!buf) {
+        GstStructure *s;
+        /* remove any left-over codec-data hanging around */
+        s = gst_caps_get_structure (caps, 0);
+        gst_structure_remove_field (s, "codec_data");
+      }
+    }
+
+    if (!(src_caps && gst_caps_is_strictly_equal (src_caps, caps))) {
+      /* update codec data to new value */
+      if (buf) {
+        gst_caps_set_simple (caps, "codec_data", GST_TYPE_BUFFER, buf, NULL);
+        gst_buffer_replace (&h265parse->codec_data, buf);
+        gst_buffer_unref (buf);
+        buf = NULL;
+      } else {
+        GstStructure *s;
+        /* remove any left-over codec-data hanging around */
+        s = gst_caps_get_structure (caps, 0);
+        gst_structure_remove_field (s, "codec_data");
+        gst_buffer_replace (&h265parse->codec_data, NULL);
+      }
+
+      gst_pad_set_caps (GST_BASE_PARSE_SRC_PAD (h265parse), caps);
+    } else if (codec_data_modified) {
+      GST_DEBUG_OBJECT (h265parse,
+          "Only codec_data is different, need inband vps/sps/pps update");
+
+      /* this will insert updated codec_data with next idr */
+      h265parse->push_codec = TRUE;
+    }
+
+    if (src_caps)
+      gst_caps_unref (src_caps);
+    gst_caps_unref (caps);
+  }
+
+  gst_caps_unref (sink_caps);
+  if (buf)
+    gst_buffer_unref (buf);
+
+}
+
+static GstFlowReturn
+gst_h265_parse2_parse_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
+{
+  GstH265Parse2 *h265parse;
+  GstBuffer *buffer;
+  guint av;
+
+  h265parse = GST_H265_PARSE2 (parse);
+  buffer = frame->buffer;
+
+  gst_h265_parse2_update_src_caps (h265parse, NULL);
+
+  if (h265parse->fps_num > 0 && h265parse->fps_den > 0) {
+    GstClockTime val =
+        gst_h265_parse2_is_field_interlaced (h265parse) ? GST_SECOND /
+        2 : GST_SECOND;
+
+    GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale (val,
+        h265parse->fps_den, h265parse->fps_num);
+  }
+
+  if (h265parse->keyframe)
+    GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_DELTA_UNIT);
+  else
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DELTA_UNIT);
+
+  if (h265parse->discard_bidirectional && h265parse->bidirectional)
+    goto discard;
+
+
+  if (h265parse->header)
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_HEADER);
+  else
+    GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_HEADER);
+
+  if (h265parse->discont) {
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_DISCONT);
+    h265parse->discont = FALSE;
+  }
+
+  if (h265parse->marker) {
+    GST_BUFFER_FLAG_SET (buffer, GST_BUFFER_FLAG_MARKER);
+    h265parse->marker = FALSE;
+  } else {
+    GST_BUFFER_FLAG_UNSET (buffer, GST_BUFFER_FLAG_MARKER);
+  }
+
+  /* replace with transformed HEVC output if applicable */
+  av = gst_adapter_available (h265parse->frame_out);
+  if (av) {
+    GstBuffer *buf;
+
+    buf = gst_adapter_take_buffer (h265parse->frame_out, av);
+    gst_buffer_copy_into (buf, buffer, GST_BUFFER_COPY_METADATA, 0, -1);
+    gst_buffer_replace (&frame->out_buffer, buf);
+    gst_buffer_unref (buf);
+  }
+
+done:
+  return GST_FLOW_OK;
+
+discard:
+  GST_DEBUG_OBJECT (h265parse, "Discarding bidirectional frame");
+  frame->flags |= GST_BASE_PARSE_FRAME_FLAG_DROP;
+  gst_h265_parse2_reset_frame (h265parse);
+  goto done;
+
+}
+
+/* sends a codec NAL downstream, decorating and transforming as needed.
+ * No ownership is taken of @nal */
+static GstFlowReturn
+gst_h265_parse2_push_codec_buffer (GstH265Parse2 * h265parse, GstBuffer * nal,
+    GstBuffer * buffer)
+{
+  GstMapInfo map;
+
+  gst_buffer_map (nal, &map, GST_MAP_READ);
+  nal = gst_h265_parse2_wrap_nal (h265parse, h265parse->format,
+      map.data, map.size);
+  gst_buffer_unmap (nal, &map);
+
+  if (h265parse->discont) {
+    GST_BUFFER_FLAG_SET (nal, GST_BUFFER_FLAG_DISCONT);
+    h265parse->discont = FALSE;
+  }
+
+  GST_BUFFER_PTS (nal) = GST_BUFFER_PTS (buffer);
+  GST_BUFFER_DTS (nal) = GST_BUFFER_DTS (buffer);
+  GST_BUFFER_DURATION (nal) = 0;
+
+  return gst_pad_push (GST_BASE_PARSE_SRC_PAD (h265parse), nal);
+}
+
+static GstEvent *
+check_pending_key_unit_event (GstEvent * pending_event, GstSegment * segment,
+    GstClockTime timestamp, guint flags, GstClockTime pending_key_unit_ts)
+{
+  GstClockTime running_time, stream_time;
+  gboolean all_headers;
+  guint count;
+  GstEvent *event = NULL;
+
+  g_return_val_if_fail (segment != NULL, NULL);
+
+  if (pending_event == NULL)
+    goto out;
+
+  if (GST_CLOCK_TIME_IS_VALID (pending_key_unit_ts) &&
+      timestamp == GST_CLOCK_TIME_NONE)
+    goto out;
+
+  running_time = gst_segment_to_running_time (segment,
+      GST_FORMAT_TIME, timestamp);
+
+  GST_INFO ("now %" GST_TIME_FORMAT " wanted %" GST_TIME_FORMAT,
+      GST_TIME_ARGS (running_time), GST_TIME_ARGS (pending_key_unit_ts));
+  if (GST_CLOCK_TIME_IS_VALID (pending_key_unit_ts) &&
+      running_time < pending_key_unit_ts)
+    goto out;
+
+  if (flags & GST_BUFFER_FLAG_DELTA_UNIT) {
+    GST_DEBUG ("pending force key unit, waiting for keyframe");
+    goto out;
+  }
+
+  stream_time = gst_segment_to_stream_time (segment,
+      GST_FORMAT_TIME, timestamp);
+
+  if (!gst_video_event_parse_upstream_force_key_unit (pending_event,
+          NULL, &all_headers, &count)) {
+    gst_video_event_parse_downstream_force_key_unit (pending_event, NULL,
+        NULL, NULL, &all_headers, &count);
+  }
+
+  event =
+      gst_video_event_new_downstream_force_key_unit (timestamp, stream_time,
+      running_time, all_headers, count);
+  gst_event_set_seqnum (event, gst_event_get_seqnum (pending_event));
+
+out:
+  return event;
+}
+
+static void
+gst_h265_parse2_prepare_key_unit (GstH265Parse2 * parse, GstEvent * event)
+{
+  GstClockTime running_time;
+  guint count;
+#ifndef GST_DISABLE_GST_DEBUG
+  gboolean have_vps, have_sps, have_pps;
+  gint i;
+#endif
+
+  parse->pending_key_unit_ts = GST_CLOCK_TIME_NONE;
+  gst_event_replace (&parse->force_key_unit_event, NULL);
+
+  gst_video_event_parse_downstream_force_key_unit (event,
+      NULL, NULL, &running_time, NULL, &count);
+
+  GST_INFO_OBJECT (parse, "pushing downstream force-key-unit event %d "
+      "%" GST_TIME_FORMAT " count %d", gst_event_get_seqnum (event),
+      GST_TIME_ARGS (running_time), count);
+  gst_pad_push_event (GST_BASE_PARSE_SRC_PAD (parse), event);
+
+#ifndef GST_DISABLE_GST_DEBUG
+  have_vps = have_sps = have_pps = FALSE;
+  for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++) {
+    if (parse->vps_nals[i] != NULL) {
+      have_vps = TRUE;
+      break;
+    }
+  }
+  for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++) {
+    if (parse->sps_nals[i] != NULL) {
+      have_sps = TRUE;
+      break;
+    }
+  }
+  for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++) {
+    if (parse->pps_nals[i] != NULL) {
+      have_pps = TRUE;
+      break;
+    }
+  }
+
+  GST_INFO_OBJECT (parse,
+      "preparing key unit, have vps %d have sps %d have pps %d", have_vps,
+      have_sps, have_pps);
+#endif
+
+  /* set push_codec to TRUE so that pre_push_frame sends VPS/SPS/PPS again */
+  parse->push_codec = TRUE;
+}
+
+static gboolean
+gst_h265_parse2_handle_vps_sps_pps_nals (GstH265Parse2 * h265parse,
+    GstBuffer * buffer, GstBaseParseFrame * frame)
+{
+  GstBuffer *codec_nal;
+  gint i;
+  gboolean send_done = FALSE;
+
+  if (h265parse->have_vps_in_frame && h265parse->have_sps_in_frame
+      && h265parse->have_pps_in_frame) {
+    GST_DEBUG_OBJECT (h265parse, "VPS/SPS/PPS exist in frame, will not insert");
+    return TRUE;
+  }
+
+  if (h265parse->align == GST_H265_PARSE_ALIGN_NAL) {
+    /* send separate config NAL buffers */
+    GST_DEBUG_OBJECT (h265parse, "- sending VPS/SPS/PPS");
+    for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++) {
+      if ((codec_nal = h265parse->vps_nals[i])) {
+        GST_DEBUG_OBJECT (h265parse, "sending VPS nal");
+        gst_h265_parse2_push_codec_buffer (h265parse, codec_nal, buffer);
+        send_done = TRUE;
+      }
+    }
+    for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++) {
+      if ((codec_nal = h265parse->sps_nals[i])) {
+        GST_DEBUG_OBJECT (h265parse, "sending SPS nal");
+        gst_h265_parse2_push_codec_buffer (h265parse, codec_nal, buffer);
+        send_done = TRUE;
+      }
+    }
+    for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++) {
+      if ((codec_nal = h265parse->pps_nals[i])) {
+        GST_DEBUG_OBJECT (h265parse, "sending PPS nal");
+        gst_h265_parse2_push_codec_buffer (h265parse, codec_nal, buffer);
+        send_done = TRUE;
+      }
+    }
+  } else {
+    /* insert config NALs into AU */
+    GstByteWriter bw;
+    GstBuffer *new_buf;
+    const gboolean bs = h265parse->format == GST_H265_PARSE_FORMAT_BYTE;
+    const gint nls = 4 - h265parse->nal_length_size;
+    gboolean ok;
+
+    gst_byte_writer_init_with_size (&bw, gst_buffer_get_size (buffer), FALSE);
+    ok = gst_byte_writer_put_buffer (&bw, buffer, 0, h265parse->idr_pos);
+    GST_DEBUG_OBJECT (h265parse, "- inserting VPS/SPS/PPS");
+    for (i = 0; i < GST_H265_MAX_VPS_COUNT; i++) {
+      if ((codec_nal = h265parse->vps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (codec_nal);
+        GST_DEBUG_OBJECT (h265parse, "inserting VPS nal");
+        if (bs) {
+          ok &= gst_byte_writer_put_uint32_be (&bw, 1);
+        } else {
+          ok &= gst_byte_writer_put_uint32_be (&bw, (nal_size << (nls * 8)));
+          ok &= gst_byte_writer_set_pos (&bw,
+              gst_byte_writer_get_pos (&bw) - nls);
+        }
+
+        ok &= gst_byte_writer_put_buffer (&bw, codec_nal, 0, nal_size);
+        send_done = TRUE;
+      }
+    }
+    for (i = 0; i < GST_H265_MAX_SPS_COUNT; i++) {
+      if ((codec_nal = h265parse->sps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (codec_nal);
+        GST_DEBUG_OBJECT (h265parse, "inserting SPS nal");
+        if (bs) {
+          ok &= gst_byte_writer_put_uint32_be (&bw, 1);
+        } else {
+          ok &= gst_byte_writer_put_uint32_be (&bw, (nal_size << (nls * 8)));
+          ok &= gst_byte_writer_set_pos (&bw,
+              gst_byte_writer_get_pos (&bw) - nls);
+        }
+
+        ok &= gst_byte_writer_put_buffer (&bw, codec_nal, 0, nal_size);
+        send_done = TRUE;
+      }
+    }
+    for (i = 0; i < GST_H265_MAX_PPS_COUNT; i++) {
+      if ((codec_nal = h265parse->pps_nals[i])) {
+        gsize nal_size = gst_buffer_get_size (codec_nal);
+        GST_DEBUG_OBJECT (h265parse, "inserting PPS nal");
+        if (bs) {
+          ok &= gst_byte_writer_put_uint32_be (&bw, 1);
+        } else {
+          ok &= gst_byte_writer_put_uint32_be (&bw, (nal_size << (nls * 8)));
+          ok &= gst_byte_writer_set_pos (&bw,
+              gst_byte_writer_get_pos (&bw) - nls);
+        }
+        ok &= gst_byte_writer_put_buffer (&bw, codec_nal, 0, nal_size);
+        send_done = TRUE;
+      }
+    }
+    ok &= gst_byte_writer_put_buffer (&bw, buffer, h265parse->idr_pos, -1);
+    /* collect result and push */
+    new_buf = gst_byte_writer_reset_and_get_buffer (&bw);
+    gst_buffer_copy_into (new_buf, buffer, GST_BUFFER_COPY_METADATA, 0, -1);
+    /* should already be keyframe/IDR, but it may not have been,
+     * so mark it as such to avoid being discarded by picky decoder */
+    GST_BUFFER_FLAG_UNSET (new_buf, GST_BUFFER_FLAG_DELTA_UNIT);
+    gst_buffer_replace (&frame->out_buffer, new_buf);
+    gst_buffer_unref (new_buf);
+    /* some result checking seems to make some compilers happy */
+    if (G_UNLIKELY (!ok)) {
+      GST_ERROR_OBJECT (h265parse, "failed to insert SPS/PPS");
+    }
+  }
+
+  return send_done;
+}
+
+static GstFlowReturn
+gst_h265_parse2_pre_push_frame (GstBaseParse * parse, GstBaseParseFrame * frame)
+{
+  GstH265Parse2 *h265parse;
+  GstBuffer *buffer;
+  GstEvent *event;
+  GstBuffer *parse_buffer = NULL;
+
+  h265parse = GST_H265_PARSE2 (parse);
+
+  if (h265parse->first_frame) {
+    GstTagList *taglist;
+    GstCaps *caps;
+
+    /* codec tag */
+    caps = gst_pad_get_current_caps (GST_BASE_PARSE_SRC_PAD (parse));
+    if (G_UNLIKELY (caps == NULL)) {
+      if (GST_PAD_IS_FLUSHING (GST_BASE_PARSE_SRC_PAD (parse))) {
+        GST_INFO_OBJECT (parse, "Src pad is flushing");
+        return GST_FLOW_FLUSHING;
+      } else {
+        GST_INFO_OBJECT (parse, "Src pad is not negotiated!");
+        return GST_FLOW_NOT_NEGOTIATED;
+      }
+    }
+
+    taglist = gst_tag_list_new_empty ();
+    gst_pb_utils_add_codec_description_to_tag_list (taglist,
+        GST_TAG_VIDEO_CODEC, caps);
+    gst_caps_unref (caps);
+
+    gst_base_parse_merge_tags (parse, taglist, GST_TAG_MERGE_REPLACE);
+    gst_tag_list_unref (taglist);
+
+    /* also signals the end of first-frame processing */
+    h265parse->first_frame = FALSE;
+  }
+
+  buffer = frame->buffer;
+
+  if ((event = check_pending_key_unit_event (h265parse->force_key_unit_event,
+              &parse->segment, GST_BUFFER_TIMESTAMP (buffer),
+              GST_BUFFER_FLAGS (buffer), h265parse->pending_key_unit_ts))) {
+    gst_h265_parse2_prepare_key_unit (h265parse, event);
+  }
+
+  /* periodic VPS/SPS/PPS sending */
+  if (h265parse->interval > 0 || h265parse->push_codec) {
+    GstClockTime timestamp = GST_BUFFER_TIMESTAMP (buffer);
+    guint64 diff;
+    gboolean initial_frame = FALSE;
+
+    /* init */
+    if (!GST_CLOCK_TIME_IS_VALID (h265parse->last_report)) {
+      h265parse->last_report = timestamp;
+      initial_frame = TRUE;
+    }
+
+    if (h265parse->idr_pos >= 0) {
+      GST_LOG_OBJECT (h265parse, "IDR nal at offset %d", h265parse->idr_pos);
+
+      if (timestamp > h265parse->last_report)
+        diff = timestamp - h265parse->last_report;
+      else
+        diff = 0;
+
+      GST_LOG_OBJECT (h265parse,
+          "now %" GST_TIME_FORMAT ", last VPS/SPS/PPS %" GST_TIME_FORMAT,
+          GST_TIME_ARGS (timestamp), GST_TIME_ARGS (h265parse->last_report));
+
+      GST_DEBUG_OBJECT (h265parse,
+          "interval since last VPS/SPS/PPS %" GST_TIME_FORMAT,
+          GST_TIME_ARGS (diff));
+
+      if (GST_TIME_AS_SECONDS (diff) >= h265parse->interval ||
+          initial_frame || h265parse->push_codec) {
+        GstClockTime new_ts;
+
+        /* avoid overwriting a perfectly fine timestamp */
+        new_ts = GST_CLOCK_TIME_IS_VALID (timestamp) ? timestamp :
+            h265parse->last_report;
+
+        if (gst_h265_parse2_handle_vps_sps_pps_nals (h265parse, buffer, frame)) {
+          h265parse->last_report = new_ts;
+        }
+      }
+
+      /* we pushed whatever we had */
+      h265parse->push_codec = FALSE;
+      h265parse->have_vps = FALSE;
+      h265parse->have_sps = FALSE;
+      h265parse->have_pps = FALSE;
+      h265parse->state &= GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS;
+    }
+  } else if (h265parse->interval == -1) {
+    if (h265parse->idr_pos >= 0) {
+      GST_LOG_OBJECT (h265parse, "IDR nal at offset %d", h265parse->idr_pos);
+
+      gst_h265_parse2_handle_vps_sps_pps_nals (h265parse, buffer, frame);
+
+      /* we pushed whatever we had */
+      h265parse->push_codec = FALSE;
+      h265parse->have_vps = FALSE;
+      h265parse->have_sps = FALSE;
+      h265parse->have_pps = FALSE;
+      h265parse->state &= GST_H265_PARSE_STATE_VALID_PICTURE_HEADERS;
+    }
+  }
+
+  if (frame->out_buffer) {
+    parse_buffer = frame->out_buffer =
+        gst_buffer_make_writable (frame->out_buffer);
+  } else {
+    parse_buffer = frame->buffer = gst_buffer_make_writable (frame->buffer);
+  }
+
+  /* see section D.3.3 of the spec */
+  switch (h265parse->sei_pic_struct) {
+    case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP:
+    case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      break;
+    case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+    case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_TOP_FIELD);
+      break;
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+    case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_INTERLACED);
+      GST_BUFFER_FLAG_SET (parse_buffer, GST_VIDEO_BUFFER_FLAG_BOTTOM_FIELD);
+      break;
+    default:
+      break;
+  }
+
+  {
+    guint i = 0;
+
+    for (i = 0; i < h265parse->time_code.num_clock_ts; i++) {
+      gint field_count = -1;
+      guint n_frames;
+      GstVideoTimeCodeFlags flags = 0;
+
+      if (!h265parse->time_code.clock_timestamp_flag[i])
+        break;
+
+      h265parse->time_code.clock_timestamp_flag[i] = 0;
+
+      /* Table D.2 */
+      switch (h265parse->sei_pic_struct) {
+        case GST_H265_SEI_PIC_STRUCT_FRAME:
+        case GST_H265_SEI_PIC_STRUCT_TOP_FIELD:
+        case GST_H265_SEI_PIC_STRUCT_BOTTOM_FIELD:
+          field_count = h265parse->sei_pic_struct;
+          break;
+        case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM:
+        case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_PREVIOUS_BOTTOM:
+        case GST_H265_SEI_PIC_STRUCT_TOP_PAIRED_NEXT_BOTTOM:
+          field_count = i + 1;
+          break;
+        case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP:
+        case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_PREVIOUS_TOP:
+        case GST_H265_SEI_PIC_STRUCT_BOTTOM_PAIRED_NEXT_TOP:
+          field_count = 2 - i;
+          break;
+        case GST_H265_SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
+          field_count = i % 2 ? 2 : 1;
+          break;
+        case GST_H265_SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
+          field_count = i % 2 ? 1 : 2;
+          break;
+        case GST_H265_SEI_PIC_STRUCT_FRAME_DOUBLING:
+        case GST_H265_SEI_PIC_STRUCT_FRAME_TRIPLING:
+          field_count = 0;
+          break;
+      }
+
+      if (field_count == -1) {
+        GST_WARNING_OBJECT (parse,
+            "failed to determine field count for timecode");
+        field_count = 0;
+      }
+
+      /* Dropping of the two lowest (value 0 and 1) n_frames[ i ] counts when
+       * seconds_value[ i ] is equal to 0 and minutes_value[ i ] is not an integer
+       * multiple of 10 */
+      if (h265parse->time_code.counting_type[i] == 4)
+        flags |= GST_VIDEO_TIME_CODE_FLAGS_DROP_FRAME;
+
+      if (h265parse->sei_pic_struct != GST_H265_SEI_PIC_STRUCT_FRAME)
+        flags |= GST_VIDEO_TIME_CODE_FLAGS_INTERLACED;
+
+      n_frames =
+          gst_util_uint64_scale_int (h265parse->time_code.n_frames[i], 1,
+          2 - h265parse->time_code.units_field_based_flag[i]);
+
+      gst_buffer_add_video_time_code_meta_full (parse_buffer,
+          h265parse->parsed_fps_n,
+          h265parse->parsed_fps_d,
+          NULL,
+          flags,
+          h265parse->time_code.hours_flag[i] ? h265parse->time_code.
+          hours_value[i] : 0,
+          h265parse->time_code.minutes_flag[i] ? h265parse->time_code.
+          minutes_value[i] : 0,
+          h265parse->time_code.seconds_flag[i] ? h265parse->time_code.
+          seconds_value[i] : 0, n_frames, field_count);
+    }
+  }
+
+  gst_video_push_user_data ((GstElement *) h265parse, &h265parse->user_data,
+      parse_buffer);
+
+  gst_h265_parse2_reset_frame (h265parse);
+
+  return GST_FLOW_OK;
+}
+
+static gboolean
+gst_h265_parse2_set_caps (GstBaseParse * parse, GstCaps * caps)
+{
+  GstH265Parse2 *h265parse;
+  GstStructure *str;
+  const GValue *value;
+  GstBuffer *codec_data = NULL;
+  gsize off, size;
+  guint format, align;
+  guint num_nals, i, j;
+  GstH265NalUnit nalu;
+  GstH265ParserResult parseres;
+  GstCaps *old_caps;
+
+  h265parse = GST_H265_PARSE2 (parse);
+
+  /* reset */
+  h265parse->push_codec = FALSE;
+
+  old_caps = gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (parse));
+  if (old_caps) {
+    if (!gst_caps_is_equal (old_caps, caps))
+      gst_h265_parse2_reset_stream_info (h265parse);
+    gst_caps_unref (old_caps);
+  }
+
+  str = gst_caps_get_structure (caps, 0);
+
+  /* accept upstream info if provided */
+  gst_structure_get_int (str, "width", &h265parse->width);
+  gst_structure_get_int (str, "height", &h265parse->height);
+  gst_structure_get_fraction (str, "framerate", &h265parse->fps_num,
+      &h265parse->fps_den);
+  gst_structure_get_fraction (str, "pixel-aspect-ratio",
+      &h265parse->upstream_par_n, &h265parse->upstream_par_d);
+
+  /* get upstream format and align from caps */
+  gst_h265_parse2_format_from_caps (caps, &format, &align);
+
+  /* packetized video has a codec_data */
+  if (format != GST_H265_PARSE_FORMAT_BYTE &&
+      (value = gst_structure_get_value (str, "codec_data"))) {
+    GstMapInfo map;
+    guint8 *data;
+    guint num_nal_arrays;
+
+    GST_DEBUG_OBJECT (h265parse, "have packetized h265");
+    /* make note for optional split processing */
+    h265parse->packetized = TRUE;
+
+    codec_data = gst_value_get_buffer (value);
+    if (!codec_data)
+      goto wrong_type;
+    gst_buffer_map (codec_data, &map, GST_MAP_READ);
+    data = map.data;
+    size = map.size;
+
+    /* parse the hvcC data */
+    if (size < 23) {
+      gst_buffer_unmap (codec_data, &map);
+      goto hvcc_too_small;
+    }
+    /* parse the version, this must be one but
+     * is zero until the spec is finalized */
+    if (data[0] != 0 && data[0] != 1) {
+      gst_buffer_unmap (codec_data, &map);
+      goto wrong_version;
+    }
+
+    h265parse->nal_length_size = (data[21] & 0x03) + 1;
+    GST_DEBUG_OBJECT (h265parse, "nal length size %u",
+        h265parse->nal_length_size);
+
+    num_nal_arrays = data[22];
+    off = 23;
+
+    for (i = 0; i < num_nal_arrays; i++) {
+      if (off + 3 >= size) {
+        gst_buffer_unmap (codec_data, &map);
+        goto hvcc_too_small;
+      }
+
+      num_nals = GST_READ_UINT16_BE (data + off + 1);
+      off += 3;
+      for (j = 0; j < num_nals; j++) {
+        parseres = gst_h265_parser_identify_nalu_hevc (h265parse->nalparser,
+            data, off, size, 2, &nalu);
+
+        if (parseres != GST_H265_PARSER_OK) {
+          gst_buffer_unmap (codec_data, &map);
+          goto hvcc_too_small;
+        }
+
+        gst_h265_parse2_process_nal (h265parse, &nalu);
+        off = nalu.offset + nalu.size;
+      }
+    }
+    gst_buffer_unmap (codec_data, &map);
+
+    /* don't confuse codec_data with inband vps/sps/pps */
+    h265parse->have_vps_in_frame = FALSE;
+    h265parse->have_sps_in_frame = FALSE;
+    h265parse->have_pps_in_frame = FALSE;
+  } else {
+    GST_DEBUG_OBJECT (h265parse, "have bytestream h265");
+    /* nothing to pre-process */
+    h265parse->packetized = FALSE;
+    /* we have 4 sync bytes */
+    h265parse->nal_length_size = 4;
+
+    if (format == GST_H265_PARSE_FORMAT_NONE) {
+      format = GST_H265_PARSE_FORMAT_BYTE;
+      align = GST_H265_PARSE_ALIGN_AU;
+    }
+  }
+
+  {
+    GstCaps *in_caps;
+
+    /* prefer input type determined above */
+    in_caps = gst_caps_new_simple ("video/x-h265",
+        "parsed", G_TYPE_BOOLEAN, TRUE,
+        "stream-format", G_TYPE_STRING,
+        gst_h265_parse2_get_string (h265parse, TRUE, format),
+        "alignment", G_TYPE_STRING,
+        gst_h265_parse2_get_string (h265parse, FALSE, align), NULL);
+    /* negotiate with downstream, sets ->format and ->align */
+    gst_h265_parse2_negotiate (h265parse, format, in_caps);
+    gst_caps_unref (in_caps);
+  }
+
+  if (format == h265parse->format && align == h265parse->align) {
+    /* do not set CAPS and passthrough mode if SPS/PPS have not been parsed */
+    if (h265parse->have_sps && h265parse->have_pps) {
+      /* Don't enable passthrough here. This element will parse various
+       * SEI messages which would be very important/useful for downstream
+       * (HDR, timecode for example)
+       */
+#if 0
+      gst_base_parse_set_passthrough (parse, TRUE);
+#endif
+
+      /* we did parse codec-data and might supplement src caps */
+      gst_h265_parse2_update_src_caps (h265parse, caps);
+    }
+  } else if (format == GST_H265_PARSE_FORMAT_HVC1
+      || format == GST_H265_PARSE_FORMAT_HEV1) {
+    /* if input != output, and input is hevc, must split before anything else */
+    /* arrange to insert codec-data in-stream if needed.
+     * src caps are only arranged for later on */
+    h265parse->push_codec = TRUE;
+    h265parse->have_vps = FALSE;
+    h265parse->have_sps = FALSE;
+    h265parse->have_pps = FALSE;
+    if (h265parse->align == GST_H265_PARSE_ALIGN_NAL)
+      h265parse->split_packetized = TRUE;
+    h265parse->packetized = TRUE;
+  }
+
+  h265parse->in_align = align;
+
+  return TRUE;
+
+  /* ERRORS */
+hvcc_too_small:
+  {
+    GST_DEBUG_OBJECT (h265parse, "hvcC size %" G_GSIZE_FORMAT " < 23", size);
+    goto refuse_caps;
+  }
+wrong_version:
+  {
+    GST_DEBUG_OBJECT (h265parse, "wrong hvcC version");
+    goto refuse_caps;
+  }
+wrong_type:
+  {
+    GST_DEBUG_OBJECT (h265parse, "wrong codec-data type");
+    goto refuse_caps;
+  }
+refuse_caps:
+  {
+    GST_WARNING_OBJECT (h265parse, "refused caps %" GST_PTR_FORMAT, caps);
+    return FALSE;
+  }
+}
+
+static void
+remove_fields (GstCaps * caps, gboolean all)
+{
+  guint i, n;
+
+  n = gst_caps_get_size (caps);
+  for (i = 0; i < n; i++) {
+    GstStructure *s = gst_caps_get_structure (caps, i);
+
+    if (all) {
+      gst_structure_remove_field (s, "alignment");
+      gst_structure_remove_field (s, "stream-format");
+    }
+    gst_structure_remove_field (s, "parsed");
+  }
+}
+
+static GstCaps *
+gst_h265_parse2_get_caps (GstBaseParse * parse, GstCaps * filter)
+{
+  GstCaps *peercaps, *templ;
+  GstCaps *res, *tmp, *pcopy;
+
+  templ = gst_pad_get_pad_template_caps (GST_BASE_PARSE_SINK_PAD (parse));
+  if (filter) {
+    GstCaps *fcopy = gst_caps_copy (filter);
+    /* Remove the fields we convert */
+    remove_fields (fcopy, TRUE);
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), fcopy);
+    gst_caps_unref (fcopy);
+  } else
+    peercaps = gst_pad_peer_query_caps (GST_BASE_PARSE_SRC_PAD (parse), NULL);
+
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, TRUE);
+
+  res = gst_caps_intersect_full (pcopy, templ, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  gst_caps_unref (templ);
+
+  if (filter) {
+    GstCaps *tmp = gst_caps_intersect_full (res, filter,
+        GST_CAPS_INTERSECT_FIRST);
+    gst_caps_unref (res);
+    res = tmp;
+  }
+
+  /* Try if we can put the downstream caps first */
+  pcopy = gst_caps_copy (peercaps);
+  remove_fields (pcopy, FALSE);
+  tmp = gst_caps_intersect_full (pcopy, res, GST_CAPS_INTERSECT_FIRST);
+  gst_caps_unref (pcopy);
+  if (!gst_caps_is_empty (tmp))
+    res = gst_caps_merge (tmp, res);
+  else
+    gst_caps_unref (tmp);
+
+  gst_caps_unref (peercaps);
+  return res;
+}
+
+static gboolean
+gst_h265_parse2_event (GstBaseParse * parse, GstEvent * event)
+{
+  gboolean res;
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+
+  switch (GST_EVENT_TYPE (event)) {
+    case GST_EVENT_CUSTOM_DOWNSTREAM:
+    {
+      GstClockTime timestamp, stream_time, running_time;
+      gboolean all_headers;
+      guint count;
+
+      if (gst_video_event_is_force_key_unit (event)) {
+        gst_video_event_parse_downstream_force_key_unit (event,
+            &timestamp, &stream_time, &running_time, &all_headers, &count);
+
+        GST_INFO_OBJECT (h265parse, "received downstream force key unit event, "
+            "seqnum %d running_time %" GST_TIME_FORMAT
+            " all_headers %d count %d", gst_event_get_seqnum (event),
+            GST_TIME_ARGS (running_time), all_headers, count);
+        if (h265parse->force_key_unit_event) {
+          GST_INFO_OBJECT (h265parse, "ignoring force key unit event "
+              "as one is already queued");
+        } else {
+          h265parse->pending_key_unit_ts = running_time;
+          gst_event_replace (&h265parse->force_key_unit_event, event);
+        }
+        gst_event_unref (event);
+        res = TRUE;
+      } else {
+        res = GST_BASE_PARSE_CLASS (parent_class)->sink_event (parse, event);
+        break;
+      }
+      break;
+    }
+    case GST_EVENT_FLUSH_STOP:
+    case GST_EVENT_SEGMENT_DONE:
+      h265parse->push_codec = TRUE;
+      res = GST_BASE_PARSE_CLASS (parent_class)->sink_event (parse, event);
+      break;
+    case GST_EVENT_SEGMENT:
+    {
+      const GstSegment *segment = NULL;
+
+      gst_event_parse_segment (event, &segment);
+
+      h265parse->last_report = GST_CLOCK_TIME_NONE;
+
+      if (segment->flags & GST_SEEK_FLAG_TRICKMODE_FORWARD_PREDICTED) {
+        GST_DEBUG_OBJECT (h265parse, "Will discard bidirectional frames");
+        h265parse->discard_bidirectional = TRUE;
+      }
+
+      res = GST_BASE_PARSE_CLASS (parent_class)->sink_event (parse, event);
+      break;
+    }
+    default:
+      res = GST_BASE_PARSE_CLASS (parent_class)->sink_event (parse, event);
+      break;
+  }
+  return res;
+}
+
+static gboolean
+gst_h265_parse2_src_event (GstBaseParse * parse, GstEvent * event)
+{
+  gboolean res;
+  GstH265Parse2 *h265parse = GST_H265_PARSE2 (parse);
+
+  switch (GST_EVENT_TYPE (event)) {
+    case GST_EVENT_CUSTOM_UPSTREAM:
+    {
+      GstClockTime running_time;
+      gboolean all_headers;
+      guint count;
+
+      if (gst_video_event_is_force_key_unit (event)) {
+        gst_video_event_parse_upstream_force_key_unit (event,
+            &running_time, &all_headers, &count);
+
+        GST_INFO_OBJECT (h265parse, "received upstream force-key-unit event, "
+            "seqnum %d running_time %" GST_TIME_FORMAT
+            " all_headers %d count %d", gst_event_get_seqnum (event),
+            GST_TIME_ARGS (running_time), all_headers, count);
+
+        if (all_headers) {
+          h265parse->pending_key_unit_ts = running_time;
+          gst_event_replace (&h265parse->force_key_unit_event, event);
+        }
+      }
+      res = GST_BASE_PARSE_CLASS (parent_class)->src_event (parse, event);
+      break;
+    }
+    default:
+      res = GST_BASE_PARSE_CLASS (parent_class)->src_event (parse, event);
+      break;
+  }
+
+  return res;
+}
+
+static void
+gst_h265_parse2_set_property (GObject * object, guint prop_id,
+    const GValue * value, GParamSpec * pspec)
+{
+  GstH265Parse2 *parse;
+  parse = GST_H265_PARSE2 (object);
+
+  switch (prop_id) {
+    case PROP_CONFIG_INTERVAL:
+      parse->interval = g_value_get_int (value);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
+
+static void
+gst_h265_parse2_get_property (GObject * object, guint prop_id, GValue * value,
+    GParamSpec * pspec)
+{
+  GstH265Parse2 *parse;
+  parse = GST_H265_PARSE2 (object);
+
+  switch (prop_id) {
+    case PROP_CONFIG_INTERVAL:
+      g_value_set_int (value, parse->interval);
+      break;
+    default:
+      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+      break;
+  }
+}
\ No newline at end of file
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.h b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.h
new file mode 100644
index 0000000000..4729ba57fd
--- /dev/null
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gsth265parse2.h
@@ -0,0 +1,141 @@
+/* GStreamer H.265 Parser
+ * Copyright (C) 2013 Intel Corporation
+ *   Contact: Sreerenj Balachandran <sreerenj.balachandran@intel.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef __GST_H265_PARSE_H__
+#define __GST_H265_PARSE_H__
+
+#include <gst/gst.h>
+#include <gst/base/gstbaseparse.h>
+#include <gst/codecparsers/gsth265parser.h>
+#include <gst/video/video.h>
+#include "gstvideoparseutils.h"
+
+G_BEGIN_DECLS
+
+#define GST_TYPE_H265_PARSE2 \
+  (gst_h265_parse2_get_type())
+#define GST_H265_PARSE2(obj) \
+  (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_H265_PARSE2,GstH265Parse2))
+#define GST_H265_PARSE2_CLASS(klass) \
+  (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_H265_PARSE2,GstH265Parse2Class))
+#define GST_IS_H265_PARSE2(obj) \
+  (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_H265_PARSE2))
+#define GST_IS_H265_PARSE2_CLASS(klass) \
+  (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_H265_PARSE2))
+
+GType gst_h265_parse2_get_type (void);
+
+typedef struct _GstH265Parse2 GstH265Parse2;
+typedef struct _GstH265Parse2Class GstH265Parse2Class;
+
+struct _GstH265Parse2
+{
+  GstBaseParse baseparse;
+
+  /* stream */
+  gint width, height;
+  gint fps_num, fps_den;
+  gint upstream_par_n, upstream_par_d;
+  gint parsed_par_n, parsed_par_d;
+  gint parsed_fps_n, parsed_fps_d;
+  GstVideoColorimetry parsed_colorimetry;
+  /* current codec_data in output caps, if any */
+  GstBuffer *codec_data;
+  /* input codec_data, if any */
+  GstBuffer *codec_data_in;
+  guint nal_length_size;
+  gboolean packetized;
+  gboolean split_packetized;
+  gboolean transform;
+
+  /* state */
+  GstH265Parser *nalparser;
+  guint in_align;
+  guint state;
+  guint align;
+  guint format;
+  gint current_off;
+
+  GstClockTime last_report;
+  gboolean push_codec;
+  /* The following variables have a meaning in context of "have
+   * VPS/SPS/PPS to push downstream", e.g. to update caps */
+  gboolean have_vps;
+  gboolean have_sps;
+  gboolean have_pps;
+
+  /* per frame vps/sps/pps check for periodic push codec decision */
+  gboolean have_vps_in_frame;
+  gboolean have_sps_in_frame;
+  gboolean have_pps_in_frame;
+
+  gboolean first_frame;
+
+  /* collected SPS and PPS NALUs */
+  GstBuffer *vps_nals[GST_H265_MAX_VPS_COUNT];
+  GstBuffer *sps_nals[GST_H265_MAX_SPS_COUNT];
+  GstBuffer *pps_nals[GST_H265_MAX_PPS_COUNT];
+
+  /* Infos we need to keep track of */
+  guint8 sei_pic_struct;
+
+  /* Collected TimeCode SEI */
+  GstH265TimeCode time_code;
+
+  gboolean discont;
+  gboolean marker;
+
+  /* frame parsing */
+  gint idr_pos, sei_pos;
+  gboolean update_caps;
+  GstAdapter *frame_out;
+  gboolean keyframe;
+  gboolean predicted;
+  gboolean bidirectional;
+  gboolean header;
+  gboolean parsed_framerate;
+  /* AU state */
+  gboolean picture_start;
+
+  GstVideoParseUserData user_data;
+
+  /* props */
+  gint interval;
+
+  GstClockTime pending_key_unit_ts;
+  GstEvent *force_key_unit_event;
+
+  GstVideoMasteringDisplayInfo mastering_display_info;
+  guint mastering_display_info_state;
+
+  GstVideoContentLightLevel content_light_level;
+  guint content_light_level_state;
+
+  /* For forward predicted trickmode */
+  gboolean discard_bidirectional;
+};
+
+struct _GstH265Parse2Class
+{
+  GstBaseParseClass parent_class;
+};
+
+G_END_DECLS
+#endif
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstmpeg4videoparse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gstmpeg4videoparse.c
index 1214a26559..e5318a846b 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstmpeg4videoparse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstmpeg4videoparse.c
@@ -519,6 +519,29 @@ next:
     goto next;
   }
 
+#ifdef TCL_PATCH
+  GstClockTime pts = GST_CLOCK_TIME_NONE;
+  GstClockTime dts = GST_CLOCK_TIME_NONE;
+  if (framesize > 4 && size > 4) {
+    gsize scan_szie = 0;
+    if (*(data) == 0x00 && *(data+1) == 0x00 && *(data+2) == 0x01 && *(data+3) == 0xb6) {
+      scan_szie = 4;
+    }
+    if (scan_szie > 0) {
+      gst_base_parse_get_ts_at_offset(parse, scan_szie, &pts, &dts);
+      if (GST_CLOCK_TIME_IS_VALID (pts)) {
+        //GST_DEBUG("frame->buffer % "GST_TIME_FORMAT", current---pts %"GST_TIME_FORMAT,GST_TIME_ARGS(GST_BUFFER_PTS (frame->buffer)),GST_TIME_ARGS(pts));
+      } else {
+        //GST_DEBUG("gst_base_parse_get_ts_at_offset---false");
+      }
+      if (GST_CLOCK_TIME_IS_VALID (pts) && GST_BUFFER_PTS (frame->buffer) != pts
+        && GST_CLOCK_TIME_IS_VALID (dts) && GST_BUFFER_DTS (frame->buffer) != dts) {
+        gst_base_parse_set_ts_at_offset (parse, off);
+      }
+    }
+  }
+#endif
+
 out:
   gst_buffer_unmap (frame->buffer, &map);
 
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstmpegvideoparse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gstmpegvideoparse.c
index f8ef31a1b9..b94bcb04ca 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstmpegvideoparse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstmpegvideoparse.c
@@ -796,6 +796,7 @@ gst_mpegv_parse_update_src_caps (GstMpegvParse * mpvparse)
 
     width = mpvparse->sequencehdr.width;
     height = mpvparse->sequencehdr.height;
+    GST_INFO("width: %d,height: %d,display_width :%d,display_height: %d",width,height,mpvparse->sequencehdr.par_w,mpvparse->sequencehdr.par_h);
 
     if (mpvparse->config_flags & FLAG_SEQUENCE_DISPLAY_EXT) {
       seqdispext = &mpvparse->sequencedispext;
@@ -809,6 +810,34 @@ gst_mpegv_parse_update_src_caps (GstMpegvParse * mpvparse)
             width, height);
       }
     }
+//mpeg2 3840X2160(16:9) because aspect_ratio_info convert to 4773X2160 can not play
+#if 0
+    float current_aspect = (float)width/height;
+    float aspect_ration = current_aspect;
+    switch (mpvparse->sequencehdr.aspect_ratio_info) {
+      case 0x02:
+        aspect_ration = 4.0/3.0;
+        break;
+      case 0x03:
+        aspect_ration = 16.0/9.0;
+        break;
+      case 0x04:
+        aspect_ration = 2.21/1.0;
+        break;
+      default:
+        GST_DEBUG ("unknown/invalid aspect_ratio_information %d",
+            mpvparse->sequencehdr.aspect_ratio_info);
+        break;
+    }
+    if (current_aspect < aspect_ration)
+    {
+      width = (int) (height*aspect_ration + 0.5f);
+    }
+    else if (current_aspect > aspect_ration)
+    {
+      height = (int) (width/aspect_ration + 0.5f);
+    }
+#endif
     gst_caps_set_simple (caps, "width", G_TYPE_INT, width,
         "height", G_TYPE_INT, height, NULL);
   }
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.c b/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.c
index 81621d993b..486d45352d 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.c
@@ -85,6 +85,10 @@ gst_png_parse_init (GstPngParse * pngparse)
 {
   GST_PAD_SET_ACCEPT_INTERSECT (GST_BASE_PARSE_SINK_PAD (pngparse));
   GST_PAD_SET_ACCEPT_TEMPLATE (GST_BASE_PARSE_SINK_PAD (pngparse));
+#ifdef TCL_PATCH
+  if(pngparse)
+    pngparse->file_size = -1;
+#endif
 }
 
 static gboolean
@@ -93,10 +97,21 @@ gst_png_parse_start (GstBaseParse * parse)
   GstPngParse *pngparse = GST_PNG_PARSE (parse);
 
   GST_DEBUG_OBJECT (pngparse, "start");
-
+#ifdef TCL_PATCH
+  gint64 frame_size = 0;
+  if (gst_pad_peer_query_duration (parse->sinkpad, GST_FORMAT_BYTES, &frame_size)) {
+    frame_size = ((frame_size + 1024 - 1) / 1024) * 1024;
+    pngparse->file_size = frame_size;
+    frame_size = MIN (frame_size, 50 * 1024 * 1024);
+    GST_DEBUG_OBJECT (parse, "frame size %lld", frame_size);
+    gst_base_parse_set_min_frame_size (parse, frame_size);
+  } else {
+    gst_base_parse_set_min_frame_size (parse, 8 + 12 + 12);
+  }
+#else
   /* the start code and at least 2 empty frames (IHDR and IEND) */
   gst_base_parse_set_min_frame_size (parse, 8 + 12 + 12);
-
+#endif
   pngparse->width = 0;
   pngparse->height = 0;
 
@@ -134,7 +149,9 @@ gst_png_parse_handle_frame (GstBaseParse * parse,
   GstFlowReturn ret = GST_FLOW_OK;
   guint64 signature;
   guint width = 0, height = 0;
-
+#ifdef TCL_PATCH
+  gboolean has_dat_block = FALSE;
+#endif
   gst_buffer_map (frame->buffer, &map, GST_MAP_READ);
   gst_byte_reader_init (&reader, map.data, map.size);
 
@@ -190,6 +207,9 @@ gst_png_parse_handle_frame (GstBaseParse * parse,
     } else if (code == GST_MAKE_FOURCC ('I', 'D', 'A', 'T')) {
       gst_base_parse_set_min_frame_size (parse,
           gst_byte_reader_get_pos (&reader) + 4 + length + 12);
+#ifdef TCL_PATCH
+      has_dat_block = TRUE;
+#endif
     }
 
     if (!gst_byte_reader_skip (&reader, length + 4))
@@ -234,7 +254,11 @@ gst_png_parse_handle_frame (GstBaseParse * parse,
         gst_caps_unref (caps);
 
         if (ret != GST_FLOW_OK)
+    #ifdef TCL_PATCH
+          goto fail;
+    #else
           goto beach;
+     #endif
       }
 
 
@@ -245,6 +269,57 @@ gst_png_parse_handle_frame (GstBaseParse * parse,
   }
 
 beach:
+#ifdef TCL_PATCH
+  if (has_dat_block && pngparse->file_size == map.size) {
+    gst_byte_reader_set_pos(&reader, map.size);
+    /* the start code and at least 2 empty frames (IHDR and IEND) */
+    gst_base_parse_set_min_frame_size (parse, 8 + 12 + 12);
+
+    if (pngparse->width != width || pngparse->height != height) {
+      GstCaps *caps, *sink_caps;
+
+      pngparse->height = height;
+      pngparse->width = width;
+
+      caps = gst_caps_new_simple ("image/png",
+          "width", G_TYPE_INT, width, "height", G_TYPE_INT, height, NULL);
+
+      sink_caps =
+          gst_pad_get_current_caps (GST_BASE_PARSE_SINK_PAD (pngparse));
+
+      if (sink_caps) {
+        GstStructure *st;
+        gint fr_num, fr_denom;
+
+        st = gst_caps_get_structure (sink_caps, 0);
+        if (st
+            && gst_structure_get_fraction (st, "framerate", &fr_num,
+                &fr_denom)) {
+          gst_caps_set_simple (caps,
+              "framerate", GST_TYPE_FRACTION, fr_num, fr_denom, NULL);
+        } else {
+          GST_WARNING_OBJECT (pngparse, "No framerate set");
+        }
+
+        gst_caps_unref (sink_caps);
+      }
+
+      if (!gst_pad_set_caps (GST_BASE_PARSE_SRC_PAD (parse), caps))
+        ret = GST_FLOW_NOT_NEGOTIATED;
+
+      gst_caps_unref (caps);
+
+      if (ret != GST_FLOW_OK)
+        goto fail;
+    }
+
+    gst_buffer_unmap (frame->buffer, &map);
+    return gst_base_parse_finish_frame (parse, frame,
+        gst_byte_reader_get_pos (&reader));
+  }
+
+fail:
+#endif
 
   gst_buffer_unmap (frame->buffer, &map);
 
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.h b/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.h
index 35744813c0..95c7782172 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.h
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstpngparse.h
@@ -49,7 +49,9 @@ struct _GstPngParse
 
   guint width;
   guint height;
-  
+#ifdef TCL_PATCH
+  gint64 file_size;
+#endif
   gboolean sent_codec_tag;
 };
 
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/gstvideoparserselements.h b/subprojects/gst-plugins-bad/gst/videoparsers/gstvideoparserselements.h
index a8d40c91f7..5fa5095695 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/gstvideoparserselements.h
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/gstvideoparserselements.h
@@ -36,6 +36,9 @@ GST_ELEMENT_REGISTER_DECLARE (diracparse);
 GST_ELEMENT_REGISTER_DECLARE (h263parse);
 GST_ELEMENT_REGISTER_DECLARE (h264parse);
 GST_ELEMENT_REGISTER_DECLARE (h265parse);
+#ifdef TCL_PATCH
+GST_ELEMENT_REGISTER_DECLARE (h265parse2);
+#endif
 GST_ELEMENT_REGISTER_DECLARE (jpeg2000parse);
 GST_ELEMENT_REGISTER_DECLARE (mpeg4videoparse);
 GST_ELEMENT_REGISTER_DECLARE (mpegvideoparse);
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/meson.build b/subprojects/gst-plugins-bad/gst/videoparsers/meson.build
index 147a2650e4..854126a509 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/meson.build
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/meson.build
@@ -11,6 +11,7 @@ vparse_sources = [
   'gstpngparse.c',
   'gstvc1parse.c',
   'gsth265parse.c',
+  'gsth265parse2.c',
   'gstvideoparseutils.c',
   'gstjpeg2000parse.c',
   'gstvp9parse.c',
diff --git a/subprojects/gst-plugins-bad/gst/videoparsers/plugin.c b/subprojects/gst-plugins-bad/gst/videoparsers/plugin.c
index 069da70700..7f3f3b6253 100644
--- a/subprojects/gst-plugins-bad/gst/videoparsers/plugin.c
+++ b/subprojects/gst-plugins-bad/gst/videoparsers/plugin.c
@@ -37,6 +37,9 @@ plugin_init (GstPlugin * plugin)
   ret |= GST_ELEMENT_REGISTER (pngparse, plugin);
   ret |= GST_ELEMENT_REGISTER (jpeg2000parse, plugin);
   ret |= GST_ELEMENT_REGISTER (h265parse, plugin);
+#ifdef TCL_PATCH
+  ret |= GST_ELEMENT_REGISTER (h265parse2, plugin);
+#endif
   ret |= GST_ELEMENT_REGISTER (vc1parse, plugin);
   /**
    * element-vp9parse:
diff --git a/subprojects/gst-plugins-bad/meson.build b/subprojects/gst-plugins-bad/meson.build
index 6598f189fb..b718940259 100644
--- a/subprojects/gst-plugins-bad/meson.build
+++ b/subprojects/gst-plugins-bad/meson.build
@@ -427,14 +427,14 @@ orc_targets = []
 orc_dep = dependency('orc-0.4', version : orc_req, required : get_option('orc'),
     fallback : ['orc', 'orc_dep'])
 orcc = find_program('orcc', required : get_option('orc'))
-if orc_dep.found() and orcc.found()
-  have_orcc = true
-  orcc_args = [orcc, '--include', 'glib.h']
-  cdata.set('HAVE_ORC', 1)
-else
+#if orc_dep.found() and orcc.found()
+#  have_orcc = true
+#  orcc_args = [orcc, '--include', 'glib.h']
+#  cdata.set('HAVE_ORC', 1)
+#else
   message('Orc Compiler not found or disabled, will use backup C code')
   cdata.set('DISABLE_ORC', 1)
-endif
+#endif
 cdata.set('GST_ENABLE_EXTRA_CHECKS', not get_option('extra-checks').disabled())
 
 gnustl_dep = declare_dependency()
diff --git a/subprojects/gst-plugins-bad/meson_options.txt b/subprojects/gst-plugins-bad/meson_options.txt
index b347dcb27b..aee06be2a1 100644
--- a/subprojects/gst-plugins-bad/meson_options.txt
+++ b/subprojects/gst-plugins-bad/meson_options.txt
@@ -67,6 +67,7 @@ option('videoparsers', type : 'feature', value : 'auto')
 option('videosignal', type : 'feature', value : 'auto')
 option('vmnc', type : 'feature', value : 'auto')
 option('y4m', type : 'feature', value : 'auto')
+option('videorender', type : 'feature', value : 'auto')
 
 # Feature options for libraries that need external deps
 option('opencv', type : 'feature', value : 'auto', description : 'OpenCV computer vision library support')
diff --git a/subprojects/gst-plugins-bad/sys/dshowsrcwrapper/dshowdeviceprovider.cpp b/subprojects/gst-plugins-bad/sys/dshowsrcwrapper/dshowdeviceprovider.cpp
index 2f49e4a403..670a3831d3 100644
--- a/subprojects/gst-plugins-bad/sys/dshowsrcwrapper/dshowdeviceprovider.cpp
+++ b/subprojects/gst-plugins-bad/sys/dshowsrcwrapper/dshowdeviceprovider.cpp
@@ -130,7 +130,7 @@ gst_dshow_device_provider_start (GstDeviceProvider * provider)
     if (dev->data)
       gst_device_provider_device_add (provider, (GstDevice *) dev->data);
   }
-  g_list_free (devs);
+  g_list_free_full (devs, gst_object_unref);
 
   return TRUE;
 }
diff --git a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsa.c b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsa.c
index 5b676ab8b1..bfc1ec7f36 100644
--- a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsa.c
+++ b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsa.c
@@ -29,12 +29,16 @@
 static gboolean
 plugin_init (GstPlugin * plugin)
 {
+#ifdef TCL_PATCH
+  return gst_element_register (plugin, "tinyalsasink", GST_RANK_PRIMARY+2, gst_tinyalsa_sink_get_type());
+#else
   if (!gst_element_register (plugin, "tinyalsasink", GST_RANK_NONE,
           GST_TYPE_TINYALSA_SINK)) {
     return FALSE;
   }
 
   return TRUE;
+#endif
 }
 
 GST_PLUGIN_DEFINE (GST_VERSION_MAJOR,
diff --git a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.c b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.c
index 7d6bf804b9..d16698c5bf 100644
--- a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.c
+++ b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.c
@@ -40,6 +40,1010 @@
 
 #include "tinyalsasink.h"
 
+#ifdef TCL_PATCH
+
+#define SNDRV_PCM_FORMAT_S8     0
+#define SNDRV_PCM_FORMAT_S16_LE 2
+#define SNDRV_PCM_FORMAT_S24_LE 6
+#define SNDRV_PCM_FORMAT_S32_LE 10
+
+#define SNDRV_PCM_FORMAT_ANY                  \
+        ((1 << SNDRV_PCM_FORMAT_S8)     |     \
+         (1 << SNDRV_PCM_FORMAT_S16_LE) |     \
+         (1 << SNDRV_PCM_FORMAT_S24_LE) |     \
+         (1 << SNDRV_PCM_FORMAT_S32_LE))
+
+enum
+{
+    PROP_0,
+    PROP_CARD,
+    PROP_DEVICE,
+    PROP_LAST
+};
+
+
+#define CONVERT_FORMAT_NONE         1000
+#define CONVERT_FORMAT_F32LE        1001
+#define CONVERT_FORMAT_F32BE        1002
+
+#define CONVERT_CAPS_TEMPLATE_STRING    \
+    "audio/x-raw, " \
+    "format = (string) { S16LE, S32LE, S24_32LE, S8, F32LE, F32BE }, " \
+    "rate = (int) [ 1, MAX ], " \
+    "channels = (int) [ 1, MAX ]"
+
+
+#define DEFAULT_CARD    0
+#define DEFAULT_DEVICE  0
+
+GST_DEBUG_CATEGORY_STATIC (tinyalsa_sink_debug);
+
+#define GST_CAT_DEFAULT tinyalsa_sink_debug
+#define parent_class    gst_tinyalsa_sink_parent_class
+
+G_DEFINE_TYPE (GstTinyalsaSink, gst_tinyalsa_sink, GST_TYPE_AUDIO_SINK);
+
+
+static void     pcm_get_config_from_spec (struct pcm_config *config, const GstAudioRingBufferSpec * spec);
+static void     gst_tinyalsa_sink_set_property (GObject * object, guint prop_id, const GValue * value, GParamSpec * pspec);
+static void     gst_tinyalsa_sink_get_property (GObject * object, guint prop_id, GValue * value,GParamSpec * pspec);
+static guint    gst_tinyalsa_sink_delay (GstAudioSink * asink);
+static gint     gst_tinyalsa_sink_write (GstAudioSink * asink, gpointer data, guint length);
+static GstCaps* gst_tinyalsa_sink_getcaps (GstBaseSink * bsink, GstCaps * filter);
+static gboolean gst_tinyalsa_sink_unprepare (GstAudioSink * asink);
+static gboolean gst_tinyalsa_sink_prepare (GstAudioSink * asink, GstAudioRingBufferSpec * spec);
+static gboolean gst_tinyalsa_sink_close (GstAudioSink * asink);
+static gboolean gst_tinyalsa_sink_open  (GstAudioSink * asink);
+static void     gst_tinyalsa_sink_reset (GstAudioSink * asink);
+GstFlowReturn   gst_tinyalsa_sink_convert_chain_func (GstPad * pad, GstObject * parent, GstBuffer * buffer);
+
+static GstPad * _setup_srcpad_link_audioconvert (GstElement * element, GstPadTemplate * tmpl);
+static GstPad * _setup_sinkpad_link_audioconvert(GstObject * parent, GstElement * element, GstPadTemplate * tmpl);
+static GstElement * _setup_audioconvert (GstTinyalsaSink * sink, GstCaps * outcaps);
+static gboolean _setup_events (GstPad * srcpad, GstElement * element, GstCaps * caps, GstFormat format);
+static void _teardown_pad_by_name (GstElement * element, const gchar * name);
+
+static void _cleanup_audioconvert (GstTinyalsaSink * sink);
+
+
+
+
+
+static GstStaticPadTemplate sink_template = GST_STATIC_PAD_TEMPLATE ("sink",
+        GST_PAD_SINK,
+        GST_PAD_ALWAYS,
+        GST_STATIC_CAPS ("audio/x-raw, "
+            "format = (string) { S16LE, S32LE, S24_32LE, S8, F32LE, F32BE }, "
+            "channels = (int) [ 1, MAX ], "
+            "rate = (int) [ 1, MAX ], "
+            "layout = (string) interleaved; "));
+
+static void
+gst_tinyalsa_sink_class_init (GstTinyalsaSinkClass * klass)
+{
+    GObjectClass        *gobject_class    = G_OBJECT_CLASS (klass);
+    GstElementClass     *element_class    = GST_ELEMENT_CLASS (klass);
+    GstBaseSinkClass    *basesink_class   = GST_BASE_SINK_CLASS (klass);
+    GstAudioSinkClass   *audiosink_class  = GST_AUDIO_SINK_CLASS (klass);
+
+    gobject_class->get_property = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_get_property);
+    gobject_class->set_property = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_set_property);
+
+    basesink_class->get_caps    = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_getcaps);
+
+    audiosink_class->open       = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_open);
+    audiosink_class->prepare    = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_prepare);
+    audiosink_class->unprepare  = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_unprepare);
+    audiosink_class->close      = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_close);
+    audiosink_class->write      = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_write);
+    audiosink_class->reset      = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_reset);
+    audiosink_class->delay      = GST_DEBUG_FUNCPTR (gst_tinyalsa_sink_delay);
+
+    gst_element_class_set_static_metadata (element_class,
+          "tinyalsa Audio Sink",
+          "Sink/Audio",
+          "Plays audio to an ALSA device",
+          "Arun Raghavan <arun@centricular.com>");
+
+    gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&sink_template));
+
+    g_object_class_install_property (gobject_class,
+            PROP_CARD,
+            g_param_spec_uint ("card", "Card", "The ALSA card to use",
+                0, G_MAXUINT, DEFAULT_CARD,
+                G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+    g_object_class_install_property (gobject_class,
+            PROP_DEVICE,
+            g_param_spec_uint ("device", "Device", "The ALSA device to use",
+                0, G_MAXUINT, DEFAULT_CARD,
+                G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));
+
+    GST_DEBUG_CATEGORY_INIT (tinyalsa_sink_debug, "tinyalsasink", 0, "tinyalsa Sink");
+}
+
+static void
+gst_tinyalsa_sink_init (GstTinyalsaSink * sink)
+{
+    sink->card          = DEFAULT_CARD;
+    sink->device        = DEFAULT_DEVICE;
+    sink->cached_caps   = NULL;
+    sink->channels_max  = 0;
+    sink->channels_min  = 0;
+    sink->need_convert_flag = FALSE;
+    sink->audio_convert     = NULL;
+    if(NULL != sink->convert_sinkpad)
+    {
+        gst_object_unref(sink->convert_sinkpad);
+        sink->convert_sinkpad  = NULL;
+    }
+    if(NULL != sink->convert_srcpad)
+    {
+        gst_object_unref(sink->convert_srcpad);
+        sink->convert_srcpad   = NULL;
+    }
+}
+
+static void
+gst_tinyalsa_sink_reset (GstAudioSink * asink)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (asink);
+    if (pcm_stop (sink->pcm) < 0)
+        GST_ERROR_OBJECT (sink, "Could not stop device: %s", pcm_get_error (sink->pcm));
+
+    if (pcm_prepare (sink->pcm) < 0)
+        GST_ERROR_OBJECT (sink, "Could not prepare device: %s", pcm_get_error (sink->pcm));
+}
+
+static gboolean
+gst_tinyalsa_sink_open (GstAudioSink * asink)
+{
+    /* Nothing to do here, we can't call pcm_open() till we have stream parameters available */
+    return TRUE;
+}
+
+
+static gboolean
+gst_tinyalsa_sink_close (GstAudioSink * asink)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (asink);
+    // 该元件不为NULL，表示使用了AudioConvert,因此需要释放，否则不需要释放
+    if(sink->audio_convert)
+    {
+        _cleanup_audioconvert(sink);
+        sink->audio_convert = NULL;
+    }
+
+    if(sink->cached_caps)
+    {
+        gst_caps_unref(sink->cached_caps);
+        sink->cached_caps = NULL;
+    }
+
+    return TRUE;
+}
+
+static gboolean
+gst_tinyalsa_sink_prepare (GstAudioSink * asink, GstAudioRingBufferSpec * spec)
+{
+    GstTinyalsaSink   *sink   = GST_TINYALSA_SINK (asink);
+    struct pcm_config  config = { 0, };
+    struct pcm_params *params = NULL;
+    int period_size_min, period_size_max;
+    int periods_min,     periods_max;
+    int channels;
+    // 从流中获取配置PCM的基础参数设置
+    pcm_get_config_from_spec (&config, spec);
+    // 默认使用最大的channels-----不用转换时
+    channels                = config.channels;
+    config.channels         = sink->channels_max;
+
+    if(config.rate == 44100)
+    {
+        config.rate = 48000;
+        g_print("\033[0;35;40m===========  set rate 48000\033[m\n");
+
+    }
+    // 确定是否需要转换,小部分片源会出现prepare->unprepare->prepare现象 片源:M039_AVI.avi
+    if((CONVERT_FORMAT_F32LE == config.format || CONVERT_FORMAT_F32BE == config.format ||
+        channels > sink->channels_max /**³¬¹ýPCMÖ§³ÖµÄ×î´óµÄchannelsÊ±*/))
+    {
+        sink->need_convert_flag = TRUE;
+        config.format           = PCM_FORMAT_S16_LE;        // 统一支持
+        /** ??? 需要转换时，必须用最小channels,否则PCM无法Ready ??? **/
+        config.channels         = sink->channels_min;
+    }
+
+    // 判断是否是软解的结果------------START-------------Audio转换代码块
+    if(sink->need_convert_flag)
+    {
+        GstCaps* output_caps = NULL;
+        GstCaps* input_caps  = NULL;
+        GstPad*  peerpad     = NULL;
+        GstPad*  pad         = GST_BASE_SINK_PAD(GST_BASE_SINK_CAST(asink));
+        if(pad)
+        {
+            GstCaps* caps = NULL;
+            peerpad       = gst_pad_get_peer(pad);
+            caps          = gst_pad_get_current_caps(peerpad);
+            input_caps    = gst_caps_copy(caps);
+            gst_caps_unref(caps);
+            caps          = NULL;
+        }
+        else
+        {
+            gst_object_unref (peerpad);
+            peerpad = NULL;
+            goto fail;
+        }
+        output_caps = gst_caps_new_simple ("audio/x-raw",
+                    "rate",      G_TYPE_INT,    config.rate,
+                    "channels",  G_TYPE_INT,    config.channels,
+                    "format"  ,  G_TYPE_STRING, "S16LE",
+                    NULL);
+
+        sink->audio_convert = _setup_audioconvert (sink, output_caps);
+        if(NULL == sink->audio_convert)
+        {
+            GST_ERROR_OBJECT(sink, "can not build AudioConvert element for soft decoder!");
+            goto fail;
+        }
+
+        if(GST_OBJECT_REFCOUNT(output_caps) != 2)
+        {
+            GST_ERROR_OBJECT(sink, "convert_outcaps refcount is not 2, while it must be 2 now!");
+            goto fail;
+        }
+
+        if(NULL == sink->audio_convert || GST_STATE_CHANGE_SUCCESS != gst_element_set_state (sink->audio_convert, GST_STATE_PLAYING))
+        {
+            GST_ERROR_OBJECT(sink, "could not set state of AudioConvert to PLAYING!");
+            goto fail;
+        }
+
+        if(FALSE == _setup_events (sink->convert_srcpad, sink->audio_convert, input_caps, GST_FORMAT_TIME))
+        {
+            GST_ERROR_OBJECT(sink, "could not push STREAM_START event to AudioConvert to start this element!");
+            goto fail;
+        }
+        if (input_caps)
+            gst_caps_unref(input_caps);
+
+        if (output_caps)
+            gst_caps_unref(output_caps);
+
+        if(peerpad)
+        {
+            gst_object_unref (peerpad);
+            peerpad = NULL;
+        }
+    }
+    // 判断是否是软解的结果------------END-------------Audio转换代码块
+
+    GST_DEBUG_OBJECT (sink, "Requesting %u periods of %u frames", config.period_count, config.period_size);
+
+    // 从硬件设备中获取到配置PCM的参数设置
+    params = pcm_params_get (sink->card, sink->device, PCM_OUT);
+    if (!params)
+        GST_ERROR_OBJECT (sink, "Could not get PCM params");
+
+    period_size_min = pcm_params_get_min (params, PCM_PARAM_PERIOD_SIZE);
+    period_size_max = pcm_params_get_max (params, PCM_PARAM_PERIOD_SIZE);
+    periods_min     = pcm_params_get_min (params, PCM_PARAM_PERIODS);
+    periods_max     = pcm_params_get_max (params, PCM_PARAM_PERIODS);
+
+    pcm_params_free (params);
+
+    /* 调节参变量--Snap period size/count to the permitted range */
+    config.period_size  = CLAMP (config.period_size,  period_size_min, period_size_max);
+    config.period_count = CLAMP (config.period_count, periods_min,     periods_max);
+
+    /* mutex with getcaps */
+    GST_OBJECT_LOCK (sink);
+    // 根据配置打开PCM输出设备
+    sink->pcm = pcm_open (sink->card, sink->device, PCM_OUT | PCM_NORESTART, &config);
+    GST_OBJECT_UNLOCK (sink);
+
+    // 校验PCM打开状态
+    if (!sink->pcm || !pcm_is_ready(sink->pcm))
+    {
+        GST_ERROR_OBJECT (sink, "Could not open device: %s", pcm_get_error (sink->pcm));
+        g_print("\033[0;35;40m===========  Could not open device: %s\033[m\n", pcm_get_error (sink->pcm));
+        goto fail;
+    }
+
+    if (pcm_prepare (sink->pcm) < 0)
+    {
+        GST_ERROR_OBJECT (sink, "Could not prepare device: %s", pcm_get_error (sink->pcm));
+        goto fail;
+    }
+
+    spec->segsize   = pcm_frames_to_bytes (sink->pcm, config.period_size);
+    spec->segtotal  = config.period_count;
+
+    GST_DEBUG_OBJECT (sink, "Configured for %u periods of %u frames", config.period_count, config.period_size);
+    return TRUE;
+
+fail:
+    if (sink->pcm)
+        pcm_close (sink->pcm);
+
+    // 该元件不为NULL，表示使用了AudioConvert,因此需要释放，否则不需要释放
+    if(sink->audio_convert)
+    {
+        _cleanup_audioconvert(sink);
+        sink->audio_convert = NULL;
+    }
+
+    return FALSE;
+}
+
+static gboolean
+gst_tinyalsa_sink_unprepare (GstAudioSink * asink)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (asink);
+    if (pcm_stop (sink->pcm) < 0)
+        GST_ERROR_OBJECT (sink, "Could not stop device: %s", pcm_get_error (sink->pcm));
+
+    /* mutex with getcaps */
+    GST_OBJECT_LOCK (sink);
+    if (pcm_close (sink->pcm))
+    {
+        GST_ERROR_OBJECT (sink, "Could not close device: %s", pcm_get_error (sink->pcm));
+        GST_OBJECT_UNLOCK(sink);
+        return FALSE;
+    }
+    sink->pcm = NULL;
+    gst_caps_replace (&sink->cached_caps, NULL);
+    if(sink->audio_convert)
+    {
+        _cleanup_audioconvert(sink);
+        sink->audio_convert = NULL;
+    }
+    GST_OBJECT_UNLOCK(sink);
+    GST_DEBUG_OBJECT (sink, "Device unprepared");
+
+    return TRUE;
+}
+
+static GstCaps *
+gst_tinyalsa_sink_getcaps (GstBaseSink * bsink, GstCaps * filter)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (bsink);
+    GstCaps *caps  = NULL;
+    GValue formats = { 0, };
+    GValue format  = { 0, };
+    struct pcm_params *params = NULL;
+    struct pcm_mask   *mask;
+    int rate_min, rate_max, channels_min, channels_max;
+    guint16 m;
+
+    GST_DEBUG_OBJECT(sink, "Querying caps");
+    GST_OBJECT_LOCK(sink);
+
+    if (sink->cached_caps)
+    {
+        GST_DEBUG_OBJECT (sink, "Returning cached caps");
+        caps = gst_caps_ref (sink->cached_caps);
+        goto done;
+    }
+
+    if (sink->pcm)
+    {
+        /* We can't query the device while it's open, so return current caps */
+        caps = gst_pad_get_current_caps (GST_BASE_SINK_PAD (bsink));
+        goto done;
+    }
+
+    params = pcm_params_get (sink->card, sink->device, PCM_OUT);
+    if (!params)
+    {
+        GST_ERROR_OBJECT (sink, "Could not get PCM params");
+        goto done;
+    }
+
+    mask = pcm_params_get_mask (params, PCM_PARAM_FORMAT);
+    m    = (mask->bits[1] << 8) | mask->bits[0];
+
+    if (!(m & SNDRV_PCM_FORMAT_ANY))
+    {
+        GST_ERROR_OBJECT (sink, "Could not find any supported format");
+        goto done;
+    }
+
+    caps = gst_caps_new_empty_simple ("audio/x-raw");
+
+    g_value_init (&formats, GST_TYPE_LIST);
+    g_value_init (&format,  G_TYPE_STRING);
+
+    if (m & (1 << SNDRV_PCM_FORMAT_S8))
+    {
+        g_value_set_static_string (&format, "S8");
+        gst_value_list_prepend_value (&formats, &format);
+    }
+    if (m & (1 << SNDRV_PCM_FORMAT_S16_LE))
+    {
+        g_value_set_static_string (&format, "S16LE");
+        gst_value_list_prepend_value (&formats, &format);
+    }
+    if (m & (1 << SNDRV_PCM_FORMAT_S24_LE))
+    {
+        g_value_set_static_string (&format, "S24_32LE");
+        gst_value_list_prepend_value (&formats, &format);
+    }
+    if (m & (1 << SNDRV_PCM_FORMAT_S32_LE))
+    {
+        g_value_set_static_string (&format, "S32LE");
+        gst_value_list_prepend_value (&formats, &format);
+    }
+
+    g_value_set_static_string (&format, "F32LE");
+    gst_value_list_prepend_value (&formats, &format);
+
+    g_value_set_static_string (&format, "F32BE");
+    gst_value_list_prepend_value (&formats, &format);
+
+
+    gst_caps_set_value (caps, "format", &formats);
+
+    g_value_unset (&format);
+    g_value_unset (&formats);
+
+    /* This is a bit of a lie, since the device likely only supports some
+     * standard rates in this range. We should probably filter the range to
+     * those, standard audio rates but even that isn't guaranteed to be accurate.
+    */
+    rate_min = pcm_params_get_min (params, PCM_PARAM_RATE);
+    rate_max = pcm_params_get_max (params, PCM_PARAM_RATE);
+
+    if (rate_min == rate_max)
+        gst_caps_set_simple (caps, "rate", G_TYPE_INT, rate_min, NULL);
+    else
+        gst_caps_set_simple (caps, "rate", GST_TYPE_INT_RANGE, rate_min, rate_max, NULL);
+
+    channels_max = pcm_params_get_max (params, PCM_PARAM_CHANNELS);
+    channels_min = pcm_params_get_min (params, PCM_PARAM_CHANNELS);
+    sink->channels_max = channels_max;
+    sink->channels_min = channels_min;
+
+    if(channels_max == 0 || channels_min ==0)
+        goto error_param;
+
+    gst_caps_set_simple (caps, "channels", GST_TYPE_INT_RANGE, 1, G_MAXINT,   NULL);
+    gst_caps_set_simple (caps, "layout",   G_TYPE_STRING,      "interleaved", NULL);
+    gst_caps_replace (&sink->cached_caps, caps);
+
+done:
+    GST_OBJECT_UNLOCK (sink);
+    GST_DEBUG_OBJECT (sink, "Got caps %" GST_PTR_FORMAT, caps);
+
+    if (caps && filter)
+    {
+        GstCaps *intersection = gst_caps_intersect_full (filter, caps, GST_CAPS_INTERSECT_FIRST);
+        gst_caps_unref (caps);
+        caps = intersection;
+    }
+
+    if (params)
+        pcm_params_free (params);
+
+    g_print("\033[0;35;40m===========  caps:%s\033[m\n", gst_caps_to_string(caps));
+
+    return caps;
+
+error_param:
+    GST_OBJECT_UNLOCK (sink);
+    GST_ERROR_OBJECT (sink, "Paramter error, Cannot open PCM");
+    if (caps)
+    {
+        gst_caps_unref (caps);
+        caps = NULL;
+    }
+
+    if (params)
+        pcm_params_free (params);
+    return NULL;
+}
+
+static enum pcm_format
+pcm_get_format_from_gst (GstAudioFormat format)
+{
+    switch (format)
+    {
+        case GST_AUDIO_FORMAT_S8:       return PCM_FORMAT_S8;
+        case GST_AUDIO_FORMAT_S16LE:    return PCM_FORMAT_S16_LE;
+        case GST_AUDIO_FORMAT_S24_32LE: return PCM_FORMAT_S24_LE;
+        case GST_AUDIO_FORMAT_S32LE:    return PCM_FORMAT_S32_LE;
+        case GST_AUDIO_FORMAT_F32LE:    return CONVERT_FORMAT_F32LE;
+        case GST_AUDIO_FORMAT_F32BE:    return CONVERT_FORMAT_F32BE;
+        default:
+            g_assert_not_reached();
+            return CONVERT_FORMAT_NONE;
+    }
+}
+
+static void
+pcm_get_config_from_spec (struct pcm_config *config, const GstAudioRingBufferSpec * spec)
+{
+    gint64 frames;
+
+    config->format   = pcm_get_format_from_gst (GST_AUDIO_INFO_FORMAT (&spec->info));
+    config->channels = GST_AUDIO_INFO_CHANNELS (&spec->info);
+    config->rate     = GST_AUDIO_INFO_RATE     (&spec->info);
+
+    gst_audio_info_convert (&spec->info,
+        GST_FORMAT_TIME,
+        spec->latency_time * GST_USECOND,
+        GST_FORMAT_DEFAULT, /* frames */
+        &frames);
+
+    config->period_size  = frames;
+    config->period_count = spec->buffer_time / spec->latency_time;
+}
+
+static gint
+gst_tinyalsa_sink_write (GstAudioSink * asink, gpointer data, guint length)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (asink);
+    // 需要转换,则将数据流接上Audio Convert后进行转换了再走Chain函数输出
+    if(sink->need_convert_flag)
+    {
+        GstBuffer * buf = gst_buffer_new_and_alloc(length);
+        if(NULL != buf && NULL != data && NULL != data)
+        {
+            gst_buffer_fill(buf, 0, data, length);
+            gst_pad_push(sink->convert_srcpad, buf);
+            // 无需free数据，data指针所在的ringbuffer会自己clear
+            // g_free(data);
+            // data = NULL;
+        }
+    }
+    // 不需要转换，直接输出给PCM
+    else
+    {
+        int ret;
+again:
+        ret = pcm_write (sink->pcm, data, length);
+        if (ret == -EPIPE)
+        {
+            GST_WARNING_OBJECT (sink, "Got an underrun");
+            if (pcm_prepare (sink->pcm) < 0)
+            {
+                GST_ERROR_OBJECT (sink, "Could not prepare device: %s", pcm_get_error (sink->pcm));
+                return -1;
+            }
+
+            goto again;
+
+        }
+        else if (ret < 0)
+        {
+            GST_ERROR_OBJECT (sink, "Could not write data to device: %s", pcm_get_error (sink->pcm));
+            return -1;
+        }
+        GST_DEBUG_OBJECT (sink, "Wrote %u bytes", length);
+    }
+    return length;
+}
+
+static guint
+gst_tinyalsa_sink_delay (GstAudioSink * asink)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (asink);
+    int delay = pcm_get_delay (sink->pcm);
+
+    if (delay < 0)
+    {
+        /* This might happen before the stream has started */
+        GST_DEBUG_OBJECT (sink, "Got negative delay");
+        delay = 0;
+    }
+    else
+        GST_DEBUG_OBJECT (sink, "Got delay of %u", delay);
+
+    return delay;
+}
+
+static void
+gst_tinyalsa_sink_get_property (GObject * object, guint prop_id,GValue * value, GParamSpec * pspec)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (object);
+
+    switch (prop_id)
+    {
+        case PROP_CARD:     g_value_set_uint (value, sink->card);   break;
+        case PROP_DEVICE:   g_value_set_uint (value, sink->device); break;
+        default:
+            G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+            break;
+    }
+}
+
+static void
+gst_tinyalsa_sink_set_property (GObject * object, guint prop_id, const GValue * value, GParamSpec * pspec)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (object);
+
+    switch (prop_id)
+    {
+        case PROP_CARD:     sink->card   = g_value_get_uint (value); break;
+        case PROP_DEVICE:   sink->device = g_value_get_uint (value); break;
+        default:
+            G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);
+            break;
+    }
+}
+
+/**----------------------------------------Audio Convert Start---------------------------------------------*/
+
+/**
+ * _setup_srcpad_link_audioconvert:
+ * @element: element to setup pad on
+ * @tmpl: pad template
+ *
+ * Returns: (transfer full): a new pad
+ */
+static GstPad *
+_setup_srcpad_link_audioconvert (GstElement * element, GstPadTemplate * tmpl)
+{
+    GstPad *srcpad, *sinkpad;
+
+    /* 创建数据推送Pad --- sending pad */
+    srcpad = gst_pad_new_from_template (tmpl, "toconvert_src");
+    GST_DEBUG_OBJECT (element, "setting up sending pad %p", srcpad);
+    // 创建失败
+    if (NULL == srcpad)
+    {
+        GST_ERROR_OBJECT(element, "Could not create a srcpad");
+        goto error;
+    }
+    // 校验-------no such case!
+    if(GST_OBJECT_REFCOUNT(srcpad) != 1)
+    {
+        // 释放到底
+        while(NULL != srcpad)
+        {
+            gst_object_unref (srcpad);
+        }
+        goto error;
+    }
+    // 获取AudioConvert元件内部的SinkPad
+    sinkpad = gst_element_get_static_pad (element, "sink");
+    if (NULL == sinkpad)
+        sinkpad = gst_element_get_request_pad (element, "sink");
+
+    // 获取失败
+    if (NULL == sinkpad)
+    {
+        GST_ERROR("Could not get sink pad from %s", GST_ELEMENT_NAME (element));
+        goto error;
+    }
+    // 校验SinkPad的运行状态----no such case!
+    if(GST_OBJECT_REFCOUNT(sinkpad) != 2)
+    {
+        GST_ERROR_OBJECT(element, "sinkpad refcount is not 2 !");
+        goto error;
+    }
+
+    // 将创建出来的SrcPad连接到AudioConvert元件的SinkPad上，以便通过其给AudioConvert元件推送数据
+    if(gst_pad_link (srcpad, sinkpad) != GST_PAD_LINK_OK)
+    {
+        GST_ERROR("Could not link source and %s sink pads", GST_ELEMENT_NAME (element));
+        /* release resource, unconnect directly */
+        gst_object_unref (sinkpad);
+        gst_object_unref (srcpad);
+        goto error;
+    }
+    // 保证Pad的refcount
+    /* because we got it higher up */
+    gst_object_unref (sinkpad);
+    if(GST_OBJECT_REFCOUNT(sinkpad) != 1)
+    {
+        GST_ERROR_OBJECT(element, "sinkpad refcount is not 1 !");
+        gst_object_unref (srcpad);
+        goto error;
+    }
+    return srcpad;
+
+error:
+    return NULL;
+}
+
+/**
+ * _setup_sinkpad_link_audioconvert:
+ * @element: element to setup pad on
+ * @tmpl: pad template
+ *
+ * Returns: (transfer full): a new pad
+ */
+static GstPad *
+_setup_sinkpad_link_audioconvert(GstObject * parent, GstElement * element, GstPadTemplate * tmpl)
+{
+    GstPad *srcpad, *sinkpad;
+
+    /* 创建转换数据接收Pad --- receiving pad */
+    sinkpad = gst_pad_new_from_template (tmpl, "converted_sink");
+    GST_DEBUG_OBJECT (element, "setting up receiving pad %p", sinkpad);
+    // 创建失败
+    if (NULL == sinkpad)
+    {
+        GST_ERROR_OBJECT(element, "Could not create a sinkpad");
+        goto error;
+    }
+    // 获取AudioConvert元件内部的SrcPad
+    srcpad = gst_element_get_static_pad (element, "src");
+    if (NULL == srcpad)
+        srcpad = gst_element_get_request_pad (element, "src");
+
+    // 获取失败
+    if (NULL == srcpad)
+    {
+        GST_ERROR("Could not get source pad from %s", GST_ELEMENT_NAME (element));
+        gst_object_unref (sinkpad);
+        goto error;
+    }
+    // 为Pad添加Parent,以便在chain函数中使用sink中的全局变量----会引起convert_sinkpad refcount增加
+    // gst_object_set_parent(GST_OBJECT_CAST(sinkpad), parent);
+    sinkpad->element_private = parent;
+    // 为创建的转换数据接收Pad创建Chain函数，用于推送到Fpp层
+    gst_pad_set_chain_function (sinkpad, gst_tinyalsa_sink_convert_chain_func);
+
+    // 将创建出来的SinkPad连接到AudioConvert元件的SrcPad上，以便通过其接收AudioConvert元件转换后的数据
+    GST_DEBUG_OBJECT (element, "Linking element src pad and receiving sink pad");
+    if(gst_pad_link (srcpad, sinkpad) != GST_PAD_LINK_OK)
+    {
+        GST_ERROR("Could not link source and %s sink pads", GST_ELEMENT_NAME (element));
+        /* release resource, unconnect directly */
+        gst_object_unref (sinkpad);
+        gst_object_unref (srcpad);
+        goto error;
+    }
+
+    // 保证Pad的refcount
+    /* because we got it higher up */
+    gst_object_unref (srcpad);
+    // 校验
+    if(GST_OBJECT_REFCOUNT(srcpad) != 1)
+    {
+        GST_ERROR_OBJECT(element, "srcpad refcount is not 1 !");
+        gst_object_unref (sinkpad);
+        goto error;
+    }
+
+    GST_DEBUG_OBJECT (element, "set up srcpad, refcount is 1");
+    return sinkpad;
+
+error:
+    return NULL;
+}
+
+
+/* takes over reference for outcaps
+ * 以指定的输出Caps创建一个AudioConvert元件,并创建两个连接该元件的Pad，
+ * 一个SrcPad用于推送数据进入AundioConvert元件，一个SinkPad用于接收转化后的数据
+ */
+static GstElement *
+_setup_audioconvert (GstTinyalsaSink * sink, GstCaps * outcaps)
+{
+    // 为元件创建Pad模板
+    GstPadTemplate   *sinktemplate;
+    // AudioConvert元件
+    GstElement       *audioconvert;
+    GstPadTemplate   *ptmpl;
+    // 指定AudioConvert转换后的输入模板，用于创建SrcPad
+    static GstStaticPadTemplate srctemplate = GST_STATIC_PAD_TEMPLATE ("convert_src",
+        GST_PAD_SRC,
+        GST_PAD_ALWAYS,
+        GST_STATIC_CAPS (CONVERT_CAPS_TEMPLATE_STRING)
+    );
+
+    /* 以指定的输出caps创建一个输出模板
+     * ----该模板将用于创建一个经过AudioConvert并连接SrcPad的SinkPad，
+     *     此时该SinkPad用于处理转换后的Audio数据(通过只有SinkPad才有
+     *     的Chain函数，将接收到的buffer流向Fpp)
+     */
+    sinktemplate = gst_pad_template_new ("converted_sink", GST_PAD_SINK, GST_PAD_ALWAYS,   outcaps);
+    GST_DEBUG_OBJECT(sink, "setup_audioconvert with caps %" GST_PTR_FORMAT, outcaps);
+
+    // 创建AudioConvert元件实例
+    audioconvert = gst_element_factory_make ("audioconvert", "audioconvert");
+    if (NULL == audioconvert)
+    {
+        GST_ERROR_OBJECT(sink, "Could not create a audioconvert element");
+        goto create_error;
+    }
+    // 设置AudioConvert属性
+    g_object_set (G_OBJECT (audioconvert), "dithering",     0, NULL);
+    g_object_set (G_OBJECT (audioconvert), "noise-shaping", 0, NULL);
+
+    // 创建一个连接AudioConvert元件的SinkPad的 外部SrcPad,以便通过其给AudioConvert元件推送数据
+
+    ptmpl                 = gst_static_pad_template_get (&srctemplate);
+    sink->convert_srcpad  = _setup_srcpad_link_audioconvert (audioconvert, ptmpl);
+    gst_object_unref (ptmpl);
+    // 校验结果
+    if(NULL == sink->convert_srcpad)
+        goto create_error;
+
+    // 创建一个的SinkPad连接到AudioConvert元件的SrcPad上，以便通过其接收AudioConvert元件转换后的数据
+    sink->convert_sinkpad = _setup_sinkpad_link_audioconvert (GST_OBJECT_CAST(sink), audioconvert, sinktemplate);
+    gst_object_unref (sinktemplate);
+    // 校验结果
+    if(NULL == sink->convert_sinkpad)
+    {
+        gst_object_unref(sink->convert_srcpad);
+        goto create_error;
+    }
+
+    /* this installs a getcaps func that will always return the caps we set later */
+    gst_pad_use_fixed_caps (sink->convert_sinkpad);
+
+    // 激活Pad
+    gst_pad_set_active (sink->convert_srcpad,  TRUE);
+    gst_pad_set_active (sink->convert_sinkpad, TRUE);
+
+    return audioconvert;
+
+create_error:
+    if(NULL != sinktemplate)
+        gst_object_unref (sinktemplate);
+
+    if(NULL != audioconvert)
+    {
+        if(GST_STATE_CHANGE_SUCCESS != gst_element_set_state (sink->audio_convert, GST_STATE_NULL))
+            GST_ERROR_OBJECT(sink, "AudioConvert could not set to NULL!");
+
+        if(GST_OBJECT_REFCOUNT(sink->audio_convert) != 1)
+            GST_ERROR_OBJECT(sink, "AudioConvert 's refcount is not 1!");
+        else
+            gst_object_unref (sink->audio_convert);
+    }
+    return NULL;
+}
+
+/**
+ * _setup_events:
+ * @srcpad: The src #GstPad to push on
+ * @element: The #GstElement use to create the stream id
+ * @caps: (allow-none): #GstCaps in case caps event must be sent
+ * @format: The #GstFormat of the default segment to send
+ *
+ * Push stream-start, caps and segment event, which consist of the minimum
+ * required events to allow streaming. Caps is optional to allow raw src
+ * testing. If @element has more than one src or sink pad, use
+ * gst_check_setup_events_with_stream_id() instead.
+ */
+static gboolean
+_setup_events (GstPad * srcpad, GstElement * element, GstCaps * caps, GstFormat format)
+{
+    gchar *stream_id;
+    GstSegment segment;
+    gboolean ret = TRUE;
+
+    stream_id = gst_pad_create_stream_id (srcpad, element, NULL);
+    gst_segment_init (&segment, format);
+    if(!gst_pad_push_event (srcpad, gst_event_new_stream_start (stream_id)))
+    {
+        GST_ERROR_OBJECT(element, "push NEW_STREAM_START event to AudioConvert error!");
+        ret = FALSE;
+    }
+    if(caps)
+    {
+        if(!gst_pad_push_event (srcpad, gst_event_new_caps (caps)))
+        {
+            GST_ERROR_OBJECT(element, "push NEW_CAPS event to AudioConvert error!");
+            ret = FALSE;
+        }
+    }
+
+    if(!gst_pad_push_event (srcpad, gst_event_new_segment (&segment)))
+    {
+        GST_ERROR_OBJECT(element, "push NEW_SEGMENT event to AudioConvert error!");
+        ret = FALSE;
+    }
+    g_free (stream_id);
+    return ret;
+}
+
+
+static void
+_teardown_pad_by_name (GstElement * element, const gchar * name)
+{
+    GstPad *pad_peer, *pad_element;
+
+    /* clean up floating src pad */
+    pad_element = gst_element_get_static_pad (element, name);
+    /* We don't check the refcount here since there *might* be
+    * a pad cache holding an extra reference on pad_element.
+    * To get to a state where no pad cache will exist,
+    * we first unlink that pad. */
+    pad_peer = gst_pad_get_peer (pad_element);
+
+    if (pad_peer)
+    {
+        if (gst_pad_get_direction (pad_element) == GST_PAD_SINK)
+            gst_pad_unlink (pad_peer, pad_element);
+        else
+            gst_pad_unlink (pad_element, pad_peer);
+    }
+
+    /* pad refs held by both creator and this function (through _get) */
+    if(GST_OBJECT_REFCOUNT(pad_element) != 2)
+        GST_ERROR_OBJECT(element, "pad :%s 's refcount is not 2!", gst_pad_get_name(pad_element));
+
+    gst_object_unref (pad_element);
+    /* one more ref is held by element itself */
+
+    if (pad_peer)
+    {
+        /* pad refs held by both creator and this function (through _get_peer) */
+        if(GST_OBJECT_REFCOUNT(pad_peer) != 2)
+            GST_ERROR_OBJECT(element, "peer pad of pad :%s 's  refcount is not 2!", gst_pad_get_name(pad_peer));
+
+        gst_object_unref (pad_peer);
+        gst_object_unref (pad_peer);
+    }
+}
+
+
+static void
+_cleanup_audioconvert (GstTinyalsaSink * sink)
+{
+    gst_pad_set_active (sink->convert_srcpad,  FALSE);
+    gst_pad_set_active (sink->convert_sinkpad, FALSE);
+    _teardown_pad_by_name (sink->audio_convert, "sink");
+    _teardown_pad_by_name (sink->audio_convert, "src");
+
+    GST_DEBUG_OBJECT(sink, "teardown_element");
+    if(GST_STATE_CHANGE_SUCCESS != gst_element_set_state (sink->audio_convert, GST_STATE_NULL))
+        GST_ERROR_OBJECT(sink, "AudioConvert could not set to NULL!");
+
+    if(GST_OBJECT_REFCOUNT(sink->audio_convert) != 1)
+        GST_ERROR_OBJECT(sink, "AudioConvert 's refcount is not 1!");
+    else
+        gst_object_unref (sink->audio_convert);
+}
+/**----------------------------------------Audio Convert End---------------------------------------------*/
+
+GstFlowReturn
+gst_tinyalsa_sink_convert_chain_func (GstPad * pad, GstObject * parent, GstBuffer * buffer)
+{
+    GstTinyalsaSink *sink = GST_TINYALSA_SINK (pad->element_private);
+    int ret;
+    // Buffer映射Data
+    GstMapInfo mapinfo;
+    gsize      u32Size;
+    guint8*    u8pBuff;
+    gst_buffer_map(buffer, &mapinfo, GST_MAP_READ);
+    u32Size = mapinfo.size;
+    u8pBuff = (guint8 *) (mapinfo.data);
+    gst_buffer_unmap (buffer, &mapinfo);
+
+again:
+    ret = pcm_write (sink->pcm, u8pBuff, u32Size);
+    if (ret == -EPIPE)
+    {
+        GST_WARNING_OBJECT (sink, "Got an underrun");
+        if (pcm_prepare (sink->pcm) < 0)
+        {
+            GST_ERROR_OBJECT (sink, "Could not prepare device: %s", pcm_get_error (sink->pcm));
+            gst_buffer_unref(buffer);
+            return GST_FLOW_NOT_SUPPORTED;
+        }
+        goto again;
+    }
+    else if (ret < 0)
+    {
+        GST_ERROR_OBJECT (sink, "Could not write data to device: %s", pcm_get_error (sink->pcm));
+        gst_buffer_unref(buffer);
+        return GST_FLOW_NOT_SUPPORTED;
+    }
+
+    gst_buffer_unref(buffer);
+    return GST_FLOW_OK;
+}
+
+#else
 /* Hardcoding these bitmask values rather than including a kernel header */
 #define SNDRV_PCM_FORMAT_S8 0
 #define SNDRV_PCM_FORMAT_S16_LE 2
@@ -499,3 +1503,4 @@ gst_tinyalsa_sink_init (GstTinyalsaSink * sink)
 
   sink->cached_caps = NULL;
 }
+#endif
diff --git a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.h b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.h
index a6ae3bfc81..01bb278ae0 100644
--- a/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.h
+++ b/subprojects/gst-plugins-bad/sys/tinyalsa/tinyalsasink.h
@@ -46,6 +46,14 @@ struct _GstTinyalsaSink {
   struct pcm *pcm;
 
   GstCaps *cached_caps; /* for queries made while the device is open */
+#ifdef TCL_PATCH
+  int          channels_max;
+  int          channels_min;
+  GstElement*  audio_convert;
+  GstPad *     convert_sinkpad;
+  GstPad *     convert_srcpad;
+  gboolean     need_convert_flag;
+#endif
 };
 
 struct _GstTinyalsaSinkClass {
diff --git a/subprojects/gst-plugins-bad/sys/winks/ksdeviceprovider.c b/subprojects/gst-plugins-bad/sys/winks/ksdeviceprovider.c
index 28e9b5b669..ef415b6324 100644
--- a/subprojects/gst-plugins-bad/sys/winks/ksdeviceprovider.c
+++ b/subprojects/gst-plugins-bad/sys/winks/ksdeviceprovider.c
@@ -535,7 +535,7 @@ gst_ks_device_provider_start (GstDeviceProvider * provider)
     if (dev->data)
       gst_device_provider_device_add (provider, (GstDevice *) dev->data);
   }
-  g_list_free (devs);
+  g_list_free_full (devs, gst_object_unref);
 
   inst = (HINSTANCE) GetModuleHandle (NULL);
 
-- 
2.25.1

